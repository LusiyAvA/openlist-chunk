diff --git a/README.md b/README.md
index 96616a3de..c4f29462e 100644
--- a/README.md
+++ b/README.md
@@ -122,12 +122,17 @@ Thank you for your support and understanding of the OpenList project.
 
 ## Demo
 
-N/A (to be rebuilt)
+- ğŸŒ [Global Demo](https://demo.oplist.org)
+- ğŸ‡¨ğŸ‡³ [CN Demo](https://demo.oplist.org.cn)
 
 ## Discussion
 
 Please refer to [*Discussions*](https://github.com/OpenListTeam/OpenList/discussions) for raising general questions, ***Issues* is for bug reports and feature requests only.**
 
+## Sponsor
+
+[![VPS.Town](https://vps.town/static/images/sponsor.png)](https://vps.town "VPS.Town - Trust, Effortlessly. Your Cloud, Reimagined.")
+
 ## License
 
 The `OpenList` is open-source software licensed under the [AGPL-3.0](https://www.gnu.org/licenses/agpl-3.0.txt) license.
diff --git a/README_cn.md b/README_cn.md
index ecf68e81e..adac3d0b9 100644
--- a/README_cn.md
+++ b/README_cn.md
@@ -122,12 +122,17 @@ OpenList æ˜¯ä¸€ä¸ªç”± OpenList å›¢é˜Ÿç‹¬ç«‹ç»´æŠ¤çš„å¼€æºé¡¹ç›®ï¼Œéµå¾ª AGPL-3
 
 ## æ¼”ç¤º
 
-N/Aï¼ˆå¾…é‡å»ºï¼‰
+- ğŸ‡¨ğŸ‡³ [å›½å†…æ¼”ç¤ºç«™](https://demo.oplist.org.cn)
+- ğŸŒ [æµ·å¤–æ¼”ç¤ºç«™](https://demo.oplist.org)
 
 ## è®¨è®º
 
 å¦‚æœ‰ä¸€èˆ¬æ€§é—®é¢˜è¯·å‰å¾€ [*Discussions*](https://github.com/OpenListTeam/OpenList/discussions) è®¨è®ºåŒºï¼Œ***Issues* ä»…ç”¨äºé”™è¯¯æŠ¥å‘Šå’ŒåŠŸèƒ½è¯·æ±‚ã€‚**
 
+## èµåŠ©è€…
+
+[![VPS.Town](https://vps.town/static/images/sponsor.png)](https://vps.town "VPS.Town - Trust, Effortlessly. Your Cloud, Reimagined.")
+
 ## è®¸å¯è¯
 
 `OpenList` æ˜¯åŸºäº [AGPL-3.0](https://www.gnu.org/licenses/agpl-3.0.txt) è®¸å¯è¯çš„å¼€æºè½¯ä»¶ã€‚
diff --git a/README_ja.md b/README_ja.md
index c59b68f5a..52c1a01c0 100644
--- a/README_ja.md
+++ b/README_ja.md
@@ -122,12 +122,17 @@ OpenListãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®ã”æ”¯æ´ã¨ã”ç†è§£ã‚’ã‚ã‚ŠãŒã¨ã†ã”ã–ã„
 
 ## ãƒ‡ãƒ¢
 
-N/Aï¼ˆå†æ§‹ç¯‰ä¸­ï¼‰
+- ğŸŒ [ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ‡ãƒ¢](https://demo.oplist.org)
+- ğŸ‡¨ğŸ‡³ [CNãƒ‡ãƒ¢](https://demo.oplist.org.cn)
 
 ## ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³
 
 ä¸€èˆ¬çš„ãªè³ªå•ã¯ [*Discussions*](https://github.com/OpenListTeam/OpenList/discussions) ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚***Issues* ã¯ãƒã‚°å ±å‘Šã¨æ©Ÿèƒ½ãƒªã‚¯ã‚¨ã‚¹ãƒˆå°‚ç”¨ã§ã™ã€‚**
 
+## ã‚¹ãƒãƒ³ã‚µãƒ¼
+
+[![VPS.Town](https://vps.town/static/images/sponsor.png)](https://vps.town "VPS.Town - Trust, Effortlessly. Your Cloud, Reimagined.")
+
 ## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
 
 ã€ŒOpenListã€ã¯ [AGPL-3.0](https://www.gnu.org/licenses/agpl-3.0.txt) ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã§ã™ã€‚
diff --git a/README_nl.md b/README_nl.md
index 56d0f70bc..8b9e62ec7 100644
--- a/README_nl.md
+++ b/README_nl.md
@@ -122,12 +122,17 @@ Dank u voor uw ondersteuning en begrip
 
 ## Demo
 
-N.v.t. (wordt opnieuw opgebouwd)
+- ğŸŒ [Global Demo](https://demo.oplist.org)
+- ğŸ‡¨ğŸ‡³ [CN Demo](https://demo.oplist.org.cn)
 
 ## Discussie
 
 Stel algemene vragen in [*Discussions*](https://github.com/OpenListTeam/OpenList/discussions), ***Issues* zijn alleen voor bugmeldingen en feature requests.**
 
+## Sponsoren
+
+[![VPS.Town](https://vps.town/static/images/sponsor.png)](https://vps.town "VPS.Town - Trust, Effortlessly. Your Cloud, Reimagined.")
+
 ## Licentie
 
 `OpenList` is open-source software onder de [AGPL-3.0](https://www.gnu.org/licenses/agpl-3.0.txt) licentie.
diff --git a/cmd/admin.go b/cmd/admin.go
index 447c49703..5e09959cf 100644
--- a/cmd/admin.go
+++ b/cmd/admin.go
@@ -6,6 +6,7 @@ package cmd
 import (
 	"fmt"
 
+	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap"
 	"github.com/OpenListTeam/OpenList/v4/internal/conf"
 	"github.com/OpenListTeam/OpenList/v4/internal/op"
 	"github.com/OpenListTeam/OpenList/v4/internal/setting"
@@ -20,8 +21,8 @@ var AdminCmd = &cobra.Command{
 	Aliases: []string{"password"},
 	Short:   "Show admin user's info and some operations about admin user's password",
 	Run: func(cmd *cobra.Command, args []string) {
-		Init()
-		defer Release()
+		bootstrap.Init()
+		defer bootstrap.Release()
 		admin, err := op.GetAdmin()
 		if err != nil {
 			utils.Log.Errorf("failed get admin user: %+v", err)
@@ -61,8 +62,8 @@ var ShowTokenCmd = &cobra.Command{
 	Use:   "token",
 	Short: "Show admin token",
 	Run: func(cmd *cobra.Command, args []string) {
-		Init()
-		defer Release()
+		bootstrap.Init()
+		defer bootstrap.Release()
 		token := setting.GetStr(conf.Token)
 		utils.Log.Infof("show admin token from CLI")
 		fmt.Println("Admin token:", token)
@@ -70,8 +71,8 @@ var ShowTokenCmd = &cobra.Command{
 }
 
 func setAdminPassword(pwd string) {
-	Init()
-	defer Release()
+	bootstrap.Init()
+	defer bootstrap.Release()
 	admin, err := op.GetAdmin()
 	if err != nil {
 		utils.Log.Errorf("failed get admin user: %+v", err)
diff --git a/cmd/cancel2FA.go b/cmd/cancel2FA.go
index 809d32e37..3ddd7f838 100644
--- a/cmd/cancel2FA.go
+++ b/cmd/cancel2FA.go
@@ -6,6 +6,7 @@ package cmd
 import (
 	"fmt"
 
+	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap"
 	"github.com/OpenListTeam/OpenList/v4/internal/op"
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
 	"github.com/spf13/cobra"
@@ -16,8 +17,8 @@ var Cancel2FACmd = &cobra.Command{
 	Use:   "cancel2fa",
 	Short: "Delete 2FA of admin user",
 	Run: func(cmd *cobra.Command, args []string) {
-		Init()
-		defer Release()
+		bootstrap.Init()
+		defer bootstrap.Release()
 		admin, err := op.GetAdmin()
 		if err != nil {
 			utils.Log.Errorf("failed to get admin user: %+v", err)
diff --git a/cmd/common.go b/cmd/common.go
index 6835a0f5c..e334fc1fa 100644
--- a/cmd/common.go
+++ b/cmd/common.go
@@ -6,24 +6,16 @@ import (
 	"strconv"
 
 	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap"
-	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap/data"
-	"github.com/OpenListTeam/OpenList/v4/internal/db"
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
 	log "github.com/sirupsen/logrus"
 )
 
 func Init() {
-	bootstrap.InitConfig()
-	bootstrap.Log()
-	bootstrap.InitDB()
-	data.InitData()
-	bootstrap.InitStreamLimit()
-	bootstrap.InitIndex()
-	bootstrap.InitUpgradePatch()
+	bootstrap.Init()
 }
 
 func Release() {
-	db.Close()
+	bootstrap.Release()
 }
 
 var pid = -1
diff --git a/cmd/crypt.go b/cmd/crypt.go
index 10b3352cd..12f51f5cd 100644
--- a/cmd/crypt.go
+++ b/cmd/crypt.go
@@ -1,19 +1,17 @@
 package cmd
 
 import (
-	log "github.com/sirupsen/logrus"
-
 	"io"
 	"os"
 	"path"
 	"path/filepath"
 	"strings"
 
-	"github.com/spf13/cobra"
-
 	rcCrypt "github.com/rclone/rclone/backend/crypt"
 	"github.com/rclone/rclone/fs/config/configmap"
 	"github.com/rclone/rclone/fs/config/obscure"
+	log "github.com/sirupsen/logrus"
+	"github.com/spf13/cobra"
 )
 
 // encryption and decryption command format for Crypt driver
diff --git a/cmd/lang.go b/cmd/lang.go
index a03b3c561..c18877cd7 100644
--- a/cmd/lang.go
+++ b/cmd/lang.go
@@ -8,7 +8,6 @@ import (
 	"fmt"
 	"io"
 	"os"
-	"reflect"
 	"strings"
 
 	_ "github.com/OpenListTeam/OpenList/v4/drivers"
@@ -69,15 +68,33 @@ func writeFile(name string, data interface{}) {
 		log.Errorf("failed to unmarshal json: %+v", err)
 		return
 	}
-	if reflect.DeepEqual(oldData, newData) {
+	if mergeJson(newData, oldData) {
 		log.Infof("%s.json no changed, skip", name)
 	} else {
 		log.Infof("%s.json changed, update file", name)
 		//log.Infof("old: %+v\nnew:%+v", oldData, data)
-		utils.WriteJsonToFile(fmt.Sprintf("lang/%s.json", name), newData, true)
+		utils.WriteJsonToFile(fmt.Sprintf("lang/%s.json", name), oldData, true)
 	}
 }
 
+func mergeJson(source, target map[string]interface{}) bool {
+	equal := true
+	for k, v := range source {
+		tgtV, tgtOk := target[k]
+		if !tgtOk {
+			equal = false
+			target[k] = v
+		} else {
+			srcMap, srcIsMap := v.(map[string]interface{})
+			tgtMap, tgtIsMap := tgtV.(map[string]interface{})
+			if srcIsMap && tgtIsMap {
+				equal = mergeJson(srcMap, tgtMap) && equal
+			}
+		}
+	}
+	return equal
+}
+
 func generateDriversJson() {
 	drivers := make(Drivers)
 	drivers["drivers"] = make(KV[interface{}])
diff --git a/cmd/server.go b/cmd/server.go
index 9f45161d7..26441f916 100644
--- a/cmd/server.go
+++ b/cmd/server.go
@@ -1,34 +1,13 @@
 package cmd
 
 import (
-	"context"
-	"errors"
-	"fmt"
-	"net"
-	"net/http"
 	"os"
 	"os/signal"
-	"strconv"
-	"sync"
 	"syscall"
 	"time"
 
-	"github.com/OpenListTeam/OpenList/v4/cmd/flags"
 	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap"
-	"github.com/OpenListTeam/OpenList/v4/internal/conf"
-	"github.com/OpenListTeam/OpenList/v4/internal/fs"
-	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
-	"github.com/OpenListTeam/OpenList/v4/server"
-	"github.com/OpenListTeam/OpenList/v4/server/middlewares"
-	"github.com/OpenListTeam/sftpd-openlist"
-	ftpserver "github.com/fclairamb/ftpserverlib"
-	"github.com/gin-gonic/gin"
-	log "github.com/sirupsen/logrus"
 	"github.com/spf13/cobra"
-	"golang.org/x/net/http2"
-	"golang.org/x/net/http2/h2c"
-
-	"github.com/quic-go/quic-go/http3"
 )
 
 // ServerCmd represents the server command
@@ -38,161 +17,9 @@ var ServerCmd = &cobra.Command{
 	Long: `Start the server at the specified address
 the address is defined in config file`,
 	Run: func(cmd *cobra.Command, args []string) {
-		Init()
-		if conf.Conf.DelayedStart != 0 {
-			utils.Log.Infof("delayed start for %d seconds", conf.Conf.DelayedStart)
-			time.Sleep(time.Duration(conf.Conf.DelayedStart) * time.Second)
-		}
-		bootstrap.InitOfflineDownloadTools()
-		bootstrap.LoadStorages()
-		bootstrap.InitTaskManager()
-		if !flags.Debug && !flags.Dev {
-			gin.SetMode(gin.ReleaseMode)
-		}
-		r := gin.New()
-
-		// gin log
-		if conf.Conf.Log.Filter.Enable {
-			r.Use(middlewares.FilteredLogger())
-		} else {
-			r.Use(gin.LoggerWithWriter(log.StandardLogger().Out))
-		}
-		r.Use(gin.RecoveryWithWriter(log.StandardLogger().Out))
-
-		server.Init(r)
-		var httpHandler http.Handler = r
-		if conf.Conf.Scheme.EnableH2c {
-			httpHandler = h2c.NewHandler(r, &http2.Server{})
-		}
-		var httpSrv, httpsSrv, unixSrv *http.Server
-		var quicSrv *http3.Server
-		if conf.Conf.Scheme.HttpPort != -1 {
-			httpBase := fmt.Sprintf("%s:%d", conf.Conf.Scheme.Address, conf.Conf.Scheme.HttpPort)
-			fmt.Printf("start HTTP server @ %s\n", httpBase)
-			utils.Log.Infof("start HTTP server @ %s", httpBase)
-			httpSrv = &http.Server{Addr: httpBase, Handler: httpHandler}
-			go func() {
-				err := httpSrv.ListenAndServe()
-				if err != nil && !errors.Is(err, http.ErrServerClosed) {
-					utils.Log.Fatalf("failed to start http: %s", err.Error())
-				}
-			}()
-		}
-		if conf.Conf.Scheme.HttpsPort != -1 {
-			httpsBase := fmt.Sprintf("%s:%d", conf.Conf.Scheme.Address, conf.Conf.Scheme.HttpsPort)
-			fmt.Printf("start HTTPS server @ %s\n", httpsBase)
-			utils.Log.Infof("start HTTPS server @ %s", httpsBase)
-			httpsSrv = &http.Server{Addr: httpsBase, Handler: r}
-			go func() {
-				err := httpsSrv.ListenAndServeTLS(conf.Conf.Scheme.CertFile, conf.Conf.Scheme.KeyFile)
-				if err != nil && !errors.Is(err, http.ErrServerClosed) {
-					utils.Log.Fatalf("failed to start https: %s", err.Error())
-				}
-			}()
-			if conf.Conf.Scheme.EnableH3 {
-				fmt.Printf("start HTTP3 (quic) server @ %s\n", httpsBase)
-				utils.Log.Infof("start HTTP3 (quic) server @ %s", httpsBase)
-				r.Use(func(c *gin.Context) {
-					if c.Request.TLS != nil {
-						port := conf.Conf.Scheme.HttpsPort
-						c.Header("Alt-Svc", fmt.Sprintf("h3=\":%d\"; ma=86400", port))
-					}
-					c.Next()
-				})
-				quicSrv = &http3.Server{Addr: httpsBase, Handler: r}
-				go func() {
-					err := quicSrv.ListenAndServeTLS(conf.Conf.Scheme.CertFile, conf.Conf.Scheme.KeyFile)
-					if err != nil && !errors.Is(err, http.ErrServerClosed) {
-						utils.Log.Fatalf("failed to start http3 (quic): %s", err.Error())
-					}
-				}()
-			}
-		}
-		if conf.Conf.Scheme.UnixFile != "" {
-			fmt.Printf("start unix server @ %s\n", conf.Conf.Scheme.UnixFile)
-			utils.Log.Infof("start unix server @ %s", conf.Conf.Scheme.UnixFile)
-			unixSrv = &http.Server{Handler: httpHandler}
-			go func() {
-				listener, err := net.Listen("unix", conf.Conf.Scheme.UnixFile)
-				if err != nil {
-					utils.Log.Fatalf("failed to listen unix: %+v", err)
-				}
-				// set socket file permission
-				mode, err := strconv.ParseUint(conf.Conf.Scheme.UnixFilePerm, 8, 32)
-				if err != nil {
-					utils.Log.Errorf("failed to parse socket file permission: %+v", err)
-				} else {
-					err = os.Chmod(conf.Conf.Scheme.UnixFile, os.FileMode(mode))
-					if err != nil {
-						utils.Log.Errorf("failed to chmod socket file: %+v", err)
-					}
-				}
-				err = unixSrv.Serve(listener)
-				if err != nil && !errors.Is(err, http.ErrServerClosed) {
-					utils.Log.Fatalf("failed to start unix: %s", err.Error())
-				}
-			}()
-		}
-		if conf.Conf.S3.Port != -1 && conf.Conf.S3.Enable {
-			s3r := gin.New()
-			s3r.Use(gin.LoggerWithWriter(log.StandardLogger().Out), gin.RecoveryWithWriter(log.StandardLogger().Out))
-			server.InitS3(s3r)
-			s3Base := fmt.Sprintf("%s:%d", conf.Conf.Scheme.Address, conf.Conf.S3.Port)
-			fmt.Printf("start S3 server @ %s\n", s3Base)
-			utils.Log.Infof("start S3 server @ %s", s3Base)
-			go func() {
-				var err error
-				if conf.Conf.S3.SSL {
-					httpsSrv = &http.Server{Addr: s3Base, Handler: s3r}
-					err = httpsSrv.ListenAndServeTLS(conf.Conf.Scheme.CertFile, conf.Conf.Scheme.KeyFile)
-				}
-				if !conf.Conf.S3.SSL {
-					httpSrv = &http.Server{Addr: s3Base, Handler: s3r}
-					err = httpSrv.ListenAndServe()
-				}
-				if err != nil && !errors.Is(err, http.ErrServerClosed) {
-					utils.Log.Fatalf("failed to start s3 server: %s", err.Error())
-				}
-			}()
-		}
-		var ftpDriver *server.FtpMainDriver
-		var ftpServer *ftpserver.FtpServer
-		if conf.Conf.FTP.Listen != "" && conf.Conf.FTP.Enable {
-			var err error
-			ftpDriver, err = server.NewMainDriver()
-			if err != nil {
-				utils.Log.Fatalf("failed to start ftp driver: %s", err.Error())
-			} else {
-				fmt.Printf("start ftp server on %s\n", conf.Conf.FTP.Listen)
-				utils.Log.Infof("start ftp server on %s", conf.Conf.FTP.Listen)
-				go func() {
-					ftpServer = ftpserver.NewFtpServer(ftpDriver)
-					err = ftpServer.ListenAndServe()
-					if err != nil {
-						utils.Log.Fatalf("problem ftp server listening: %s", err.Error())
-					}
-				}()
-			}
-		}
-		var sftpDriver *server.SftpDriver
-		var sftpServer *sftpd.SftpServer
-		if conf.Conf.SFTP.Listen != "" && conf.Conf.SFTP.Enable {
-			var err error
-			sftpDriver, err = server.NewSftpDriver()
-			if err != nil {
-				utils.Log.Fatalf("failed to start sftp driver: %s", err.Error())
-			} else {
-				fmt.Printf("start sftp server on %s", conf.Conf.SFTP.Listen)
-				utils.Log.Infof("start sftp server on %s", conf.Conf.SFTP.Listen)
-				go func() {
-					sftpServer = sftpd.NewSftpServer(sftpDriver)
-					err = sftpServer.RunServer()
-					if err != nil {
-						utils.Log.Fatalf("problem sftp server listening: %s", err.Error())
-					}
-				}()
-			}
-		}
+		bootstrap.Init()
+		defer bootstrap.Release()
+		bootstrap.Start()
 		// Wait for interrupt signal to gracefully shutdown the server with
 		// a timeout of 1 second.
 		quit := make(chan os.Signal, 1)
@@ -201,69 +28,7 @@ the address is defined in config file`,
 		// kill -9 is syscall. SIGKILL but can"t be catch, so don't need add it
 		signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
 		<-quit
-		utils.Log.Println("Shutdown server...")
-		fs.ArchiveContentUploadTaskManager.RemoveAll()
-		Release()
-		ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)
-		defer cancel()
-		var wg sync.WaitGroup
-		if conf.Conf.Scheme.HttpPort != -1 {
-			wg.Add(1)
-			go func() {
-				defer wg.Done()
-				if err := httpSrv.Shutdown(ctx); err != nil {
-					utils.Log.Fatal("HTTP server shutdown err: ", err)
-				}
-			}()
-		}
-		if conf.Conf.Scheme.HttpsPort != -1 {
-			wg.Add(1)
-			go func() {
-				defer wg.Done()
-				if err := httpsSrv.Shutdown(ctx); err != nil {
-					utils.Log.Fatal("HTTPS server shutdown err: ", err)
-				}
-			}()
-			if conf.Conf.Scheme.EnableH3 {
-				wg.Add(1)
-				go func() {
-					defer wg.Done()
-					if err := quicSrv.Shutdown(ctx); err != nil {
-						utils.Log.Fatal("HTTP3 (quic) server shutdown err: ", err)
-					}
-				}()
-			}
-		}
-		if conf.Conf.Scheme.UnixFile != "" {
-			wg.Add(1)
-			go func() {
-				defer wg.Done()
-				if err := unixSrv.Shutdown(ctx); err != nil {
-					utils.Log.Fatal("Unix server shutdown err: ", err)
-				}
-			}()
-		}
-		if conf.Conf.FTP.Listen != "" && conf.Conf.FTP.Enable && ftpServer != nil && ftpDriver != nil {
-			wg.Add(1)
-			go func() {
-				defer wg.Done()
-				ftpDriver.Stop()
-				if err := ftpServer.Stop(); err != nil {
-					utils.Log.Fatal("FTP server shutdown err: ", err)
-				}
-			}()
-		}
-		if conf.Conf.SFTP.Listen != "" && conf.Conf.SFTP.Enable && sftpServer != nil && sftpDriver != nil {
-			wg.Add(1)
-			go func() {
-				defer wg.Done()
-				if err := sftpServer.Close(); err != nil {
-					utils.Log.Fatal("SFTP server shutdown err: ", err)
-				}
-			}()
-		}
-		wg.Wait()
-		utils.Log.Println("Server exit")
+		bootstrap.Shutdown(1 * time.Second)
 	},
 }
 
diff --git a/cmd/storage.go b/cmd/storage.go
index c744dace5..6190feb38 100644
--- a/cmd/storage.go
+++ b/cmd/storage.go
@@ -8,6 +8,7 @@ import (
 	"os"
 	"strconv"
 
+	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap"
 	"github.com/OpenListTeam/OpenList/v4/internal/db"
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
 	"github.com/charmbracelet/bubbles/table"
@@ -30,8 +31,8 @@ var disableStorageCmd = &cobra.Command{
 			return fmt.Errorf("mount path is required")
 		}
 		mountPath := args[0]
-		Init()
-		defer Release()
+		bootstrap.Init()
+		defer bootstrap.Release()
 		storage, err := db.GetStorageByMountPath(mountPath)
 		if err != nil {
 			return fmt.Errorf("failed to query storage: %+v", err)
@@ -69,8 +70,8 @@ var deleteStorageCmd = &cobra.Command{
 			}
 		}
 
-		Init()
-		defer Release()
+		bootstrap.Init()
+		defer bootstrap.Release()
 		err = db.DeleteStorageById(uint(id))
 		if err != nil {
 			return fmt.Errorf("failed to delete storage by id: %+v", err)
@@ -123,8 +124,8 @@ var listStorageCmd = &cobra.Command{
 	Use:   "list",
 	Short: "List all storages",
 	RunE: func(cmd *cobra.Command, args []string) error {
-		Init()
-		defer Release()
+		bootstrap.Init()
+		defer bootstrap.Release()
 		storages, _, err := db.GetStorages(1, -1)
 		if err != nil {
 			return fmt.Errorf("failed to query storages: %+v", err)
diff --git a/drivers/115_open/driver.go b/drivers/115_open/driver.go
index afccb2a7e..909bf4a99 100644
--- a/drivers/115_open/driver.go
+++ b/drivers/115_open/driver.go
@@ -53,6 +53,12 @@ func (d *Open115) Init(ctx context.Context) error {
 	if d.Addition.LimitRate > 0 {
 		d.limiter = rate.NewLimiter(rate.Limit(d.Addition.LimitRate), 1)
 	}
+	if d.PageSize <= 0 {
+		d.PageSize = 200
+	} else if d.PageSize > 1150 {
+		d.PageSize = 1150
+	}
+
 	return nil
 }
 
@@ -69,7 +75,7 @@ func (d *Open115) Drop(ctx context.Context) error {
 
 func (d *Open115) List(ctx context.Context, dir model.Obj, args model.ListArgs) ([]model.Obj, error) {
 	var res []model.Obj
-	pageSize := int64(200)
+	pageSize := int64(d.PageSize)
 	offset := int64(0)
 	for {
 		if err := d.WaitLimit(ctx); err != nil {
diff --git a/drivers/115_open/meta.go b/drivers/115_open/meta.go
index f66ae9310..ed908e2e6 100644
--- a/drivers/115_open/meta.go
+++ b/drivers/115_open/meta.go
@@ -12,6 +12,7 @@ type Addition struct {
 	OrderBy        string  `json:"order_by" type:"select" options:"file_name,file_size,user_utime,file_type"`
 	OrderDirection string  `json:"order_direction" type:"select" options:"asc,desc"`
 	LimitRate      float64 `json:"limit_rate" type:"float" default:"1" help:"limit all api request rate ([limit]r/1s)"`
+	PageSize       int64   `json:"page_size" type:"number" default:"200" help:"list api per page size of 115open driver"`
 	AccessToken    string  `json:"access_token" required:"true"`
 	RefreshToken   string  `json:"refresh_token" required:"true"`
 }
diff --git a/drivers/115_open/upload.go b/drivers/115_open/upload.go
index 3c847e057..3575678c2 100644
--- a/drivers/115_open/upload.go
+++ b/drivers/115_open/upload.go
@@ -107,16 +107,16 @@ func (d *Open115) multpartUpload(ctx context.Context, stream model.FileStreamer,
 		if err != nil {
 			return err
 		}
-		rateLimitedRd := driver.NewLimitedUploadStream(ctx, rd)
 		err = retry.Do(func() error {
 			rd.Seek(0, io.SeekStart)
-			part, err := bucket.UploadPart(imur, rateLimitedRd, partSize, int(i))
+			part, err := bucket.UploadPart(imur, driver.NewLimitedUploadStream(ctx, rd), partSize, int(i))
 			if err != nil {
 				return err
 			}
 			parts[i-1] = part
 			return nil
 		},
+			retry.Context(ctx),
 			retry.Attempts(3),
 			retry.DelayType(retry.BackOffDelay),
 			retry.Delay(time.Second))
diff --git a/drivers/123/upload.go b/drivers/123/upload.go
index a4ae988d9..cc149cfe3 100644
--- a/drivers/123/upload.go
+++ b/drivers/123/upload.go
@@ -125,27 +125,18 @@ func (d *Pan123) newUpload(ctx context.Context, upReq *UploadResp, file model.Fi
 				curSize = lastChunkSize
 			}
 			var reader io.ReadSeeker
-			var rateLimitedRd io.Reader
 			threadG.GoWithLifecycle(errgroup.Lifecycle{
-				Before: func(ctx context.Context) error {
-					if reader == nil {
-						var err error
-						reader, err = ss.GetSectionReader(offset, curSize)
-						if err != nil {
-							return err
-						}
-						rateLimitedRd = driver.NewLimitedUploadStream(ctx, reader)
-					}
-					return nil
+				Before: func(ctx context.Context) (err error) {
+					reader, err = ss.GetSectionReader(offset, curSize)
+					return
 				},
-				Do: func(ctx context.Context) error {
+				Do: func(ctx context.Context) (err error) {
 					reader.Seek(0, io.SeekStart)
 					uploadUrl := s3PreSignedUrls.Data.PreSignedUrls[strconv.Itoa(cur)]
 					if uploadUrl == "" {
 						return fmt.Errorf("upload url is empty, s3PreSignedUrls: %+v", s3PreSignedUrls)
 					}
-					reader.Seek(0, io.SeekStart)
-					req, err := http.NewRequestWithContext(ctx, http.MethodPut, uploadUrl, rateLimitedRd)
+					req, err := http.NewRequestWithContext(ctx, http.MethodPut, uploadUrl, driver.NewLimitedUploadStream(ctx, reader))
 					if err != nil {
 						return err
 					}
@@ -157,7 +148,7 @@ func (d *Pan123) newUpload(ctx context.Context, upReq *UploadResp, file model.Fi
 					}
 					defer res.Body.Close()
 					if res.StatusCode == http.StatusForbidden {
-						singleflight.AnyGroup.Do(fmt.Sprintf("Pan123.newUpload_%p", threadG), func() (any, error) {
+						_, err, _ = singleflight.AnyGroup.Do(fmt.Sprintf("Pan123.newUpload_%p", threadG), func() (any, error) {
 							newS3PreSignedUrls, err := getS3UploadUrl(ctx, upReq, cur, end)
 							if err != nil {
 								return nil, err
@@ -177,7 +168,7 @@ func (d *Pan123) newUpload(ctx context.Context, upReq *UploadResp, file model.Fi
 						}
 						return fmt.Errorf("upload s3 chunk %d failed, status code: %d, body: %s", cur, res.StatusCode, body)
 					}
-					progress := 10.0 + 85.0*float64(threadG.Success())/float64(chunkCount)
+					progress := 100 * float64(threadG.Success()+1) / float64(chunkCount+1)
 					up(progress)
 					return nil
 				},
diff --git a/drivers/123_link/driver.go b/drivers/123_link/driver.go
index af8cc2164..dec09816b 100644
--- a/drivers/123_link/driver.go
+++ b/drivers/123_link/driver.go
@@ -39,6 +39,10 @@ func (d *Pan123Link) Drop(ctx context.Context) error {
 	return nil
 }
 
+func (Addition) GetRootPath() string {
+	return "/"
+}
+
 func (d *Pan123Link) Get(ctx context.Context, path string) (model.Obj, error) {
 	node := GetNodeFromRootByPath(d.root, path)
 	return nodeToObj(node, path)
diff --git a/drivers/123_open/driver.go b/drivers/123_open/driver.go
index ac75e51d7..d9984e57f 100644
--- a/drivers/123_open/driver.go
+++ b/drivers/123_open/driver.go
@@ -18,6 +18,7 @@ type Open123 struct {
 	model.Storage
 	Addition
 	UID uint64
+	tm  *tokenManager
 }
 
 func (d *Open123) Config() driver.Config {
@@ -33,6 +34,24 @@ func (d *Open123) Init(ctx context.Context) error {
 		d.UploadThread = 3
 	}
 
+	if d.RefreshToken != "" {
+		// refresh token ç›´æ¥ä¸»åŠ¨åˆ·æ–°
+		d.AccessToken = ""
+		d.tm = &tokenManager{}
+	} else {
+		// é¿å…ä¸ªäºº token åˆ·æ–°äº§ç”Ÿçš„å¤šä¸ªç™»å½•ï¼Œè¢«åŠ¨åˆ·æ–°
+		// é»˜è®¤è¿‡æœŸæ—¶é—´90å¤©ï¼Œjwt exp ä¸å¯é 
+		d.tm = &tokenManager{
+			// accessToken: d.AccessToken,
+			expiredAt: time.Now().Add(90 * 24 * time.Hour),
+		}
+	}
+
+	_, err := d.getAccessToken(false)
+	if err != nil {
+		return fmt.Errorf("init get access token error: %w", err)
+	}
+
 	return nil
 }
 
diff --git a/drivers/123_open/meta.go b/drivers/123_open/meta.go
index db4ccc187..67f56d8ea 100644
--- a/drivers/123_open/meta.go
+++ b/drivers/123_open/meta.go
@@ -13,7 +13,7 @@ type Addition struct {
 	ClientID     string `json:"ClientID" required:"false"`
 	ClientSecret string `json:"ClientSecret" required:"false"`
 
-	//  ç›´æ¥å†™å…¥AccessToken
+	//  ç›´æ¥å†™å…¥AccessToken, AccessTokenæœ‰è¿‡æœŸæ—¶é—´ï¼Œä¸å»ºè®®ç›´æ¥å¡«å†™
 	AccessToken string `json:"AccessToken" required:"false"`
 
 	//  ç”¨æˆ·å+å¯†ç æ–¹å¼ç™»å½•çš„AccessTokenå¯ä»¥å…¼å®¹
diff --git a/drivers/123_open/token.go b/drivers/123_open/token.go
new file mode 100644
index 000000000..3c5c416c9
--- /dev/null
+++ b/drivers/123_open/token.go
@@ -0,0 +1,115 @@
+package _123_open
+
+import (
+	"encoding/json"
+	"errors"
+	"fmt"
+	"net/http"
+	"sync"
+	"time"
+
+	"github.com/OpenListTeam/OpenList/v4/drivers/base"
+	"github.com/OpenListTeam/OpenList/v4/internal/op"
+)
+
+var (
+	AccessToken  = "https://open-api.123pan.com/api/v1/access_token"
+	RefreshToken = "https://open-api.123pan.com/api/v1/oauth2/access_token"
+)
+
+type tokenManager struct {
+	// accessToken  string
+	expiredAt    time.Time
+	mu           sync.Mutex
+	blockRefresh bool
+}
+
+func (d *Open123) getAccessToken(forceRefresh bool) (string, error) {
+	tm := d.tm
+	tm.mu.Lock()
+	defer tm.mu.Unlock()
+	if tm.blockRefresh {
+		return "", errors.New("Authentication expired")
+	}
+	if !forceRefresh && d.AccessToken != "" && time.Now().Before(tm.expiredAt.Add(-5*time.Minute)) {
+		return d.AccessToken, nil
+	}
+	if err := d.flushAccessToken(); err != nil {
+		// token expired and failed to refresh, block further refresh attempts
+		tm.blockRefresh = true
+		return "", err
+	}
+	return d.AccessToken, nil
+}
+
+func (d *Open123) flushAccessToken() error {
+	// directly send request to avoid deadlock
+	req := base.RestyClient.R()
+	req.SetHeaders(map[string]string{
+		"authorization": "Bearer " + d.AccessToken,
+		"platform":      "open_platform",
+		"Content-Type":  "application/json",
+	})
+
+	if d.ClientID != "" {
+		if d.RefreshToken != "" {
+			var resp RefreshTokenResp
+			req.SetQueryParam("client_id", d.ClientID)
+			if d.ClientSecret != "" {
+				req.SetQueryParam("client_secret", d.ClientSecret)
+			}
+			req.SetQueryParam("grant_type", "refresh_token")
+			req.SetQueryParam("refresh_token", d.RefreshToken)
+			req.SetResult(&resp)
+			res, err := req.Execute(http.MethodPost, RefreshToken)
+			if err != nil {
+				return err
+			}
+			body := res.Body()
+			var baseResp BaseResp
+			if err = json.Unmarshal(body, &baseResp); err != nil {
+				return err
+			}
+			if baseResp.Code != 0 {
+				return fmt.Errorf("get access token failed: %s", baseResp.Message)
+			}
+
+			d.AccessToken = resp.AccessToken
+			// add token expire time
+			d.tm.expiredAt = time.Now().Add(time.Duration(resp.ExpiresIn) * time.Second)
+			d.RefreshToken = resp.RefreshToken
+			op.MustSaveDriverStorage(d)
+			d.tm.blockRefresh = false
+			return nil
+		} else if d.ClientSecret != "" {
+			var resp AccessTokenResp
+			req.SetBody(base.Json{
+				"clientID":     d.ClientID,
+				"clientSecret": d.ClientSecret,
+			})
+			req.SetResult(&resp)
+			res, err := req.Execute(http.MethodPost, AccessToken)
+			if err != nil {
+				return err
+			}
+			body := res.Body()
+			var baseResp BaseResp
+			if err = json.Unmarshal(body, &baseResp); err != nil {
+				return err
+			}
+			if baseResp.Code != 0 {
+				return fmt.Errorf("get access token failed: %s", baseResp.Message)
+			}
+			d.AccessToken = resp.Data.AccessToken
+			// parse token expire time
+			d.tm.expiredAt, err = time.Parse(time.RFC3339, resp.Data.ExpiredAt)
+			if err != nil {
+				return fmt.Errorf("parse expire time failed: %w", err)
+			}
+			op.MustSaveDriverStorage(d)
+			d.tm.blockRefresh = false
+			return nil
+		}
+	}
+	return errors.New("no valid authentication method available")
+}
diff --git a/drivers/123_open/upload.go b/drivers/123_open/upload.go
index 73395fcfd..90cff90d7 100644
--- a/drivers/123_open/upload.go
+++ b/drivers/123_open/upload.go
@@ -73,25 +73,20 @@ func (d *Open123) Upload(ctx context.Context, file model.FileStreamer, createRes
 		// è¡¨å•
 		b := bytes.NewBuffer(make([]byte, 0, 2048))
 		threadG.GoWithLifecycle(errgroup.Lifecycle{
-			Before: func(ctx context.Context) error {
-				if reader == nil {
-					var err error
-					// æ¯ä¸ªåˆ†ç‰‡ä¸€ä¸ªreader
-					reader, err = ss.GetSectionReader(offset, size)
-					if err != nil {
-						return err
-					}
-					// è®¡ç®—å½“å‰åˆ†ç‰‡çš„MD5
+			Before: func(ctx context.Context) (err error) {
+				reader, err = ss.GetSectionReader(offset, size)
+				return
+			},
+			Do: func(ctx context.Context) (err error) {
+				reader.Seek(0, io.SeekStart)
+				if sliceMD5 == "" {
+					// æŠŠè€—æ—¶çš„è®¡ç®—æ”¾åœ¨è¿™é‡Œï¼Œé¿å…é˜»å¡å…¶ä»–åç¨‹
 					sliceMD5, err = utils.HashReader(utils.MD5, reader)
 					if err != nil {
 						return err
 					}
+					reader.Seek(0, io.SeekStart)
 				}
-				return nil
-			},
-			Do: func(ctx context.Context) error {
-				// é‡ç½®åˆ†ç‰‡readerä½ç½®ï¼Œå› ä¸ºHashReaderã€ä¸Šä¸€æ¬¡å¤±è´¥å·²ç»è¯»å–åˆ°åˆ†ç‰‡EOF
-				reader.Seek(0, io.SeekStart)
 
 				b.Reset()
 				w := multipart.NewWriter(b)
@@ -121,6 +116,10 @@ func (d *Open123) Upload(ctx context.Context, file model.FileStreamer, createRes
 				head := bytes.NewReader(b.Bytes()[:headSize])
 				tail := bytes.NewReader(b.Bytes()[headSize:])
 				rateLimitedRd = driver.NewLimitedUploadStream(ctx, io.MultiReader(head, reader, tail))
+				token, err := d.getAccessToken(false)
+				if err != nil {
+					return err
+				}
 				// åˆ›å»ºè¯·æ±‚å¹¶è®¾ç½®header
 				req, err := http.NewRequestWithContext(ctx, http.MethodPost, uploadDomain+"/upload/v2/file/slice", rateLimitedRd)
 				if err != nil {
@@ -128,7 +127,7 @@ func (d *Open123) Upload(ctx context.Context, file model.FileStreamer, createRes
 				}
 
 				// è®¾ç½®è¯·æ±‚å¤´
-				req.Header.Add("Authorization", "Bearer "+d.AccessToken)
+				req.Header.Add("Authorization", "Bearer "+token)
 				req.Header.Add("Content-Type", w.FormDataContentType())
 				req.Header.Add("Platform", "open_platform")
 
@@ -140,12 +139,13 @@ func (d *Open123) Upload(ctx context.Context, file model.FileStreamer, createRes
 				if res.StatusCode != 200 {
 					return fmt.Errorf("slice %d upload failed, status code: %d", partNumber, res.StatusCode)
 				}
-				var resp BaseResp
-				respBody, err := io.ReadAll(res.Body)
+				b.Reset()
+				_, err = b.ReadFrom(res.Body)
 				if err != nil {
 					return err
 				}
-				err = json.Unmarshal(respBody, &resp)
+				var resp BaseResp
+				err = json.Unmarshal(b.Bytes(), &resp)
 				if err != nil {
 					return err
 				}
@@ -153,7 +153,7 @@ func (d *Open123) Upload(ctx context.Context, file model.FileStreamer, createRes
 					return fmt.Errorf("slice %d upload failed: %s", partNumber, resp.Message)
 				}
 
-				progress := 10.0 + 85.0*float64(threadG.Success())/float64(uploadNums)
+				progress := 100 * float64(threadG.Success()+1) / float64(uploadNums+1)
 				up(progress)
 				return nil
 			},
diff --git a/drivers/123_open/util.go b/drivers/123_open/util.go
index b09d9eb8b..5d961d5c2 100644
--- a/drivers/123_open/util.go
+++ b/drivers/123_open/util.go
@@ -13,7 +13,6 @@ import (
 	"time"
 
 	"github.com/OpenListTeam/OpenList/v4/drivers/base"
-	"github.com/OpenListTeam/OpenList/v4/internal/op"
 	"github.com/go-resty/resty/v2"
 	"github.com/google/uuid"
 	log "github.com/sirupsen/logrus"
@@ -22,8 +21,6 @@ import (
 var ( // ä¸åŒæƒ…å†µä¸‹è·å–çš„AccessTokenQPSé™åˆ¶ä¸åŒ å¦‚ä¸‹æ¨¡å—åŒ–æ˜“äºæ‹“å±•
 	Api = "https://open-api.123pan.com"
 
-	AccessToken    = InitApiInfo(Api+"/api/v1/access_token", 1)
-	RefreshToken   = InitApiInfo(Api+"/api/v1/oauth2/access_token", 1)
 	UserInfo       = InitApiInfo(Api+"/api/v1/user/info", 1)
 	FileList       = InitApiInfo(Api+"/api/v2/file/list", 3)
 	DownloadInfo   = InitApiInfo(Api+"/api/v1/file/download_info", 5)
@@ -40,11 +37,14 @@ var ( // ä¸åŒæƒ…å†µä¸‹è·å–çš„AccessTokenQPSé™åˆ¶ä¸åŒ å¦‚ä¸‹æ¨¡å—åŒ–æ˜“
 )
 
 func (d *Open123) Request(apiInfo *ApiInfo, method string, callback base.ReqCallback, resp interface{}) ([]byte, error) {
-	retryToken := true
 	for {
+		token, err := d.getAccessToken(false)
+		if err != nil {
+			return nil, err
+		}
 		req := base.RestyClient.R()
 		req.SetHeaders(map[string]string{
-			"authorization": "Bearer " + d.AccessToken,
+			"authorization": "Bearer " + token,
 			"platform":      "open_platform",
 			"Content-Type":  "application/json",
 		})
@@ -74,9 +74,9 @@ func (d *Open123) Request(apiInfo *ApiInfo, method string, callback base.ReqCall
 
 		if baseResp.Code == 0 {
 			return body, nil
-		} else if baseResp.Code == 401 && retryToken {
-			retryToken = false
-			if err := d.flushAccessToken(); err != nil {
+		} else if baseResp.Code == 401 {
+			// å¼ºåˆ¶åˆ·æ–°Token, æœ‰å°æ¦‚ç‡ä¼š race condition å¯¼è‡´å¤šæ¬¡åˆ·æ–°Tokenï¼Œä½†ä¸å½±å“æ­£ç¡®è¿è¡Œ
+			if _, err := d.getAccessToken(true); err != nil {
 				return nil, err
 			}
 		} else if baseResp.Code == 429 {
@@ -88,42 +88,6 @@ func (d *Open123) Request(apiInfo *ApiInfo, method string, callback base.ReqCall
 	}
 }
 
-func (d *Open123) flushAccessToken() error {
-	if d.ClientID != "" {
-		if d.RefreshToken != "" {
-			var resp RefreshTokenResp
-			_, err := d.Request(RefreshToken, http.MethodPost, func(req *resty.Request) {
-				req.SetQueryParam("client_id", d.ClientID)
-				if d.ClientSecret != "" {
-					req.SetQueryParam("client_secret", d.ClientSecret)
-				}
-				req.SetQueryParam("grant_type", "refresh_token")
-				req.SetQueryParam("refresh_token", d.RefreshToken)
-			}, &resp)
-			if err != nil {
-				return err
-			}
-			d.AccessToken = resp.AccessToken
-			d.RefreshToken = resp.RefreshToken
-			op.MustSaveDriverStorage(d)
-		} else if d.ClientSecret != "" {
-			var resp AccessTokenResp
-			_, err := d.Request(AccessToken, http.MethodPost, func(req *resty.Request) {
-				req.SetBody(base.Json{
-					"clientID":     d.ClientID,
-					"clientSecret": d.ClientSecret,
-				})
-			}, &resp)
-			if err != nil {
-				return err
-			}
-			d.AccessToken = resp.Data.AccessToken
-			op.MustSaveDriverStorage(d)
-		}
-	}
-	return nil
-}
-
 func (d *Open123) SignURL(originURL, privateKey string, uid uint64, validDuration time.Duration) (newURL string, err error) {
 	// ç”ŸæˆUnixæ—¶é—´æˆ³
 	ts := time.Now().Add(validDuration).Unix()
diff --git a/drivers/139/driver.go b/drivers/139/driver.go
index fbbc7f8e0..88f0d0f46 100644
--- a/drivers/139/driver.go
+++ b/drivers/139/driver.go
@@ -14,6 +14,7 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/driver"
 	"github.com/OpenListTeam/OpenList/v4/internal/errs"
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	"github.com/OpenListTeam/OpenList/v4/internal/op"
 	streamPkg "github.com/OpenListTeam/OpenList/v4/internal/stream"
 	"github.com/OpenListTeam/OpenList/v4/pkg/cron"
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
@@ -28,6 +29,7 @@ type Yun139 struct {
 	Account           string
 	ref               *Yun139
 	PersonalCloudHost string
+	RootPath          string
 }
 
 func (d *Yun139) Config() driver.Config {
@@ -41,7 +43,16 @@ func (d *Yun139) GetAddition() driver.Additional {
 func (d *Yun139) Init(ctx context.Context) error {
 	if d.ref == nil {
 		if len(d.Authorization) == 0 {
-			return fmt.Errorf("authorization is empty")
+			if d.Username != "" && d.Password != "" {
+				log.Infof("139yun: authorization is empty, trying to login with password.")
+				newAuth, err := d.loginWithPassword()
+				log.Debugf("newAuth: Ok: %s", newAuth)
+				if err != nil {
+					return fmt.Errorf("login with password failed: %w", err)
+				}
+			} else {
+				return fmt.Errorf("authorization is empty and username/password is not provided")
+			}
 		}
 		err := d.refreshToken()
 		if err != nil {
@@ -92,7 +103,22 @@ func (d *Yun139) Init(ctx context.Context) error {
 		if len(d.Addition.RootFolderID) == 0 {
 			d.RootFolderID = d.CloudID
 		}
+		_, err := d.groupGetFiles(d.RootFolderID)
+		if err != nil {
+			return err
+		}
 	case MetaFamily:
+		if len(d.Addition.RootFolderID) == 0 {
+			// Attempt to obtain data.path as the root via a query and persist it.
+			if root, err := d.getFamilyRootPath(d.CloudID); err == nil && root != "" {
+				d.RootFolderID = root
+				op.MustSaveDriverStorage(d)
+			}
+		}
+		_, err := d.familyGetFiles(d.RootFolderID)
+		if err != nil {
+			return err
+		}
 	default:
 		return errs.NotImplement
 	}
@@ -279,6 +305,42 @@ func (d *Yun139) Move(ctx context.Context, srcObj, dstDir model.Obj) (model.Obj,
 			return nil, err
 		}
 		return srcObj, nil
+	case MetaFamily:
+		pathname := "/isbo/openApi/createBatchOprTask"
+		var contentList []string
+		var catalogList []string
+		if srcObj.IsDir() {
+			catalogList = append(catalogList, path.Join(srcObj.GetPath(), srcObj.GetID()))
+		} else {
+			contentList = append(contentList, path.Join(srcObj.GetPath(), srcObj.GetID()))
+		}
+
+		body := base.Json{
+			"catalogList": catalogList,
+			"accountInfo": base.Json{
+				"accountName": d.getAccount(),
+				"accountType": "1",
+			},
+			"contentList":   contentList,
+			"destCatalogID": dstDir.GetID(),
+			"destGroupID":   d.CloudID,
+			"destPath":      path.Join(dstDir.GetPath(), dstDir.GetID()),
+			"destType":      0,
+			"srcGroupID":    d.CloudID,
+			"srcType":       0,
+			"taskType":      3,
+		}
+
+		var resp CreateBatchOprTaskResp
+		_, err := d.isboPost(pathname, body, &resp)
+		if err != nil {
+			return nil, err
+		}
+		log.Debugf("[139] Move MetaFamily CreateBatchOprTaskResp.Result.ResultCode: %s", resp.Result.ResultCode)
+		if resp.Result.ResultCode != "0" {
+			return nil, fmt.Errorf("failed to move in family cloud: %s", resp.Result.ResultDesc)
+		}
+		return srcObj, nil
 	default:
 		return nil, errs.NotImplement
 	}
@@ -353,19 +415,27 @@ func (d *Yun139) Rename(ctx context.Context, srcObj model.Obj, newName string) e
 		var data base.Json
 		var pathname string
 		if srcObj.IsDir() {
-			// ç½‘é¡µæ¥å£ä¸æ”¯æŒé‡å‘½åå®¶åº­äº‘æ–‡ä»¶å¤¹
-			// data = base.Json{
-			// 	"catalogType": 3,
-			// 	"catalogID":   srcObj.GetID(),
-			// 	"catalogName": newName,
-			// 	"commonAccountInfo": base.Json{
-			// 		"account":     d.getAccount(),
-			// 		"accountType": 1,
-			// 	},
-			// 	"path": srcObj.GetPath(),
-			// }
-			// pathname = "/orchestration/familyCloud-rebuild/photoContent/v1.0/modifyCatalogInfo"
-			return errs.NotImplement
+			pathname = "/modifyCloudDocV2"
+			data = base.Json{
+				"catalogType": 3,
+				"cloudID":     d.CloudID,
+				"commonAccountInfo": base.Json{
+					"account":     d.getAccount(),
+					"accountType": "1",
+				},
+				"docLibName":   newName,
+				"docLibraryID": srcObj.GetID(),
+				"path":         path.Join(srcObj.GetPath(), srcObj.GetID()),
+			}
+			var resp ModifyCloudDocV2Resp
+			_, err = d.andAlbumRequest(pathname, data, &resp)
+			if err != nil {
+				return err
+			}
+			if resp.Result.ResultCode != "0" {
+				return fmt.Errorf("failed to rename family folder: %s", resp.Result.ResultDesc)
+			}
+			return nil
 		} else {
 			data = base.Json{
 				"contentID":   srcObj.GetID(),
@@ -421,6 +491,33 @@ func (d *Yun139) Copy(ctx context.Context, srcObj, dstDir model.Obj) error {
 		}
 		pathname := "/orchestration/personalCloud/batchOprTask/v1.0/createBatchOprTask"
 		_, err = d.post(pathname, data, nil)
+	case MetaGroup:
+		err = d.handleMetaGroupCopy(ctx, srcObj, dstDir)
+	case MetaFamily:
+		pathname := "/copyContentCatalog"
+		var sourceContentIDs []string
+		var sourceCatalogIDs []string
+		if srcObj.IsDir() {
+			sourceCatalogIDs = append(sourceCatalogIDs, srcObj.GetID())
+		} else {
+			sourceContentIDs = append(sourceContentIDs, srcObj.GetID())
+		}
+
+		body := base.Json{
+			"commonAccountInfo": base.Json{
+				"accountType":   "1",
+				"accountUserId": d.ref.UserDomainID,
+			},
+			"destCatalogID":    dstDir.GetID(),
+			"destCloudID":      d.CloudID,
+			"sourceCatalogIDs": sourceCatalogIDs,
+			"sourceCloudID":    d.CloudID,
+			"sourceContentIDs": sourceContentIDs,
+		}
+
+		var resp base.Json // Assuming a generic JSON response for success/failure
+		_, err = d.andAlbumRequest(pathname, body, &resp)
+		// For now, we assume no error means success.
 	default:
 		err = errs.NotImplement
 	}
@@ -680,6 +777,8 @@ func (d *Yun139) Put(ctx context.Context, dstDir model.Obj, stream model.FileStr
 		return nil
 	case MetaPersonal:
 		fallthrough
+	case MetaGroup:
+		fallthrough
 	case MetaFamily:
 		// å¤„ç†å†²çª
 		// è·å–æ–‡ä»¶åˆ—è¡¨
@@ -727,12 +826,17 @@ func (d *Yun139) Put(ctx context.Context, dstDir model.Obj, stream model.FileStr
 			},
 		}
 		pathname := "/orchestration/personalCloud/uploadAndDownload/v1.0/pcUploadFileRequest"
-		if d.isFamily() {
+		if d.isFamily() || d.Addition.Type == MetaGroup {
+			uploadPath := path.Join(dstDir.GetPath(), dstDir.GetID())
+			// if dstDir is root folder
+			if dstDir.GetID() == d.RootFolderID {
+				uploadPath = d.RootPath
+			}
 			data = d.newJson(base.Json{
 				"fileCount":    1,
 				"manualRename": 2,
 				"operation":    0,
-				"path":         path.Join(dstDir.GetPath(), dstDir.GetID()),
+				"path":         uploadPath,
 				"seqNo":        random.String(32), // åºåˆ—å·ä¸èƒ½ä¸ºç©º
 				"totalSize":    reportSize,
 				"uploadContentList": []base.Json{{
@@ -744,6 +848,7 @@ func (d *Yun139) Put(ctx context.Context, dstDir model.Obj, stream model.FileStr
 			pathname = "/orchestration/familyCloud-rebuild/content/v1.0/getFileUploadURL"
 		}
 		var resp UploadResp
+		log.Debugf("[139] upload request body: %+v", data)
 		_, err = d.post(pathname, data, &resp)
 		if err != nil {
 			return err
@@ -839,7 +944,7 @@ func (d *Yun139) GetDetails(ctx context.Context) (*model.StorageDetails, error)
 	if d.UserDomainID == "" {
 		return nil, errs.NotImplement
 	}
-	var total, free uint64
+	var total, used uint64
 	if d.isFamily() {
 		diskInfo, err := d.getFamilyDiskInfo(ctx)
 		if err != nil {
@@ -854,7 +959,7 @@ func (d *Yun139) GetDetails(ctx context.Context) (*model.StorageDetails, error)
 			return nil, fmt.Errorf("failed convert used size into integer: %+v", err)
 		}
 		total = totalMb * 1024 * 1024
-		free = total - (usedMb * 1024 * 1024)
+		used = usedMb * 1024 * 1024
 	} else {
 		diskInfo, err := d.getPersonalDiskInfo(ctx)
 		if err != nil {
@@ -869,13 +974,10 @@ func (d *Yun139) GetDetails(ctx context.Context) (*model.StorageDetails, error)
 			return nil, fmt.Errorf("failed convert free size into integer: %+v", err)
 		}
 		total = totalMb * 1024 * 1024
-		free = freeMb * 1024 * 1024
+		used = total - (freeMb * 1024 * 1024)
 	}
 	return &model.StorageDetails{
-		DiskUsage: model.DiskUsage{
-			TotalSpace: total,
-			FreeSpace:  free,
-		},
+		DiskUsage: driver.DiskUsageFromUsedAndTotal(used, total),
 	}, nil
 }
 
diff --git a/drivers/139/meta.go b/drivers/139/meta.go
index b226e240f..91d54fd30 100644
--- a/drivers/139/meta.go
+++ b/drivers/139/meta.go
@@ -8,6 +8,9 @@ import (
 type Addition struct {
 	//Account       string `json:"account" required:"true"`
 	Authorization string `json:"authorization" type:"text" required:"true"`
+	Username      string `json:"username" required:"true"`
+	Password      string `json:"password" required:"true" secret:"true"`
+	MailCookies   string `json:"mail_cookies" required:"true" type:"text" help:"Cookies from mail.139.com used for login authentication."`
 	driver.RootID
 	Type                 string `json:"type" type:"select" options:"personal_new,family,group,personal" default:"personal_new"`
 	CloudID              string `json:"cloud_id"`
diff --git a/drivers/139/types.go b/drivers/139/types.go
index 118655deb..499cdbc4d 100644
--- a/drivers/139/types.go
+++ b/drivers/139/types.go
@@ -329,3 +329,62 @@ type FamilyDiskInfoResp struct {
 		DiskSize string `json:"diskSize"`
 	} `json:"data"`
 }
+
+type AndAlbumUploadResp struct {
+	Result struct {
+		ResultCode string `json:"resultCode"`
+		ResultDesc string `json:"resultDesc"`
+	} `json:"result"`
+	UploadResult struct {
+		UploadTaskID     string `json:"uploadTaskID"`
+		RedirectionURL   string `json:"redirectionUrl"`
+		NewContentIDList []struct {
+			ContentID   string `json:"contentID"`
+			ContentName string `json:"contentName"`
+		} `json:"newContentIDList"`
+	} `json:"uploadResult"`
+}
+
+type ModifyCloudDocV2Req struct {
+	CatalogType       int    `json:"catalogType"`
+	CloudID           string `json:"cloudID"`
+	CommonAccountInfo struct {
+		Account     string `json:"account"`
+		AccountType string `json:"accountType"`
+	} `json:"commonAccountInfo"`
+	DocLibName   string `json:"docLibName"`
+	DocLibraryID string `json:"docLibraryID"`
+	Path         string `json:"path"`
+}
+
+type ModifyCloudDocV2Resp struct {
+	Result struct {
+		ResultCode string `json:"resultCode"`
+		ResultDesc string `json:"resultDesc"`
+	} `json:"result"`
+}
+
+type CreateBatchOprTaskReq struct {
+	CatalogList       []string `json:"catalogList"`
+	CommonAccountInfo struct {
+		Account     string `json:"account"`
+		AccountType string `json:"accountType"`
+	} `json:"commonAccountInfo"`
+	ContentList       []string `json:"contentList"`
+	DestCatalogID     string   `json:"destCatalogID"`
+	DestGroupID       string   `json:"destGroupID"`
+	DestPath          string   `json:"destPath"`
+	DestType          int      `json:"destType"`
+	SourceCatalogType int      `json:"sourceCatalogType"`
+	SourceCloudID     string   `json:"sourceCloudID"`
+	SourceType        int      `json:"sourceType"`
+	TaskType          int      `json:"taskType"`
+}
+
+type CreateBatchOprTaskResp struct {
+	Result struct {
+		ResultCode string `json:"resultCode"`
+		ResultDesc string `json:"resultDesc"`
+	} `json:"result"`
+	TaskID string `json:"taskID"`
+}
diff --git a/drivers/139/util.go b/drivers/139/util.go
index 9a9d2c6d0..2c7ac242d 100644
--- a/drivers/139/util.go
+++ b/drivers/139/util.go
@@ -1,14 +1,22 @@
 package _139
 
 import (
+	"bytes"
 	"context"
+	"crypto/aes"
+	"crypto/cipher"
+	"crypto/md5"
+	crypto_rand "crypto/rand"
+	"crypto/sha1"
 	"encoding/base64"
+	"encoding/hex"
 	"errors"
 	"fmt"
 	"io"
 	"net/http"
 	"net/url"
 	"path"
+	"regexp"
 	"sort"
 	"strconv"
 	"strings"
@@ -25,6 +33,11 @@ import (
 	log "github.com/sirupsen/logrus"
 )
 
+const (
+	KEY_HEX_1 = "73634235495062495331515373756c734e7253306c673d3d" // ç¬¬ä¸€å±‚ AES è§£å¯†å¯†é’¥
+	KEY_HEX_2 = "7150714477323633586746674c337538"                 // ç¬¬äºŒå±‚ AES è§£å¯†å¯†é’¥
+)
+
 // do others that not defined in Driver interface
 func (d *Yun139) isFamily() bool {
 	return d.Type == "family"
@@ -96,12 +109,16 @@ func (d *Yun139) refreshToken() error {
 		SetBody(reqBody).
 		SetResult(&resp).
 		Post(url)
-	if err != nil {
-		return err
-	}
-	if resp.Return != "0" {
-		return fmt.Errorf("failed to refresh token: %s", resp.Desc)
+	if err != nil || resp.Return != "0" {
+		log.Warnf("139yun: failed to refresh token with old token: %v, desc: %s. trying to login with password.", err, resp.Desc)
+		newAuth, loginErr := d.loginWithPassword()
+		log.Debugf("newAuth: Ok: %s", newAuth)
+		if loginErr != nil {
+			return fmt.Errorf("failed to login with password after refresh failed: %w", loginErr)
+		}
+		return nil
 	}
+
 	d.Authorization = base64.StdEncoding.EncodeToString([]byte(splits[0] + ":" + splits[1] + ":" + resp.Token))
 	op.MustSaveDriverStorage(d)
 	return nil
@@ -146,10 +163,29 @@ func (d *Yun139) request(url string, method string, callback base.ReqCallback, r
 
 	var e BaseResp
 	req.SetResult(&e)
+	log.Debugf("[139] request: %s %s, body: %s", method, url, string(body))
 	res, err := req.Execute(method, url)
-	log.Debugln(res.String())
+	if err != nil {
+		log.Debugf("[139] request error: %v", err)
+		return nil, err
+	}
+	log.Debugf("[139] response body: %s", res.String())
 	if !e.Success {
-		return nil, errors.New(e.Message)
+		// Always try to unmarshal to the specific response type first if 'resp' is provided.
+		if resp != nil {
+			err = utils.Json.Unmarshal(res.Body(), resp)
+			if err != nil {
+				log.Debugf("[139] failed to unmarshal response to specific type: %v", err)
+				return nil, err // Return unmarshal error
+			}
+			if createBatchOprTaskResp, ok := resp.(*CreateBatchOprTaskResp); ok {
+				log.Debugf("[139] CreateBatchOprTaskResp.Result.ResultCode: %s", createBatchOprTaskResp.Result.ResultCode)
+				if createBatchOprTaskResp.Result.ResultCode == "0" {
+					goto SUCCESS_PROCESS
+				}
+			}
+		}
+		return nil, errors.New(e.Message) // Fallback to original error if not handled
 	}
 	if resp != nil {
 		err = utils.Json.Unmarshal(res.Body(), resp)
@@ -157,6 +193,7 @@ func (d *Yun139) request(url string, method string, callback base.ReqCallback, r
 			return nil, err
 		}
 	}
+SUCCESS_PROCESS:
 	return res.Body(), nil
 }
 
@@ -311,6 +348,9 @@ func (d *Yun139) familyGetFiles(catalogID string) ([]model.Obj, error) {
 			return nil, err
 		}
 		path := resp.Data.Path
+		if catalogID == d.RootFolderID {
+			d.RootPath = path
+		}
 		for _, catalog := range resp.Data.CloudCatalogList {
 			f := model.Object{
 				ID:       catalog.CatalogID,
@@ -366,6 +406,9 @@ func (d *Yun139) groupGetFiles(catalogID string) ([]model.Obj, error) {
 			return nil, err
 		}
 		path := resp.Data.GetGroupContentResult.ParentCatalogID
+		if catalogID == d.RootFolderID {
+			d.RootPath = path
+		}
 		for _, catalog := range resp.Data.GetGroupContentResult.CatalogList {
 			f := model.Object{
 				ID:       catalog.CatalogID,
@@ -494,11 +537,13 @@ func (d *Yun139) personalRequest(pathname string, method string, callback base.R
 
 	var e BaseResp
 	req.SetResult(&e)
+	log.Debugf("[139] personal request: %s %s, body: %s", method, url, string(body))
 	res, err := req.Execute(method, url)
 	if err != nil {
+		log.Debugf("[139] personal request error: %v", err)
 		return nil, err
 	}
-	log.Debugln(res.String())
+	log.Debugf("[139] personal response body: %s", res.String())
 	if !e.Success {
 		return nil, errors.New(e.Message)
 	}
@@ -517,6 +562,13 @@ func (d *Yun139) personalPost(pathname string, data interface{}, resp interface{
 	}, resp)
 }
 
+func (d *Yun139) isboPost(pathname string, data interface{}, resp interface{}) ([]byte, error) {
+	url := "https://group.yun.139.com/hcy/mutual/adapter" + pathname
+	return d.request(url, http.MethodPost, func(req *resty.Request) {
+		req.SetBody(data)
+	}, resp)
+}
+
 func getPersonalTime(t string) time.Time {
 	stamp, err := time.ParseInLocation("2006-01-02T15:04:05.999-07:00", t, utils.CNLoc)
 	if err != nil {
@@ -703,3 +755,645 @@ func (d *Yun139) getFamilyDiskInfo(ctx context.Context) (*FamilyDiskInfoResp, er
 	}
 	return &resp, nil
 }
+
+func getMd5(dataStr string) string {
+	hash := md5.Sum([]byte(dataStr))
+	return fmt.Sprintf("%x", hash)
+}
+
+func (d *Yun139) step1_password_login() (string, error) {
+	log.Debugf("--- æ‰§è¡Œæ­¥éª¤ 1: ç™»å½• API ---")
+	loginURL := "https://mail.10086.cn/Login/Login.ashx"
+
+	// å¯†ç  SHA1 å“ˆå¸Œ
+	hashedPassword := sha1Hash(fmt.Sprintf("fetion.com.cn:%s", d.Password))
+	log.Debugf("DEBUG: åŸå§‹å¯†ç : %s", d.Password)
+	log.Debugf("DEBUG: SHA1 è¾“å…¥: fetion.com.cn:%s", d.Password)
+	log.Debugf("DEBUG: ç”Ÿæˆçš„ Password å“ˆå¸Œ: %s", hashedPassword)
+
+	cguid := strconv.FormatInt(time.Now().UnixMilli(), 10) // éšæœºç”Ÿæˆ cguid
+
+	loginHeaders := map[string]string{
+		"accept":                    "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
+		"accept-language":           "zh-CN,zh;q=0.9,zh-TW;q=0.8,en-US;q=0.7,en;q=0.6,en-GB;q=0.5",
+		"cache-control":             "max-age=0",
+		"content-type":              "application/x-www-form-urlencoded",
+		"dnt":                       "1",
+		"origin":                    "https://mail.10086.cn",
+		"priority":                  "u=0, i",
+		"referer":                   fmt.Sprintf("https://mail.10086.cn/default.html?&s=1&v=0&u=%s&m=1&ec=S001&resource=indexLogin&clientid=1003&auto=on&cguid=%s&mtime=45", base64.StdEncoding.EncodeToString([]byte(d.Username)), cguid),
+		"sec-ch-ua":                 "\"Microsoft Edge\";v=\"141\", \"Not?A_Brand\";v=\"8\", \"Chromium\";v=\"141\"",
+		"sec-ch-ua-mobile":          "?0",
+		"sec-ch-ua-platform":        "\"Windows\"",
+		"sec-fetch-dest":            "document",
+		"sec-fetch-mode":            "navigate",
+		"sec-fetch-site":            "same-origin",
+		"sec-fetch-user":            "?1",
+		"upgrade-insecure-requests": "1",
+		"user-agent":                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36 Edg/141.0.0.0",
+		"Cookie":                    d.MailCookies,
+	}
+
+	loginData := url.Values{}
+	loginData.Set("UserName", d.Username)
+	loginData.Set("passOld", "")
+	loginData.Set("auto", "on")
+	loginData.Set("Password", hashedPassword)
+	loginData.Set("webIndexPagePwdLogin", "1")
+	loginData.Set("pwdType", "1")
+	loginData.Set("clientId", "1003")
+	loginData.Set("authType", "2")
+
+	log.Debugf("DEBUG: ç™»å½•è¯·æ±‚ URL: %s", loginURL)
+	log.Debugf("DEBUG: ç™»å½•è¯·æ±‚ Headers: %+v", loginHeaders)
+	log.Debugf("DEBUG: ç™»å½•è¯·æ±‚ Body: %s", loginData.Encode())
+
+	// è®¾ç½®å®¢æˆ·ç«¯ä¸è·Ÿéšé‡å®šå‘
+	client := base.RestyClient.SetRedirectPolicy(resty.NoRedirectPolicy())
+	res, err := client.R().
+		SetHeaders(loginHeaders).
+		SetFormDataFromValues(loginData).
+		Post(loginURL)
+
+	if err != nil {
+		// å¦‚æœæ˜¯é‡å®šå‘é”™è¯¯ï¼Œåˆ™ä¸ä½œä¸ºå¤±è´¥å¤„ç†ï¼Œå› ä¸ºæˆ‘ä»¬ç¦æ­¢äº†è‡ªåŠ¨é‡å®šå‘
+		if res != nil && res.StatusCode() >= 300 && res.StatusCode() < 400 {
+			log.Debugf("DEBUG: ç™»å½•å“åº” Status Code: %d (Redirect)", res.StatusCode())
+		} else {
+			return "", fmt.Errorf("step1 login request failed: %w", err)
+		}
+	} else {
+		log.Debugf("DEBUG: ç™»å½•å“åº” Status Code: %d", res.StatusCode())
+	}
+	// æ¢å¤å®¢æˆ·ç«¯çš„é»˜è®¤é‡å®šå‘ç­–ç•¥ï¼Œä»¥å…å½±å“åç»­è¯·æ±‚
+	base.RestyClient.SetRedirectPolicy(resty.FlexibleRedirectPolicy(10))
+	log.Debugf("DEBUG: ç™»å½•å“åº” Headers: %+v", res.Header())
+
+	var sid, extractedCguid string
+
+	// ä» Location å¤´éƒ¨æå– sid å’Œ cguid
+	locationHeader := res.Header().Get("Location")
+	if locationHeader != "" {
+		sidMatch := regexp.MustCompile(`sid=([^&]+)`).FindStringSubmatch(locationHeader)
+		cguidMatch := regexp.MustCompile(`cguid=([^&]+)`).FindStringSubmatch(locationHeader)
+		if len(sidMatch) > 1 {
+			sid = sidMatch[1]
+			log.Debugf("DEBUG: ä» Location æå–åˆ° sid: %s", sid)
+		}
+		if len(cguidMatch) > 1 {
+			extractedCguid = cguidMatch[1]
+			log.Debugf("DEBUG: ä» Location æå–åˆ° cguid: %s", extractedCguid)
+		}
+	}
+
+	// å¦‚æœ Location ä¸­æ²¡æœ‰ï¼Œå°è¯•ä» Set-Cookie ä¸­æå–
+	if sid == "" || extractedCguid == "" {
+		setCookieHeaders := res.Header().Values("Set-Cookie")
+		for _, cookieStr := range setCookieHeaders {
+			ssoSidMatch := regexp.MustCompile(`Os_SSo_Sid=([^;]+)`).FindStringSubmatch(cookieStr)
+			cookieCguidMatch := regexp.MustCompile(`cguid=([^;]+)`).FindStringSubmatch(cookieStr)
+			if len(ssoSidMatch) > 1 && sid == "" {
+				sid = ssoSidMatch[1]
+				log.Debugf("DEBUG: ä» Set-Cookie æå–åˆ° sid: %s", sid)
+			}
+			if len(cookieCguidMatch) > 1 && extractedCguid == "" {
+				extractedCguid = cookieCguidMatch[1]
+				log.Debugf("DEBUG: ä» Set-Cookie æå–åˆ° cguid: %s", extractedCguid)
+			}
+		}
+	}
+
+	if sid == "" || extractedCguid == "" {
+		return "", errors.New("failed to extract sid or cguid from login response")
+	}
+
+	// æå–å¹¶è®°å½• cookies
+	loginUrlObj, _ := url.Parse(loginURL)
+	cookies := base.RestyClient.GetClient().Jar.Cookies(loginUrlObj)
+	var cookieStrings []string
+	for _, cookie := range cookies {
+		cookieStrings = append(cookieStrings, cookie.Name+"="+cookie.Value)
+	}
+	cookieStr := strings.Join(cookieStrings, "; ")
+	log.Debugf("DEBUG: æå–åˆ°çš„ Cookies: %s", cookieStr)
+	d.MailCookies = cookieStr
+
+	return sid, nil
+}
+
+func (d *Yun139) step2_get_single_token(sid string) (string, error) {
+	log.Debugf("\n--- æ‰§è¡Œæ­¥éª¤ 2: æ¢artifact API ---")
+	cguid := strconv.FormatInt(time.Now().UnixMilli(), 10)
+
+	exchangeArtifactURL := fmt.Sprintf("https://smsrebuild1.mail.10086.cn/setting/s?func=%s&sid=%s&cguid=%s", url.QueryEscape("umc:getArtifact"), sid, cguid)
+
+	// ä» MailCookies ä¸­æå– RMKEY
+	var rmkey string
+	cookies := strings.Split(d.MailCookies, ";")
+	for _, cookie := range cookies {
+		cookie = strings.TrimSpace(cookie)
+		if strings.HasPrefix(cookie, "RMKEY=") {
+			rmkey = cookie
+			break
+		}
+	}
+	if rmkey == "" {
+		return "", errors.New("RMKEY not found in MailCookies")
+	}
+
+	exchangePassidHeaders := map[string]string{
+		"Host":            "smsrebuild1.mail.10086.cn",
+		"Cookie":          rmkey,
+		"Content-Type":    "text/xml; charset=utf-8",
+		"Accept-Encoding": "gzip",
+		"User-Agent":      "okhttp/4.12.0",
+	}
+
+	log.Debugf("DEBUG: æ¢passid è¯·æ±‚ URL: %s", exchangeArtifactURL)
+	log.Debugf("DEBUG: æ¢passid è¯·æ±‚ Headers: %+v", exchangePassidHeaders)
+
+	res, err := base.RestyClient.R().
+		SetHeaders(exchangePassidHeaders).
+		Post(exchangeArtifactURL)
+
+	if err != nil {
+		return "", fmt.Errorf("step2 exchange artifact request failed: %w", err)
+	}
+
+	log.Debugf("DEBUG: æ¢passid å“åº” Status Code: %d", res.StatusCode())
+	log.Debugf("DEBUG: æ¢passid å“åº” Headers: %+v", res.Header())
+	log.Debugf("DEBUG: æ¢passid å“åº” Body: %s...", res.String()[:min(len(res.String()), 500)])
+
+	dycpwd := jsoniter.Get(res.Body(), "var", "artifact").ToString()
+	if dycpwd == "" {
+		return "", errors.New("failed to extract dycpwd from artifact exchange response")
+	}
+	log.Debugf("DEBUG: æå–åˆ° dycpwd: %s", dycpwd)
+
+	return dycpwd, nil
+}
+
+// --- è¾…åŠ©å‡½æ•°ï¼šåŠ å¯†/è§£å¯† ---
+
+// sha1Hash è®¡ç®— SHA1 å“ˆå¸Œå€¼ï¼Œè¿”å›åå…­è¿›åˆ¶å­—ç¬¦ä¸²ã€‚
+func sha1Hash(data string) string {
+	h := sha1.New()
+	h.Write([]byte(data))
+	return hex.EncodeToString(h.Sum(nil))
+}
+
+// pkcs7_pad PKCS7 å¡«å……
+func pkcs7_pad(data []byte, blockSize int) []byte {
+	padding := blockSize - len(data)%blockSize
+	padtext := bytes.Repeat([]byte{byte(padding)}, padding)
+	return append(data, padtext...)
+}
+
+// pkcs7_unpad PKCS7 å»å¡«å……
+func pkcs7_unpad(data []byte) ([]byte, error) {
+	length := len(data)
+	if length == 0 {
+		return nil, errors.New("pkcs7: data is empty")
+	}
+	unpadding := int(data[length-1])
+	if unpadding > length {
+		return nil, errors.New("pkcs7: invalid padding")
+	}
+	return data[:(length - unpadding)], nil
+}
+
+// aes_ecb_decrypt AES/ECB/Pkcs7 è§£å¯†ï¼Œè¾“å…¥ä¸ºåå…­è¿›åˆ¶å­—ç¬¦ä¸²ã€‚
+func aes_ecb_decrypt(ciphertext []byte, key []byte) ([]byte, error) {
+	block, err := aes.NewCipher(key)
+	if err != nil {
+		return nil, err
+	}
+
+	if len(ciphertext)%block.BlockSize() != 0 {
+		return nil, errors.New("AES ECB decrypt: ciphertext is not a multiple of the block size")
+	}
+
+	decrypted := make([]byte, len(ciphertext))
+	blockSize := block.BlockSize()
+
+	for bs, be := 0, blockSize; bs < len(ciphertext); bs, be = bs+blockSize, be+blockSize {
+		block.Decrypt(decrypted[bs:be], ciphertext[bs:be])
+	}
+
+	return pkcs7_unpad(decrypted)
+}
+
+// ä»¥ä¸‹æä¾› camelCase çš„ AES CBC åŠ è§£å¯†ï¼Œä¾›æ–‡ä»¶ä¸­å…¶å®ƒä½ç½®è°ƒç”¨ï¼ˆå¹¶æ”¯æŒä¼ å…¥ IVï¼‰ã€‚
+func aesCbcEncrypt(plaintext []byte, key []byte, iv []byte) ([]byte, error) {
+	block, err := aes.NewCipher(key)
+	if err != nil {
+		return nil, err
+	}
+	if len(iv) != block.BlockSize() {
+		return nil, fmt.Errorf("aesCbcEncrypt: iv length %d does not match block size %d", len(iv), block.BlockSize())
+	}
+	padded := pkcs7_pad(plaintext, block.BlockSize())
+	ciphertext := make([]byte, len(padded))
+	mode := cipher.NewCBCEncrypter(block, iv)
+	mode.CryptBlocks(ciphertext, padded)
+	return ciphertext, nil
+}
+
+func aesCbcDecrypt(ciphertext []byte, key []byte, iv []byte) ([]byte, error) {
+	block, err := aes.NewCipher(key)
+	if err != nil {
+		return nil, err
+	}
+	if len(iv) != block.BlockSize() {
+		return nil, fmt.Errorf("aesCbcDecrypt: iv length %d does not match block size %d", len(iv), block.BlockSize())
+	}
+	if len(ciphertext)%block.BlockSize() != 0 {
+		return nil, errors.New("aesCbcDecrypt: ciphertext is not a multiple of the block size")
+	}
+	decrypted := make([]byte, len(ciphertext))
+	mode := cipher.NewCBCDecrypter(block, iv)
+	mode.CryptBlocks(decrypted, ciphertext)
+	return pkcs7_unpad(decrypted)
+}
+
+// sortedJsonStringify å¯¹ JSON å¯¹è±¡è¿›è¡Œæ’åºå¹¶å­—ç¬¦ä¸²åŒ–ã€‚
+func sortedJsonStringify(obj interface{}) (string, error) {
+	if obj == nil {
+		return "null", nil
+	}
+
+	switch v := obj.(type) {
+	case string:
+		// å°è¯•è§£æä¸º JSONï¼Œå¦‚æœæˆåŠŸåˆ™é€’å½’å¤„ç†
+		var parsed interface{}
+		if err := jsoniter.Unmarshal([]byte(v), &parsed); err == nil {
+			return sortedJsonStringify(parsed)
+		}
+		// å¦‚æœä¸æ˜¯ JSON å­—ç¬¦ä¸²ï¼Œåˆ™ç›´æ¥è¿”å› JSON å­—ç¬¦ä¸²åŒ–çš„ç»“æœ
+		return jsoniter.MarshalToString(v)
+	case int, float64, bool:
+		return fmt.Sprintf("%v", v), nil
+	case []interface{}:
+		var items []string
+		for _, item := range v {
+			s, err := sortedJsonStringify(item)
+			if err != nil {
+				return "", err
+			}
+			items = append(items, s)
+		}
+		return fmt.Sprintf("[%s]", strings.Join(items, ",")), nil
+	case map[string]interface{}:
+		sortedKeys := make([]string, 0, len(v))
+		for key := range v {
+			sortedKeys = append(sortedKeys, key)
+		}
+		sort.Strings(sortedKeys)
+
+		var pairs []string
+		for _, key := range sortedKeys {
+			value := v[key]
+			s, err := sortedJsonStringify(value)
+			if err != nil {
+				return "", err
+			}
+			// Use jsoniter.MarshalToString for the key to ensure it's quoted correctly
+			keyStr, err := jsoniter.MarshalToString(key)
+			if err != nil {
+				return "", err
+			}
+			pairs = append(pairs, fmt.Sprintf("%s:%s", keyStr, s))
+		}
+		return fmt.Sprintf("{%s}", strings.Join(pairs, ",")), nil
+	default:
+		// Fallback for other types, e.g., numbers, booleans, or unhandled complex types
+		// Use jsoniter's default marshalling for these
+		return jsoniter.MarshalToString(v)
+	}
+}
+
+// yun139EncryptedRequest handles the common encrypted request/response flow.
+func (d *Yun139) yun139EncryptedRequest(url string, body interface{}, headers map[string]string, aesKeyHex string, resp interface{}) ([]byte, error) {
+	// 1. Decode AES key
+	aesKey, err := hex.DecodeString(aesKeyHex)
+	if err != nil {
+		return nil, fmt.Errorf("yun139EncryptedRequest: failed to decode AES key: %w", err)
+	}
+
+	// 2. Marshal and sort the request body
+	sortedJson, err := sortedJsonStringify(body)
+	if err != nil {
+		return nil, fmt.Errorf("yun139EncryptedRequest: failed to marshal and sort body: %w", err)
+	}
+	log.Debugf("yun139EncryptedRequest: Request Body (plaintext): %s", sortedJson)
+
+	// 3. Encrypt the body using AES/CBC
+	iv := make([]byte, 16) // 16 bytes for AES-128
+	if _, err := crypto_rand.Read(iv); err != nil {
+		return nil, fmt.Errorf("yun139EncryptedRequest: failed to generate IV: %w", err)
+	}
+	encryptedBody, err := aesCbcEncrypt([]byte(sortedJson), aesKey, iv)
+	if err != nil {
+		return nil, fmt.Errorf("yun139EncryptedRequest: failed to encrypt body: %w", err)
+	}
+	payload := base64.StdEncoding.EncodeToString(append(iv, encryptedBody...))
+
+	// 4. Make the request
+	res, err := base.RestyClient.R().
+		SetHeaders(headers).
+		SetBody(payload).
+		Post(url)
+
+	if err != nil {
+		return nil, fmt.Errorf("yun139EncryptedRequest: http request failed: %w", err)
+	}
+
+	if res.StatusCode() != 200 {
+		return nil, fmt.Errorf("yun139EncryptedRequest: unexpected status code %d: %s", res.StatusCode(), res.String())
+	}
+
+	// 5. Decrypt the response
+	respBody := res.Body()
+	var decryptedBytes []byte
+
+	if len(respBody) > 0 && respBody[0] == '{' {
+		log.Warnf("yun139EncryptedRequest: received a plain JSON response, not an encrypted string. Body: %s", string(respBody))
+		decryptedBytes = respBody
+	} else {
+		decodedResp, err := base64.StdEncoding.DecodeString(string(respBody))
+		if err != nil {
+			return nil, fmt.Errorf("yun139EncryptedRequest: response base64 decode failed: %w. Body: '%s'", err, string(respBody))
+		}
+
+		if len(decodedResp) < 16 {
+			return nil, fmt.Errorf("yun139EncryptedRequest: decoded response is too short to be encrypted. Length: %d", len(decodedResp))
+		}
+
+		respIv := decodedResp[:16]
+		respCiphertext := decodedResp[16:]
+
+		decryptedBytes, err = aesCbcDecrypt(respCiphertext, aesKey, respIv)
+		if err != nil {
+			return nil, fmt.Errorf("yun139EncryptedRequest: response aes decrypt failed: %w", err)
+		}
+	}
+
+	log.Debugf("yun139EncryptedRequest: Response Body (decrypted): %s", string(decryptedBytes))
+
+	// 6. Unmarshal to the final response struct
+	if resp != nil {
+		err = utils.Json.Unmarshal(decryptedBytes, resp)
+		if err != nil {
+			return nil, fmt.Errorf("yun139EncryptedRequest: failed to unmarshal decrypted response: %w", err)
+		}
+	}
+
+	return decryptedBytes, nil
+}
+
+func (d *Yun139) step3_third_party_login(dycpwd string) (string, error) {
+	log.Debugf("\n--- æ‰§è¡Œæ­¥éª¤ 3: å•ç‚¹ç™»å½• API ---")
+	ssoLoginURL := "https://user-njs.yun.139.com/user/thirdlogin"
+
+	// æ„å»ºåŸå§‹è¯·æ±‚ä½“
+	ssoRequestBodyRaw := base.Json{
+		"clientkey_decrypt": "l3TryM&Q+X7@dzwk)qP",
+		"clienttype":        "886",
+		"cpid":              "507",
+		"dycpwd":            dycpwd,
+		"extInfo":           base.Json{"ifOpenAccount": "0"},
+		"loginMode":         "0",
+		"msisdn":            d.Username,
+		"pintype":           "13",
+		"secinfo":           strings.ToUpper(sha1Hash(fmt.Sprintf("fetion.com.cn:%s", dycpwd))),
+		"version":           "20250901",
+	}
+
+	ssoLoginHeaders := map[string]string{
+		"hcy-cool-flag":       "1",
+		"x-huawei-channelSrc": "10246600",
+		"x-sdk-channelSrc":    "",
+		"x-MM-Source":         "0",
+		"x-UserAgent":         "android|23116PN5BC|android15|1.2.6|||1440x3200|10246600",
+		"x-DeviceInfo":        "4|127.0.0.1|5|1.2.6|Xiaomi|23116PN5BC||02-00-00-00-00-00|android 15|1440x3200|android|||",
+		"Content-Type":        "text/plain;charset=UTF-8",
+		"Host":                "user-njs.yun.139.com",
+		"Connection":          "Keep-Alive",
+		"Accept-Encoding":     "gzip",
+		"User-Agent":          "okhttp/3.12.2",
+	}
+
+	// ä½¿ç”¨é€šç”¨åŠ å¯†è¯·æ±‚å‡½æ•°
+	decryptedLayer1StrBytes, err := d.yun139EncryptedRequest(ssoLoginURL, ssoRequestBodyRaw, ssoLoginHeaders, KEY_HEX_1, nil)
+	if err != nil {
+		return "", fmt.Errorf("step3 encrypted request failed: %w", err)
+	}
+
+	hexInner := jsoniter.Get(decryptedLayer1StrBytes, "data").ToString()
+	if hexInner == "" {
+		return "", errors.New("missing data field in first layer decryption result")
+	}
+	log.Debugf("DEBUG: ç¬¬ä¸€å±‚è§£å¯†æå–åˆ° hex_inner: %s...", hexInner[:min(len(hexInner), 50)])
+
+	// ç¬¬äºŒå±‚è§£å¯†
+	key2, err := hex.DecodeString(KEY_HEX_2)
+	if err != nil {
+		return "", fmt.Errorf("failed to decode KEY_HEX_2: %w", err)
+	}
+	hexInnerBytes, err := hex.DecodeString(hexInner)
+	if err != nil {
+		return "", fmt.Errorf("failed to decode hex_inner: %w", err)
+	}
+	finalJsonStrBytes, err := aes_ecb_decrypt(hexInnerBytes, key2)
+	if err != nil {
+		return "", fmt.Errorf("step3 response layer2 aes ecb decrypt failed: %w", err)
+	}
+	log.Debugf("DEBUG: æœ€ç»ˆè§£å¯†ç»“æœ: %s", string(finalJsonStrBytes))
+
+	// æå– authToken
+	authToken := jsoniter.Get(finalJsonStrBytes, "authToken").ToString()
+	if authToken == "" {
+		return "", errors.New("failed to extract authToken from final decryption result")
+	}
+	log.Debugf("DEBUG: æå–åˆ° authToken: %s", authToken)
+
+	// æå– account å’Œ userDomainId
+	account := jsoniter.Get(finalJsonStrBytes, "account").ToString()
+	userDomainId := jsoniter.Get(finalJsonStrBytes, "userDomainId").ToString()
+
+	if account == "" || userDomainId == "" {
+		return "", errors.New("failed to extract account or userDomainId from final decryption result")
+	}
+
+	d.UserDomainID = userDomainId
+	newAuthorization := base64.StdEncoding.EncodeToString([]byte(fmt.Sprintf("pc:%s:%s", account, authToken)))
+	return newAuthorization, nil
+}
+
+func (d *Yun139) loginWithPassword() (string, error) {
+	if d.Username == "" || d.Password == "" || d.MailCookies == "" {
+		return "", errors.New("username, password or mail_cookies is empty")
+	}
+
+	passId, err := d.step1_password_login()
+	if err != nil {
+		return "", err
+	}
+	log.Infof("Step 1 success, passId: %s", passId)
+
+	token, err := d.step2_get_single_token(passId)
+	if err != nil {
+		return "", err
+	}
+	log.Infof("Step 2 success, token: %s", token)
+
+	newAuth, err := d.step3_third_party_login(token)
+	if err != nil {
+		return "", err
+	}
+	log.Infof("Step 3 success, new authorization generated.")
+
+	d.Authorization = newAuth // Ensure Authorization is also updated before saving
+	op.MustSaveDriverStorage(d)
+	return newAuth, nil
+}
+
+func (d *Yun139) andAlbumRequest(pathname string, body interface{}, resp interface{}) ([]byte, error) {
+	url := "https://group.yun.139.com/hcy/family/adapter/andAlbum/openApi" + pathname
+
+	headers := map[string]string{
+		"Host":                "group.yun.139.com",
+		"authorization":       "Basic " + d.getAuthorization(),
+		"x-svctype":           "2",
+		"hcy-cool-flag":       "1",
+		"api-version":         "v2",
+		"x-huawei-channelsrc": "10246600",
+		"x-sdk-channelsrc":    "",
+		"x-mm-source":         "0",
+		"x-deviceinfo":        "1|127.0.0.1|1|12.3.2|Xiaomi|23116PN5BC||02-00-00-00-00-00|android 15|1440x3200|android|zh||||032|0|", //é‡è¦å‚æ•°
+		"content-type":        "application/json; charset=utf-8",
+		"user-agent":          "okhttp/4.11.0",
+		"accept-encoding":     "gzip",
+	}
+
+	return d.yun139EncryptedRequest(url, body, headers, KEY_HEX_1, resp)
+}
+
+func (d *Yun139) handleMetaGroupCopy(ctx context.Context, srcObj, dstDir model.Obj) error {
+	pathname := "/copyContentCatalog"
+	var sourceContentIDs []string
+	var sourceCatalogIDs []string
+	if srcObj.IsDir() {
+		sourceCatalogIDs = append(sourceCatalogIDs, path.Join("root:/", srcObj.GetPath(), srcObj.GetID()))
+	} else {
+		sourceContentIDs = append(sourceContentIDs, path.Join("root:/", srcObj.GetPath(), srcObj.GetID()))
+	}
+
+	destCatalogID := path.Join("root:/", dstDir.GetPath(), dstDir.GetID())
+	log.Debugf("[139Yun Group Copy] srcObj ID: %s, srcObj Path: %s, dstDir ID: %s, dstDir Path: %s, destCatalogID: %s", srcObj.GetID(), srcObj.GetPath(), dstDir.GetID(), dstDir.GetPath(), destCatalogID)
+
+	body := base.Json{
+		"commonAccountInfo": base.Json{
+			"accountType":   "1",
+			"accountUserId": d.UserDomainID,
+		},
+		"destCatalogID":    destCatalogID,
+		"destCloudID":      d.CloudID,
+		"sourceCatalogIDs": sourceCatalogIDs,
+		"sourceCloudID":    d.CloudID,
+		"sourceContentIDs": sourceContentIDs,
+	}
+
+	var resp base.Json
+	_, err := d.andAlbumRequest(pathname, body, &resp)
+	return err
+}
+
+// getGroupRootByCloudID æŸ¥è¯¢ group ä¸Šå±‚ä¿¡æ¯ï¼Œä¼˜å…ˆè¿”å› parentCatalogIDï¼Œå›é€€åˆ° catalogList[0].path
+func (d *Yun139) getGroupRootByCloudID(cloudID string) (string, error) {
+	pathname := "/orchestration/group-rebuild/catalog/v1.0/queryGroupContentList"
+	body := base.Json{
+		"groupID": cloudID,
+		"commonAccountInfo": base.Json{
+			"account":     d.getAccount(),
+			"accountType": 1,
+		},
+		"pageInfo": base.Json{
+			"pageNum":  1,
+			"pageSize": 1,
+		},
+	}
+	var resp base.Json
+	_, err := d.post(pathname, body, &resp)
+	if err != nil {
+		return "", err
+	}
+	dataObj, _ := resp["data"].(map[string]interface{})
+	if dataObj == nil {
+		return "", fmt.Errorf("invalid group response data")
+	}
+	if gcr, ok := dataObj["getGroupContentResult"].(map[string]interface{}); ok {
+		if pid, ok := gcr["parentCatalogID"].(string); ok && pid != "" {
+			return pid, nil
+		}
+		if cl, ok := gcr["catalogList"].([]interface{}); ok && len(cl) > 0 {
+			if first, ok := cl[0].(map[string]interface{}); ok {
+				if p, ok := first["path"].(string); ok && p != "" {
+					return p, nil
+				}
+			}
+		}
+	}
+	return "", fmt.Errorf("no root found in group response")
+}
+
+// getFamilyRootPath æŸ¥è¯¢ family çš„ä¸Šå±‚ pathï¼ˆdata.pathï¼‰
+// è¿”å›å€¼å·²å»é™¤å‰ç¼€ "root:/"ï¼ˆæˆ– "root:"ï¼‰ï¼Œç›´æ¥è¿”å›çº¯ ID æˆ– path éƒ¨åˆ†ï¼Œä¾¿äºæŒä¹…åŒ–ä¸º RootFolderIDã€‚
+func (d *Yun139) getFamilyRootPath(cloudID string) (string, error) {
+	// ä½¿ç”¨ v1.2 æ¥å£ï¼ˆä»£ç æ—¥å¿—ä¸­å·²æœ‰è¯¥è¯·æ±‚ï¼‰ï¼ŒpageSize å– 1 è¶³å¤Ÿè·å– path å­—æ®µ
+	pathname := "/orchestration/familyCloud-rebuild/content/v1.2/queryContentList"
+	body := base.Json{
+		"catalogID":   "",
+		"catalogType": 3,
+		"cloudID":     cloudID,
+		"cloudType":   1,
+		"commonAccountInfo": base.Json{
+			"account":     d.getAccount(),
+			"accountType": 1,
+		},
+		"contentSortType": 0,
+		"pageInfo": base.Json{
+			"pageNum":  1,
+			"pageSize": 1,
+		},
+		"sortDirection": 1,
+	}
+	var resp base.Json
+	_, err := d.post(pathname, body, &resp)
+	if err != nil {
+		return "", err
+	}
+	dataObj, _ := resp["data"].(map[string]interface{})
+	if dataObj == nil {
+		return "", fmt.Errorf("invalid family response data")
+	}
+	// helper to strip "root:/" or "root:" prefix
+	stripRoot := func(s string) string {
+		s = strings.TrimSpace(s)
+		s = strings.TrimPrefix(s, "root:/")
+		s = strings.TrimPrefix(s, "root:")
+		return s
+	}
+	if p, ok := dataObj["path"].(string); ok && p != "" {
+		return stripRoot(p), nil
+	}
+	// å›é€€ï¼šæœ‰æ—¶ path åœ¨ cloudCatalogList.catalogList ä¸­
+	if cl, ok := dataObj["cloudCatalogList"].([]interface{}); ok && len(cl) > 0 {
+		if first, ok := cl[0].(map[string]interface{}); ok {
+			if p, ok := first["path"].(string); ok && p != "" {
+				return stripRoot(p), nil
+			}
+		}
+	}
+	return "", fmt.Errorf("no path found in family response")
+}
diff --git a/drivers/189/util.go b/drivers/189/util.go
index 6e0682ea7..bb9a6adb4 100644
--- a/drivers/189/util.go
+++ b/drivers/189/util.go
@@ -107,7 +107,7 @@ import (
 //	res, err = d.client.R().
 //		SetHeaders(map[string]string{
 //			"lt":         lt,
-//			"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36",
+//			"User-Agent": base.UserAgentNT,
 //			"Referer":    "https://open.e.189.cn/",
 //			"accept":     "application/json;charset=UTF-8",
 //		}).SetFormData(map[string]string{
diff --git a/drivers/189pc/utils.go b/drivers/189pc/utils.go
index 64a06663a..08ee658ca 100644
--- a/drivers/189pc/utils.go
+++ b/drivers/189pc/utils.go
@@ -756,30 +756,24 @@ func (y *Cloud189PC) StreamUpload(ctx context.Context, dstDir model.Obj, file mo
 		}
 		partInfo := ""
 		var reader io.ReadSeeker
-		var rateLimitedRd io.Reader
 		threadG.GoWithLifecycle(errgroup.Lifecycle{
-			Before: func(ctx context.Context) error {
-				if reader == nil {
-					var err error
-					reader, err = ss.GetSectionReader(offset, partSize)
-					if err != nil {
-						return err
-					}
-					silceMd5.Reset()
-					w, err := utils.CopyWithBuffer(writers, reader)
-					if w != partSize {
-						return fmt.Errorf("failed to read all data: (expect =%d, actual =%d) %w", partSize, w, err)
-					}
-					// è®¡ç®—å—md5å¹¶è¿›è¡Œhexå’Œbase64ç¼–ç 
-					md5Bytes := silceMd5.Sum(nil)
-					silceMd5Hexs = append(silceMd5Hexs, strings.ToUpper(hex.EncodeToString(md5Bytes)))
-					partInfo = fmt.Sprintf("%d-%s", i, base64.StdEncoding.EncodeToString(md5Bytes))
-
-					rateLimitedRd = driver.NewLimitedUploadStream(ctx, reader)
+			Before: func(ctx context.Context) (err error) {
+				reader, err = ss.GetSectionReader(offset, partSize)
+				if err != nil {
+					return err
 				}
+				silceMd5.Reset()
+				w, err := utils.CopyWithBuffer(writers, reader)
+				if w != partSize {
+					return fmt.Errorf("failed to read all data: (expect =%d, actual =%d) %w", partSize, w, err)
+				}
+				// è®¡ç®—å—md5å¹¶è¿›è¡Œhexå’Œbase64ç¼–ç 
+				md5Bytes := silceMd5.Sum(nil)
+				silceMd5Hexs = append(silceMd5Hexs, strings.ToUpper(hex.EncodeToString(md5Bytes)))
+				partInfo = fmt.Sprintf("%d-%s", i, base64.StdEncoding.EncodeToString(md5Bytes))
 				return nil
 			},
-			Do: func(ctx context.Context) error {
+			Do: func(ctx context.Context) (err error) {
 				reader.Seek(0, io.SeekStart)
 				uploadUrls, err := y.GetMultiUploadUrls(ctx, isFamily, initMultiUpload.Data.UploadFileID, partInfo)
 				if err != nil {
@@ -788,11 +782,11 @@ func (y *Cloud189PC) StreamUpload(ctx context.Context, dstDir model.Obj, file mo
 
 				// step.4 ä¸Šä¼ åˆ‡ç‰‡
 				uploadUrl := uploadUrls[0]
-				_, err = y.put(ctx, uploadUrl.RequestURL, uploadUrl.Headers, false, rateLimitedRd, isFamily)
+				_, err = y.put(ctx, uploadUrl.RequestURL, uploadUrl.Headers, false, driver.NewLimitedUploadStream(ctx, reader), isFamily)
 				if err != nil {
 					return err
 				}
-				up(float64(threadG.Success()) * 100 / float64(count))
+				up(float64(threadG.Success()+1) * 100 / float64(count+1))
 				return nil
 			},
 			After: func(err error) {
@@ -804,6 +798,7 @@ func (y *Cloud189PC) StreamUpload(ctx context.Context, dstDir model.Obj, file mo
 	if err = threadG.Wait(); err != nil {
 		return nil, err
 	}
+	defer up(100)
 
 	if fileMd5 != nil {
 		fileMd5Hex = strings.ToUpper(hex.EncodeToString(fileMd5.Sum(nil)))
@@ -995,7 +990,7 @@ func (y *Cloud189PC) FastUpload(ctx context.Context, dstDir model.Obj, file mode
 					return err
 				}
 
-				up(float64(threadG.Success()) * 100 / float64(len(uploadUrls)))
+				up(float64(threadG.Success()+1) * 100 / float64(len(uploadUrls)+1))
 				uploadProgress.UploadParts[i] = ""
 				return nil
 			})
@@ -1007,6 +1002,7 @@ func (y *Cloud189PC) FastUpload(ctx context.Context, dstDir model.Obj, file mode
 			}
 			return nil, err
 		}
+		defer up(100)
 	}
 
 	// step.5 æäº¤
diff --git a/drivers/alias/driver.go b/drivers/alias/driver.go
index 208708aa9..672bd00b1 100644
--- a/drivers/alias/driver.go
+++ b/drivers/alias/driver.go
@@ -5,6 +5,7 @@ import (
 	"errors"
 	"fmt"
 	"io"
+	"math/rand"
 	"net/url"
 	stdpath "path"
 	"strings"
@@ -16,6 +17,7 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/op"
 	"github.com/OpenListTeam/OpenList/v4/internal/sign"
 	"github.com/OpenListTeam/OpenList/v4/internal/stream"
+	"github.com/OpenListTeam/OpenList/v4/pkg/http_range"
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
 	"github.com/OpenListTeam/OpenList/v4/server/common"
 )
@@ -23,10 +25,9 @@ import (
 type Alias struct {
 	model.Storage
 	Addition
-	rootOrder   []string
-	pathMap     map[string][]string
-	autoFlatten bool
-	oneKey      string
+	rootOrder []string
+	pathMap   map[string][]string
+	root      model.Obj
 }
 
 func (d *Alias) Config() driver.Config {
@@ -38,9 +39,6 @@ func (d *Alias) GetAddition() driver.Additional {
 }
 
 func (d *Alias) Init(ctx context.Context) error {
-	if d.Paths == "" {
-		return errors.New("paths is required")
-	}
 	paths := strings.Split(d.Paths, "\n")
 	d.rootOrder = make([]string, 0, len(paths))
 	d.pathMap = make(map[string][]string)
@@ -50,19 +48,50 @@ func (d *Alias) Init(ctx context.Context) error {
 			continue
 		}
 		k, v := getPair(path)
-		if _, ok := d.pathMap[k]; !ok {
+		temp, ok := d.pathMap[k]
+		if !ok {
 			d.rootOrder = append(d.rootOrder, k)
 		}
-		d.pathMap[k] = append(d.pathMap[k], v)
+		d.pathMap[k] = append(temp, v)
 	}
-	if len(d.pathMap) == 1 {
-		for k := range d.pathMap {
-			d.oneKey = k
+
+	switch len(d.rootOrder) {
+	case 0:
+		return errors.New("paths is required")
+	case 1:
+		paths := d.pathMap[d.rootOrder[0]]
+		roots := make(BalancedObjs, 0, len(paths))
+		roots = append(roots, &model.Object{
+			Name:     "root",
+			Path:     paths[0],
+			IsFolder: true,
+			Modified: d.Modified,
+			Mask:     model.Locked,
+		})
+		for _, path := range paths[1:] {
+			roots = append(roots, &model.Object{
+				Path: path,
+			})
+		}
+		d.root = roots
+	default:
+		d.root = &model.Object{
+			Name:     "root",
+			Path:     "/",
+			IsFolder: true,
+			Modified: d.Modified,
+			Mask:     model.ReadOnly,
 		}
-		d.autoFlatten = true
-	} else {
-		d.oneKey = ""
-		d.autoFlatten = false
+	}
+
+	if !utils.SliceContains(ValidReadConflictPolicy, d.ReadConflictPolicy) {
+		d.ReadConflictPolicy = FirstRWP
+	}
+	if !utils.SliceContains(ValidWriteConflictPolicy, d.WriteConflictPolicy) {
+		d.WriteConflictPolicy = DisabledWP
+	}
+	if !utils.SliceContains(ValidPutConflictPolicy, d.PutConflictPolicy) {
+		d.PutConflictPolicy = DisabledWP
 	}
 	return nil
 }
@@ -70,310 +99,292 @@ func (d *Alias) Init(ctx context.Context) error {
 func (d *Alias) Drop(ctx context.Context) error {
 	d.rootOrder = nil
 	d.pathMap = nil
+	d.root = nil
 	return nil
 }
 
-func (d *Alias) Get(ctx context.Context, path string) (model.Obj, error) {
-	if utils.PathEqual(path, "/") {
-		return &model.Object{
-			Name:     "Root",
-			IsFolder: true,
-			Path:     "/",
-		}, nil
+func (d *Alias) GetRoot(ctx context.Context) (model.Obj, error) {
+	if d.root == nil {
+		return nil, errs.StorageNotInit
 	}
-	root, sub := d.getRootAndPath(path)
-	dsts, ok := d.pathMap[root]
-	if !ok {
+	return d.root, nil
+}
+
+// é€šè¿‡op.Getè°ƒç”¨çš„è¯ï¼Œpathä¸€å®šæ˜¯å­è·¯å¾„(/å¼€å¤´)
+func (d *Alias) Get(ctx context.Context, path string) (model.Obj, error) {
+	roots, sub := d.getRootsAndPath(path)
+	if len(roots) == 0 {
 		return nil, errs.ObjectNotFound
 	}
-	var ret *model.Object
-	provider := ""
-	for _, dst := range dsts {
-		rawPath := stdpath.Join(dst, sub)
+	for idx, root := range roots {
+		rawPath := stdpath.Join(root, sub)
 		obj, err := fs.Get(ctx, rawPath, &fs.GetArgs{NoLog: true})
 		if err != nil {
 			continue
 		}
-		storage, err := fs.GetStorage(rawPath, &fs.GetStoragesArgs{})
-		if ret == nil {
-			ret = &model.Object{
-				Path:     path,
-				Name:     obj.GetName(),
-				Size:     obj.GetSize(),
-				Modified: obj.ModTime(),
-				IsFolder: obj.IsDir(),
-				HashInfo: obj.GetHash(),
-			}
-			if !d.ProviderPassThrough || err != nil {
-				break
+		mask := model.GetObjMask(obj) &^ model.Temp
+		if sub == "" {
+			// æ ¹ç›®å½•
+			mask |= model.Locked | model.Virtual
+		}
+		ret := model.Object{
+			Path:     rawPath,
+			Name:     obj.GetName(),
+			Size:     obj.GetSize(),
+			Modified: obj.ModTime(),
+			IsFolder: obj.IsDir(),
+			HashInfo: obj.GetHash(),
+			Mask:     mask,
+		}
+		obj = &ret
+		if d.ProviderPassThrough && !obj.IsDir() {
+			if storage, err := fs.GetStorage(rawPath, &fs.GetStoragesArgs{}); err == nil {
+				obj = &model.ObjectProvider{
+					Object: ret,
+					Provider: model.Provider{
+						Provider: storage.Config().Name,
+					},
+				}
 			}
-			provider = storage.Config().Name
-		} else if err != nil || provider != storage.GetStorage().Driver {
-			provider = ""
-			break
 		}
+
+		roots = roots[idx+1:]
+		var objs BalancedObjs
+		if idx > 0 {
+			objs = make(BalancedObjs, 0, len(roots)+2)
+		} else {
+			objs = make(BalancedObjs, 0, len(roots)+1)
+		}
+		objs = append(objs, obj)
+		if idx > 0 {
+			objs = append(objs, nil)
+		}
+		for _, d := range roots {
+			objs = append(objs, &tempObj{model.Object{
+				Path: stdpath.Join(d, sub),
+			}})
+		}
+		return objs, nil
 	}
-	if ret == nil {
-		return nil, errs.ObjectNotFound
-	}
-	if provider != "" {
-		return &model.ObjectProvider{
-			Object: *ret,
-			Provider: model.Provider{
-				Provider: provider,
-			},
-		}, nil
-	}
-	return ret, nil
+	return nil, errs.ObjectNotFound
 }
 
 func (d *Alias) List(ctx context.Context, dir model.Obj, args model.ListArgs) ([]model.Obj, error) {
-	path := dir.GetPath()
-	if utils.PathEqual(path, "/") && !d.autoFlatten {
-		return d.listRoot(ctx, args.WithStorageDetails && d.DetailsPassThrough, args.Refresh), nil
-	}
-	root, sub := d.getRootAndPath(path)
-	dsts, ok := d.pathMap[root]
+	dirs, ok := dir.(BalancedObjs)
 	if !ok {
-		return nil, errs.ObjectNotFound
+		return d.listRoot(ctx, args.WithStorageDetails && d.DetailsPassThrough, args.Refresh), nil
 	}
-	var objs []model.Obj
-	for _, dst := range dsts {
-		tmp, err := fs.List(ctx, stdpath.Join(dst, sub), &fs.ListArgs{
+
+	// å› ä¸ºaliasæ˜¯NoCacheä¸”Getæ–¹æ³•ä¸ä¼šè¿”å›NotSupportæˆ–NotImplementé”™è¯¯
+	// æ‰€ä»¥è¿™é‡Œå¯¹è±¡ä¸ä¼šä¼ å›åˆ°aliasï¼Œä¹Ÿå°±ä¸éœ€è¦è¿”å›BalancedObjsäº†
+	objMap := make(map[string]model.Obj)
+	for _, dir := range dirs {
+		if dir == nil {
+			continue
+		}
+		dirPath := dir.GetPath()
+		tmp, err := fs.List(ctx, dirPath, &fs.ListArgs{
 			NoLog:              true,
 			Refresh:            args.Refresh,
 			WithStorageDetails: args.WithStorageDetails && d.DetailsPassThrough,
 		})
-		if err == nil {
-			tmp, err = utils.SliceConvert(tmp, func(obj model.Obj) (model.Obj, error) {
-				objRes := model.Object{
-					Name:     obj.GetName(),
-					Size:     obj.GetSize(),
-					Modified: obj.ModTime(),
-					IsFolder: obj.IsDir(),
-				}
-				if thumb, ok := model.GetThumb(obj); ok {
-					return &model.ObjThumb{
-						Object: objRes,
-						Thumbnail: model.Thumbnail{
-							Thumbnail: thumb,
-						},
-					}, nil
+		if err != nil {
+			continue
+		}
+		for _, obj := range tmp {
+			name := obj.GetName()
+			if _, exists := objMap[name]; exists {
+				continue
+			}
+			mask := model.GetObjMask(obj) &^ model.Temp
+			objRes := model.Object{
+				Name:     name,
+				Path:     stdpath.Join(dirPath, name),
+				Size:     obj.GetSize(),
+				Modified: obj.ModTime(),
+				IsFolder: obj.IsDir(),
+				Mask:     mask,
+			}
+			var objRet model.Obj
+			if thumb, ok := model.GetThumb(obj); ok {
+				objRet = &model.ObjThumb{
+					Object: objRes,
+					Thumbnail: model.Thumbnail{
+						Thumbnail: thumb,
+					},
 				}
-				if details, ok := model.GetStorageDetails(obj); ok {
-					return &model.ObjStorageDetails{
-						Obj:                    &objRes,
-						StorageDetailsWithName: *details,
-					}, nil
+			} else {
+				objRet = &objRes
+			}
+			if details, ok := model.GetStorageDetails(obj); ok {
+				objRet = &model.ObjStorageDetails{
+					Obj:                    objRet,
+					StorageDetailsWithName: *details,
 				}
-				return &objRes, nil
-			})
-		}
-		if err == nil {
-			objs = append(objs, tmp...)
+			}
+			objMap[name] = objRet
 		}
 	}
+	objs := make([]model.Obj, 0, len(objMap))
+	for _, obj := range objMap {
+		objs = append(objs, obj)
+	}
 	return objs, nil
 }
 
 func (d *Alias) Link(ctx context.Context, file model.Obj, args model.LinkArgs) (*model.Link, error) {
-	root, sub := d.getRootAndPath(file.GetPath())
-	dsts, ok := d.pathMap[root]
-	if !ok {
-		return nil, errs.ObjectNotFound
-	}
-	// proxy || ftp,s3
-	if common.GetApiUrl(ctx) == "" {
-		args.Redirect = false
-	}
-	for _, dst := range dsts {
-		reqPath := stdpath.Join(dst, sub)
-		link, fi, err := d.link(ctx, reqPath, args)
+	if d.ReadConflictPolicy == AllRWP && !args.Redirect {
+		files, err := d.getAllObjs(ctx, file, getWriteAndPutFilterFunc(AllRWP))
 		if err != nil {
-			continue
+			return nil, err
 		}
-		if link == nil {
-			// é‡å®šå‘ä¸”éœ€è¦é€šè¿‡ä»£ç†
-			return &model.Link{
-				URL: fmt.Sprintf("%s/p%s?sign=%s",
-					common.GetApiUrl(ctx),
-					utils.EncodePath(reqPath, true),
-					sign.Sign(reqPath)),
-			}, nil
+		linkClosers := make([]io.Closer, 0, len(files))
+		rrf := make([]model.RangeReaderIF, 0, len(files))
+		for _, f := range files {
+			link, fi, err := d.link(ctx, f.GetPath(), args)
+			if err != nil {
+				continue
+			}
+			if fi.GetSize() != files.GetSize() {
+				_ = link.Close()
+				continue
+			}
+			l := *link // å¤åˆ¶ä¸€ä»½ï¼Œé¿å…ä¿®æ”¹åˆ°åŸå§‹link
+			if l.ContentLength == 0 {
+				l.ContentLength = fi.GetSize()
+			}
+			if d.DownloadConcurrency > 0 {
+				l.Concurrency = d.DownloadConcurrency
+			}
+			if d.DownloadPartSize > 0 {
+				l.PartSize = d.DownloadPartSize * utils.KB
+			}
+			rr, err := stream.GetRangeReaderFromLink(l.ContentLength, &l)
+			if err != nil {
+				_ = link.Close()
+				continue
+			}
+			linkClosers = append(linkClosers, link)
+			rrf = append(rrf, rr)
 		}
-
-		resultLink := *link
-		resultLink.SyncClosers = utils.NewSyncClosers(link)
-		if args.Redirect {
-			return &resultLink, nil
+		rr := func(ctx context.Context, httpRange http_range.Range) (io.ReadCloser, error) {
+			return rrf[rand.Intn(len(rrf))].RangeRead(ctx, httpRange)
 		}
+		return &model.Link{
+			RangeReader: stream.RangeReaderFunc(rr),
+			SyncClosers: utils.NewSyncClosers(linkClosers...),
+		}, nil
+	}
 
-		if resultLink.ContentLength == 0 {
-			resultLink.ContentLength = fi.GetSize()
-		}
-		if d.DownloadConcurrency > 0 {
-			resultLink.Concurrency = d.DownloadConcurrency
-		}
-		if d.DownloadPartSize > 0 {
-			resultLink.PartSize = d.DownloadPartSize * utils.KB
-		}
+	reqPath := d.getBalancedPath(ctx, file)
+	link, fi, err := d.link(ctx, reqPath, args)
+	if err != nil {
+		return nil, err
+	}
+	if link == nil {
+		// é‡å®šå‘ä¸”éœ€è¦é€šè¿‡ä»£ç†
+		return &model.Link{
+			URL: fmt.Sprintf("%s/p%s?sign=%s",
+				common.GetApiUrl(ctx),
+				utils.EncodePath(reqPath, true),
+				sign.Sign(reqPath)),
+		}, nil
+	}
+	resultLink := *link // å¤åˆ¶ä¸€ä»½ï¼Œé¿å…ä¿®æ”¹åˆ°åŸå§‹link
+	resultLink.SyncClosers = utils.NewSyncClosers(link)
+	if args.Redirect {
 		return &resultLink, nil
 	}
-	return nil, errs.ObjectNotFound
+	if resultLink.ContentLength == 0 {
+		resultLink.ContentLength = fi.GetSize()
+	}
+	if d.DownloadConcurrency > 0 {
+		resultLink.Concurrency = d.DownloadConcurrency
+	}
+	if d.DownloadPartSize > 0 {
+		resultLink.PartSize = d.DownloadPartSize * utils.KB
+	}
+	return &resultLink, nil
 }
 
 func (d *Alias) Other(ctx context.Context, args model.OtherArgs) (interface{}, error) {
-	root, sub := d.getRootAndPath(args.Obj.GetPath())
-	dsts, ok := d.pathMap[root]
-	if !ok {
-		return nil, errs.ObjectNotFound
-	}
-	for _, dst := range dsts {
-		rawPath := stdpath.Join(dst, sub)
-		storage, actualPath, err := op.GetStorageAndActualPath(rawPath)
-		if err != nil {
-			continue
-		}
-		other, ok := storage.(driver.Other)
-		if !ok {
-			continue
-		}
-		obj, err := op.GetUnwrap(ctx, storage, actualPath)
-		if err != nil {
-			continue
-		}
-		return other.Other(ctx, model.OtherArgs{
-			Obj:    obj,
-			Method: args.Method,
-			Data:   args.Data,
-		})
+	// Other ä¸åº”è´Ÿè½½å‡è¡¡ï¼Œè¿™æ˜¯å› ä¸ºå‰ç«¯æ˜¯å¦è°ƒç”¨ /fs/other çš„åˆ¤æ–­æ¡ä»¶æ˜¯è¿”å›çš„ provider çš„å€¼
+	// è€Œ ProviderPassThrough å¼€å¯æ—¶ï¼Œè¿”å›çš„ provider å›ºå®šä¸ºç¬¬ä¸€ä¸ª obj çš„åç«¯é©±åŠ¨
+	storage, actualPath, err := op.GetStorageAndActualPath(args.Obj.GetPath())
+	if err != nil {
+		return nil, err
 	}
-	return nil, errs.NotImplement
+	return op.Other(ctx, storage, model.FsOtherArgs{
+		Path:   actualPath,
+		Method: args.Method,
+		Data:   args.Data,
+	})
 }
 
 func (d *Alias) MakeDir(ctx context.Context, parentDir model.Obj, dirName string) error {
-	if !d.Writable {
-		return errs.PermissionDenied
-	}
-	reqPath, err := d.getReqPath(ctx, parentDir, true)
+	objs, err := d.getWriteObjs(ctx, parentDir)
 	if err == nil {
-		for _, path := range reqPath {
-			err = errors.Join(err, fs.MakeDir(ctx, stdpath.Join(*path, dirName)))
+		for _, obj := range objs {
+			err = errors.Join(err, fs.MakeDir(ctx, stdpath.Join(obj.GetPath(), dirName)))
 		}
-		return err
-	}
-	if errs.IsNotImplementError(err) {
-		return errors.New("same-name dirs cannot make sub-dir")
 	}
 	return err
 }
 
 func (d *Alias) Move(ctx context.Context, srcObj, dstDir model.Obj) error {
-	if !d.Writable {
-		return errs.PermissionDenied
-	}
-	srcPath, err := d.getReqPath(ctx, srcObj, false)
-	if errs.IsNotImplementError(err) {
-		return errors.New("same-name files cannot be moved")
-	}
-	if err != nil {
-		return err
-	}
-	dstPath, err := d.getReqPath(ctx, dstDir, true)
-	if errs.IsNotImplementError(err) {
-		return errors.New("same-name dirs cannot be moved to")
-	}
-	if err != nil {
-		return err
-	}
-	if len(srcPath) == len(dstPath) {
-		for i := range srcPath {
-			_, e := fs.Move(ctx, *srcPath[i], *dstPath[i])
+	srcs, dsts, err := d.getMoveObjs(ctx, srcObj, dstDir)
+	if err == nil {
+		for i, dst := range dsts {
+			src := srcs[i]
+			_, e := fs.Move(ctx, src.GetPath(), dst.GetPath())
+			err = errors.Join(err, e)
+		}
+		srcs = srcs[len(dsts):]
+		for _, src := range srcs {
+			e := fs.Remove(ctx, src.GetPath())
 			err = errors.Join(err, e)
 		}
-		return err
-	} else {
-		return errors.New("parallel paths mismatch")
 	}
+	return err
 }
 
 func (d *Alias) Rename(ctx context.Context, srcObj model.Obj, newName string) error {
-	if !d.Writable {
-		return errs.PermissionDenied
-	}
-	reqPath, err := d.getReqPath(ctx, srcObj, false)
+	objs, err := d.getWriteObjs(ctx, srcObj)
 	if err == nil {
-		for _, path := range reqPath {
-			err = errors.Join(err, fs.Rename(ctx, *path, newName))
+		for _, obj := range objs {
+			err = errors.Join(err, fs.Rename(ctx, obj.GetPath(), newName))
 		}
-		return err
-	}
-	if errs.IsNotImplementError(err) {
-		return errors.New("same-name files cannot be Rename")
 	}
 	return err
 }
 
 func (d *Alias) Copy(ctx context.Context, srcObj, dstDir model.Obj) error {
-	if !d.Writable {
-		return errs.PermissionDenied
-	}
-	srcPath, err := d.getReqPath(ctx, srcObj, false)
-	if errs.IsNotImplementError(err) {
-		return errors.New("same-name files cannot be copied")
-	}
-	if err != nil {
-		return err
-	}
-	dstPath, err := d.getReqPath(ctx, dstDir, true)
-	if errs.IsNotImplementError(err) {
-		return errors.New("same-name dirs cannot be copied to")
-	}
-	if err != nil {
-		return err
-	}
-	if len(srcPath) == len(dstPath) {
-		for i := range srcPath {
-			_, e := fs.Copy(ctx, *srcPath[i], *dstPath[i])
-			err = errors.Join(err, e)
-		}
-		return err
-	} else if len(srcPath) == 1 || !d.ProtectSameName {
-		for _, path := range dstPath {
-			_, e := fs.Copy(ctx, *srcPath[0], *path)
+	srcs, dsts, err := d.getCopyObjs(ctx, srcObj, dstDir)
+	if err == nil {
+		for i, src := range srcs {
+			dst := dsts[i]
+			_, e := fs.Copy(ctx, src.GetPath(), dst.GetPath())
 			err = errors.Join(err, e)
 		}
-		return err
-	} else {
-		return errors.New("parallel paths mismatch")
 	}
+	return err
 }
 
 func (d *Alias) Remove(ctx context.Context, obj model.Obj) error {
-	if !d.Writable {
-		return errs.PermissionDenied
-	}
-	reqPath, err := d.getReqPath(ctx, obj, false)
+	objs, err := d.getWriteObjs(ctx, obj)
 	if err == nil {
-		for _, path := range reqPath {
-			err = errors.Join(err, fs.Remove(ctx, *path))
+		for _, obj := range objs {
+			err = errors.Join(err, fs.Remove(ctx, obj.GetPath()))
 		}
-		return err
-	}
-	if errs.IsNotImplementError(err) {
-		return errors.New("same-name files cannot be Delete")
 	}
 	return err
 }
 
 func (d *Alias) Put(ctx context.Context, dstDir model.Obj, s model.FileStreamer, up driver.UpdateProgress) error {
-	if !d.Writable {
-		return errs.PermissionDenied
-	}
-	reqPath, err := d.getReqPath(ctx, dstDir, true)
+	objs, err := d.getPutObjs(ctx, dstDir)
 	if err == nil {
-		if len(reqPath) == 1 {
-			storage, reqActualPath, err := op.GetStorageAndActualPath(*reqPath[0])
+		if len(objs) == 1 {
+			storage, reqActualPath, err := op.GetStorageAndActualPath(objs.GetPath())
 			if err != nil {
 				return err
 			}
@@ -387,10 +398,10 @@ func (d *Alias) Put(ctx context.Context, dstDir model.Obj, s model.FileStreamer,
 			if err != nil {
 				return err
 			}
-			count := float64(len(reqPath) + 1)
+			count := float64(len(objs) + 1)
 			up(100 / count)
-			for i, path := range reqPath {
-				err = errors.Join(err, fs.PutDirectly(ctx, *path, &stream.FileStream{
+			for i, obj := range objs {
+				err = errors.Join(err, fs.PutDirectly(ctx, obj.GetPath(), &stream.FileStream{
 					Obj:      s,
 					Mimetype: s.GetMimetype(),
 					Reader:   file,
@@ -404,55 +415,40 @@ func (d *Alias) Put(ctx context.Context, dstDir model.Obj, s model.FileStreamer,
 			return err
 		}
 	}
-	if errs.IsNotImplementError(err) {
-		return errors.New("same-name dirs cannot be Put")
-	}
 	return err
 }
 
 func (d *Alias) PutURL(ctx context.Context, dstDir model.Obj, name, url string) error {
-	if !d.Writable {
-		return errs.PermissionDenied
-	}
-	reqPath, err := d.getReqPath(ctx, dstDir, true)
+	objs, err := d.getPutObjs(ctx, dstDir)
 	if err == nil {
-		for _, path := range reqPath {
-			err = errors.Join(err, fs.PutURL(ctx, *path, name, url))
+		for _, obj := range objs {
+			err = errors.Join(err, fs.PutURL(ctx, obj.GetPath(), name, url))
 		}
 		return err
 	}
-	if errs.IsNotImplementError(err) {
-		return errors.New("same-name files cannot offline download")
-	}
 	return err
 }
 
 func (d *Alias) GetArchiveMeta(ctx context.Context, obj model.Obj, args model.ArchiveArgs) (model.ArchiveMeta, error) {
-	root, sub := d.getRootAndPath(obj.GetPath())
-	dsts, ok := d.pathMap[root]
-	if !ok {
-		return nil, errs.ObjectNotFound
+	reqPath := d.getBalancedPath(ctx, obj)
+	if reqPath == "" {
+		return nil, errs.NotFile
 	}
-	for _, dst := range dsts {
-		meta, err := d.getArchiveMeta(ctx, dst, sub, args)
-		if err == nil {
-			return meta, nil
-		}
+	meta, err := d.getArchiveMeta(ctx, reqPath, args)
+	if err == nil {
+		return meta, nil
 	}
 	return nil, errs.NotImplement
 }
 
 func (d *Alias) ListArchive(ctx context.Context, obj model.Obj, args model.ArchiveInnerArgs) ([]model.Obj, error) {
-	root, sub := d.getRootAndPath(obj.GetPath())
-	dsts, ok := d.pathMap[root]
-	if !ok {
-		return nil, errs.ObjectNotFound
+	reqPath := d.getBalancedPath(ctx, obj)
+	if reqPath == "" {
+		return nil, errs.NotFile
 	}
-	for _, dst := range dsts {
-		l, err := d.listArchive(ctx, dst, sub, args)
-		if err == nil {
-			return l, nil
-		}
+	l, err := d.listArchive(ctx, reqPath, args)
+	if err == nil {
+		return l, nil
 	}
 	return nil, errs.NotImplement
 }
@@ -461,80 +457,54 @@ func (d *Alias) Extract(ctx context.Context, obj model.Obj, args model.ArchiveIn
 	// aliasçš„ä¸¤ä¸ªé©±åŠ¨ï¼Œä¸€ä¸ªæ”¯æŒé©±åŠ¨æå–ï¼Œä¸€ä¸ªä¸æ”¯æŒï¼Œå¦‚ä½•å…¼å®¹ï¼Ÿ
 	// å¦‚æœè®¿é—®çš„æ˜¯ä¸æ”¯æŒé©±åŠ¨æå–çš„é©±åŠ¨å†…çš„å‹ç¼©æ–‡ä»¶ï¼ŒGetArchiveMetaå°±ä¼šè¿”å›errs.NotImplementï¼Œæå–URLå‰ç¼€å°±ä¼šæ˜¯/aeï¼ŒExtractå°±ä¸ä¼šè¢«è°ƒç”¨
 	// å¦‚æœè®¿é—®çš„æ˜¯æ”¯æŒé©±åŠ¨æå–çš„é©±åŠ¨å†…çš„å‹ç¼©æ–‡ä»¶ï¼ŒGetArchiveMetaå°±ä¼šè¿”å›æœ‰æ•ˆå€¼ï¼Œæå–URLå‰ç¼€å°±ä¼šæ˜¯/adï¼ŒExtractå°±ä¼šè¢«è°ƒç”¨
-	root, sub := d.getRootAndPath(obj.GetPath())
-	dsts, ok := d.pathMap[root]
-	if !ok {
-		return nil, errs.ObjectNotFound
+	reqPath := d.getBalancedPath(ctx, obj)
+	if reqPath == "" {
+		return nil, errs.NotFile
 	}
-	for _, dst := range dsts {
-		reqPath := stdpath.Join(dst, sub)
-		link, err := d.extract(ctx, reqPath, args)
-		if err != nil {
-			continue
-		}
-		if link == nil {
-			return &model.Link{
-				URL: fmt.Sprintf("%s/ap%s?inner=%s&pass=%s&sign=%s",
-					common.GetApiUrl(ctx),
-					utils.EncodePath(reqPath, true),
-					utils.EncodePath(args.InnerPath, true),
-					url.QueryEscape(args.Password),
-					sign.SignArchive(reqPath)),
-			}, nil
-		}
-		resultLink := *link
-		resultLink.SyncClosers = utils.NewSyncClosers(link)
-		return &resultLink, nil
+	link, err := d.extract(ctx, reqPath, args)
+	if err != nil {
+		return nil, errs.NotImplement
+	}
+	if link == nil {
+		return &model.Link{
+			URL: fmt.Sprintf("%s/ap%s?inner=%s&pass=%s&sign=%s",
+				common.GetApiUrl(ctx),
+				utils.EncodePath(reqPath, true),
+				utils.EncodePath(args.InnerPath, true),
+				url.QueryEscape(args.Password),
+				sign.SignArchive(reqPath)),
+		}, nil
 	}
-	return nil, errs.NotImplement
+	resultLink := *link
+	resultLink.SyncClosers = utils.NewSyncClosers(link)
+	return &resultLink, nil
 }
 
 func (d *Alias) ArchiveDecompress(ctx context.Context, srcObj, dstDir model.Obj, args model.ArchiveDecompressArgs) error {
-	if !d.Writable {
-		return errs.PermissionDenied
-	}
-	srcPath, err := d.getReqPath(ctx, srcObj, false)
-	if errs.IsNotImplementError(err) {
-		return errors.New("same-name files cannot be decompressed")
-	}
-	if err != nil {
-		return err
-	}
-	dstPath, err := d.getReqPath(ctx, dstDir, true)
-	if errs.IsNotImplementError(err) {
-		return errors.New("same-name dirs cannot be decompressed to")
-	}
-	if err != nil {
-		return err
-	}
-	if len(srcPath) == len(dstPath) {
-		for i := range srcPath {
-			_, e := fs.ArchiveDecompress(ctx, *srcPath[i], *dstPath[i], args)
-			err = errors.Join(err, e)
-		}
-		return err
-	} else if len(srcPath) == 1 || !d.ProtectSameName {
-		for _, path := range dstPath {
-			_, e := fs.ArchiveDecompress(ctx, *srcPath[0], *path, args)
+	srcs, dsts, err := d.getCopyObjs(ctx, srcObj, dstDir)
+	if err == nil {
+		for i, src := range srcs {
+			dst := dsts[i]
+			_, e := fs.ArchiveDecompress(ctx, src.GetPath(), dst.GetPath(), args)
 			err = errors.Join(err, e)
 		}
-		return err
-	} else {
-		return errors.New("parallel paths mismatch")
 	}
+	return err
 }
 
 func (d *Alias) ResolveLinkCacheMode(path string) driver.LinkCacheMode {
-	root, sub := d.getRootAndPath(path)
-	dsts, ok := d.pathMap[root]
-	if !ok {
+	roots, sub := d.getRootsAndPath(path)
+	if len(roots) == 0 {
 		return 0
 	}
-	for _, dst := range dsts {
-		storage, actualPath, err := op.GetStorageAndActualPath(stdpath.Join(dst, sub))
+	for _, root := range roots {
+		storage, actualPath, err := op.GetStorageAndActualPath(stdpath.Join(root, sub))
 		if err != nil {
 			continue
 		}
+		if storage.Config().CheckStatus && storage.GetStorage().Status != op.WORK {
+			continue
+		}
 		mode := storage.Config().LinkCacheMode
 		if mode == -1 {
 			return storage.(driver.LinkCacheModeResolver).ResolveLinkCacheMode(actualPath)
diff --git a/drivers/alias/meta.go b/drivers/alias/meta.go
index 763e66472..72eb3c877 100644
--- a/drivers/alias/meta.go
+++ b/drivers/alias/meta.go
@@ -6,17 +6,15 @@ import (
 )
 
 type Addition struct {
-	// Usually one of two
-	// driver.RootPath
-	// define other
-	Paths               string `json:"paths" required:"true" type:"text"`
-	ProtectSameName     bool   `json:"protect_same_name" default:"true" required:"false" help:"Protects same-name files from Delete or Rename"`
-	ParallelWrite       bool   `json:"parallel_write" type:"bool" default:"false"`
-	DownloadConcurrency int    `json:"download_concurrency" default:"0" required:"false" type:"number" help:"Need to enable proxy"`
-	DownloadPartSize    int    `json:"download_part_size" default:"0" type:"number" required:"false" help:"Need to enable proxy. Unit: KB"`
-	Writable            bool   `json:"writable" type:"bool" default:"false"`
-	ProviderPassThrough bool   `json:"provider_pass_through" type:"bool" default:"false"`
-	DetailsPassThrough  bool   `json:"details_pass_through" type:"bool" default:"false"`
+	Paths                string `json:"paths" required:"true" type:"text"`
+	ReadConflictPolicy   string `json:"read_conflict_policy" type:"select" options:"first,random,all" default:"first"`
+	WriteConflictPolicy  string `json:"write_conflict_policy" type:"select" options:"disabled,first,deterministic,deterministic_or_all,all,all_strict" default:"disabled" help:"How the driver handles identical backend paths when renaming, removing, or making directories."`
+	PutConflictPolicy    string `json:"put_conflict_policy" type:"select" options:"disabled,first,deterministic,deterministic_or_all,all,all_strict,random,quota,quota_strict" default:"disabled" help:"How the driver handles identical backend paths when uploading, copying, moving, or decompressing."`
+	FileConsistencyCheck bool   `json:"file_consistency_check" type:"bool" default:"false"`
+	DownloadConcurrency  int    `json:"download_concurrency" default:"0" required:"false" type:"number" help:"Need to enable proxy"`
+	DownloadPartSize     int    `json:"download_part_size" default:"0" type:"number" required:"false" help:"Need to enable proxy. Unit: KB"`
+	ProviderPassThrough  bool   `json:"provider_pass_through" type:"bool" default:"false"`
+	DetailsPassThrough   bool   `json:"details_pass_through" type:"bool" default:"false"`
 }
 
 var config = driver.Config{
@@ -31,10 +29,6 @@ var config = driver.Config{
 
 func init() {
 	op.RegisterDriver(func() driver.Driver {
-		return &Alias{
-			Addition: Addition{
-				ProtectSameName: true,
-			},
-		}
+		return &Alias{}
 	})
 }
diff --git a/drivers/alias/types.go b/drivers/alias/types.go
index e560393da..9fade0c5b 100644
--- a/drivers/alias/types.go
+++ b/drivers/alias/types.go
@@ -1 +1,78 @@
 package alias
+
+import (
+	"time"
+
+	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+	"github.com/pkg/errors"
+)
+
+const (
+	DisabledWP             = "disabled"
+	FirstRWP               = "first"
+	DeterministicWP        = "deterministic"
+	DeterministicOrAllWP   = "deterministic_or_all"
+	AllRWP                 = "all"
+	AllStrictWP            = "all_strict"
+	RandomBalancedRP       = "random"
+	BalancedByQuotaP       = "quota"
+	BalancedByQuotaStrictP = "quota_strict"
+)
+
+var (
+	ValidReadConflictPolicy  = []string{FirstRWP, RandomBalancedRP, AllRWP}
+	ValidWriteConflictPolicy = []string{DisabledWP, FirstRWP, DeterministicWP, DeterministicOrAllWP, AllRWP,
+		AllStrictWP}
+	ValidPutConflictPolicy = []string{DisabledWP, FirstRWP, DeterministicWP, DeterministicOrAllWP, AllRWP,
+		AllStrictWP, RandomBalancedRP, BalancedByQuotaP, BalancedByQuotaStrictP}
+)
+
+var (
+	ErrPathConflict     = errors.New("path conflict")
+	ErrSamePathLeak     = errors.New("leak some of same-name dirs")
+	ErrNoEnoughSpace    = errors.New("none of same-name dirs has enough space")
+	ErrNotEnoughSrcObjs = errors.New("cannot move fewer objs to more paths, please try copying")
+)
+
+type BalancedObjs []model.Obj
+
+func (b BalancedObjs) GetSize() int64 {
+	return b[0].GetSize()
+}
+
+func (b BalancedObjs) ModTime() time.Time {
+	return b[0].ModTime()
+}
+
+func (b BalancedObjs) CreateTime() time.Time {
+	return b[0].CreateTime()
+}
+
+func (b BalancedObjs) IsDir() bool {
+	return b[0].IsDir()
+}
+
+func (b BalancedObjs) GetHash() utils.HashInfo {
+	return b[0].GetHash()
+}
+
+func (b BalancedObjs) GetName() string {
+	return b[0].GetName()
+}
+
+func (b BalancedObjs) GetPath() string {
+	return b[0].GetPath()
+}
+
+func (b BalancedObjs) GetID() string {
+	return b[0].GetID()
+}
+
+func (b BalancedObjs) Unwrap() model.Obj {
+	return b[0]
+}
+
+var _ model.Obj = (BalancedObjs)(nil)
+
+type tempObj struct{ model.Object }
diff --git a/drivers/alias/util.go b/drivers/alias/util.go
index c37e1efff..23b10e994 100644
--- a/drivers/alias/util.go
+++ b/drivers/alias/util.go
@@ -2,7 +2,7 @@ package alias
 
 import (
 	"context"
-	"errors"
+	"math/rand"
 	stdpath "path"
 	"strings"
 	"time"
@@ -13,6 +13,7 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
 	"github.com/OpenListTeam/OpenList/v4/internal/op"
 	"github.com/OpenListTeam/OpenList/v4/server/common"
+	"github.com/pkg/errors"
 	log "github.com/sirupsen/logrus"
 )
 
@@ -26,13 +27,15 @@ func (d *Alias) listRoot(ctx context.Context, withDetails, refresh bool) []model
 	detailsChan := make(chan detailWithIndex, len(d.pathMap))
 	workerCount := 0
 	for _, k := range d.rootOrder {
-		obj := model.Object{
+		obj := &model.Object{
 			Name:     k,
+			Path:     "/" + k,
 			IsFolder: true,
 			Modified: d.Modified,
+			Mask:     model.Locked | model.Virtual,
 		}
 		idx := len(objs)
-		objs = append(objs, &obj)
+		objs = append(objs, obj)
 		v := d.pathMap[k]
 		if !withDetails || len(v) != 1 {
 			continue
@@ -41,6 +44,7 @@ func (d *Alias) listRoot(ctx context.Context, withDetails, refresh bool) []model
 		if err != nil {
 			continue
 		}
+		obj.Modified = remoteDriver.GetStorage().Modified
 		_, ok := remoteDriver.(driver.WithDetails)
 		if !ok {
 			continue
@@ -77,26 +81,22 @@ func (d *Alias) listRoot(ctx context.Context, withDetails, refresh bool) []model
 
 // do others that not defined in Driver interface
 func getPair(path string) (string, string) {
-	// path = strings.TrimSpace(path)
-	if strings.Contains(path, ":") {
-		pair := strings.SplitN(path, ":", 2)
-		if !strings.Contains(pair[0], "/") {
-			return pair[0], pair[1]
-		}
+	if name, path, ok := strings.Cut(path, ":"); ok && !strings.Contains(name, "/") {
+		return name, path
 	}
 	return stdpath.Base(path), path
 }
 
-func (d *Alias) getRootAndPath(path string) (string, string) {
-	if d.autoFlatten {
-		return d.oneKey, path
+func (d *Alias) getRootsAndPath(path string) (roots []string, sub string) {
+	if len(d.rootOrder) == 1 {
+		return d.pathMap[d.rootOrder[0]], path
 	}
 	path = strings.TrimPrefix(path, "/")
-	parts := strings.SplitN(path, "/", 2)
-	if len(parts) == 1 {
-		return parts[0], ""
+	before, after, ok := strings.Cut(path, "/")
+	if !ok {
+		return d.pathMap[path], ""
 	}
-	return parts[0], parts[1]
+	return d.pathMap[before], after
 }
 
 func (d *Alias) link(ctx context.Context, reqPath string, args model.LinkArgs) (*model.Link, model.Obj, error) {
@@ -104,59 +104,350 @@ func (d *Alias) link(ctx context.Context, reqPath string, args model.LinkArgs) (
 	if err != nil {
 		return nil, nil, err
 	}
-	if !args.Redirect {
-		return op.Link(ctx, storage, reqActualPath, args)
+	if args.Redirect && common.ShouldProxy(storage, stdpath.Base(reqPath)) {
+		return nil, nil, nil
 	}
-	obj, err := fs.Get(ctx, reqPath, &fs.GetArgs{NoLog: true})
-	if err != nil {
-		return nil, nil, err
+	return op.Link(ctx, storage, reqActualPath, args)
+}
+
+func isConsistent(a, b model.Obj) bool {
+	if a.GetSize() != b.GetSize() {
+		return false
 	}
-	if common.ShouldProxy(storage, stdpath.Base(reqPath)) {
-		return nil, obj, nil
+	for ht, v := range a.GetHash().All() {
+		ah := b.GetHash().GetHash(ht)
+		if ah != "" && ah != v {
+			return false
+		}
 	}
-	return op.Link(ctx, storage, reqActualPath, args)
+	return true
 }
 
-func (d *Alias) getReqPath(ctx context.Context, obj model.Obj, isParent bool) ([]*string, error) {
-	root, sub := d.getRootAndPath(obj.GetPath())
-	if sub == "" && !isParent {
-		return nil, errs.NotSupport
+func (d *Alias) getAllObjs(ctx context.Context, bObj model.Obj, ifContinue func(err error) (bool, error)) (BalancedObjs, error) {
+	objs := bObj.(BalancedObjs)
+	length := 0
+	for _, o := range objs {
+		var err error
+		var obj model.Obj
+		temp, isTemp := o.(*tempObj)
+		if isTemp {
+			obj, err = fs.Get(ctx, o.GetPath(), &fs.GetArgs{NoLog: true})
+			if err == nil {
+				if !bObj.IsDir() {
+					if obj.IsDir() {
+						err = errs.NotFile
+					} else if d.FileConsistencyCheck && !isConsistent(bObj, obj) {
+						err = errs.ObjectNotFound
+					}
+				} else if !obj.IsDir() {
+					err = errs.NotFolder
+				}
+			}
+		} else if o == nil {
+			err = errs.ObjectNotFound
+		}
+
+		cont, err := ifContinue(err)
+		if err != nil {
+			if cont {
+				continue
+			}
+			return nil, err
+		}
+		if isTemp {
+			objRes := temp.Object
+			// objRes.Name = obj.GetName()
+			// objRes.Size = obj.GetSize()
+			// objRes.Modified = obj.ModTime()
+			// objRes.HashInfo = obj.GetHash()
+			objs[length] = &objRes
+		} else {
+			objs[length] = o
+		}
+		length++
+		if !cont {
+			break
+		}
 	}
-	dsts, ok := d.pathMap[root]
-	all := true
-	if !ok {
+	if length == 0 {
 		return nil, errs.ObjectNotFound
 	}
-	var reqPath []*string
-	for _, dst := range dsts {
-		path := stdpath.Join(dst, sub)
-		_, err := fs.Get(ctx, path, &fs.GetArgs{NoLog: true})
+	return objs[:length], nil
+}
+
+func (d *Alias) getBalancedPath(ctx context.Context, file model.Obj) string {
+	if d.ReadConflictPolicy == FirstRWP {
+		return file.GetPath()
+	}
+	files := file.(BalancedObjs)
+	if rand.Intn(len(files)) == 0 {
+		return file.GetPath()
+	}
+	files, _ = d.getAllObjs(ctx, file, getWriteAndPutFilterFunc(AllRWP))
+	return files[rand.Intn(len(files))].GetPath()
+}
+
+func getWriteAndPutFilterFunc(policy string) func(error) (bool, error) {
+	if policy == AllRWP {
+		return func(err error) (bool, error) {
+			return true, err
+		}
+	}
+	all := true
+	l := 0
+	return func(err error) (bool, error) {
 		if err != nil {
+			switch policy {
+			case AllStrictWP:
+				return false, ErrSamePathLeak
+			case DeterministicOrAllWP:
+				if l >= 2 {
+					return false, ErrSamePathLeak
+				}
+			}
 			all = false
-			if d.ProtectSameName && d.ParallelWrite && len(reqPath) >= 2 {
-				return nil, errs.NotImplement
+		} else {
+			switch policy {
+			case FirstRWP:
+				return false, nil
+			case DeterministicWP:
+				if l > 0 {
+					return false, ErrPathConflict
+				}
+			case DeterministicOrAllWP:
+				if l > 0 && !all {
+					return false, ErrSamePathLeak
+				}
 			}
+			l += 1
+		}
+		return true, err
+	}
+}
+
+func (d *Alias) getWriteObjs(ctx context.Context, obj model.Obj) (BalancedObjs, error) {
+	if d.WriteConflictPolicy == DisabledWP {
+		return nil, errs.PermissionDenied
+	}
+	return d.getAllObjs(ctx, obj, getWriteAndPutFilterFunc(d.WriteConflictPolicy))
+}
+
+func (d *Alias) getPutObjs(ctx context.Context, obj model.Obj) (BalancedObjs, error) {
+	if d.PutConflictPolicy == DisabledWP {
+		return nil, errs.PermissionDenied
+	}
+	objs, err := d.getAllObjs(ctx, obj, getWriteAndPutFilterFunc(d.PutConflictPolicy))
+	if err != nil {
+		return nil, err
+	}
+	strict := false
+	switch d.PutConflictPolicy {
+	case RandomBalancedRP:
+		ri := rand.Intn(len(objs))
+		return objs[ri : ri+1], nil
+	case BalancedByQuotaStrictP:
+		strict = true
+		fallthrough
+	case BalancedByQuotaP:
+		objs, ok := getRandomObjByQuotaBalanced(ctx, objs, strict, uint64(obj.GetSize()))
+		if !ok {
+			return nil, ErrNoEnoughSpace
+		}
+		return objs, nil
+	default:
+		return objs, nil
+	}
+}
+
+func getRandomObjByQuotaBalanced(ctx context.Context, reqPath BalancedObjs, strict bool, objSize uint64) (BalancedObjs, bool) {
+	// Get all space
+	details := make([]*model.StorageDetails, len(reqPath))
+	detailsChan := make(chan detailWithIndex, len(reqPath))
+	workerCount := 0
+	for i, p := range reqPath {
+		s, err := fs.GetStorage(p.GetPath(), &fs.GetStoragesArgs{})
+		if err != nil {
 			continue
 		}
-		if !d.ProtectSameName && !d.ParallelWrite {
-			return []*string{&path}, nil
+		if _, ok := s.(driver.WithDetails); !ok {
+			continue
 		}
-		reqPath = append(reqPath, &path)
-		if d.ProtectSameName && !d.ParallelWrite && len(reqPath) >= 2 {
-			return nil, errs.NotImplement
+		workerCount++
+		go func(dri driver.Driver, i int) {
+			d, e := op.GetStorageDetails(ctx, dri)
+			if e != nil {
+				if !errors.Is(e, errs.NotImplement) && !errors.Is(e, errs.StorageNotInit) {
+					log.Errorf("failed get %s storage details: %+v", dri.GetStorage().MountPath, e)
+				}
+			}
+			detailsChan <- detailWithIndex{idx: i, val: d}
+		}(s, i)
+	}
+	for workerCount > 0 {
+		select {
+		case r := <-detailsChan:
+			details[r.idx] = r.val
+			workerCount--
+		case <-time.After(time.Second):
+			workerCount = 0
 		}
-		if d.ProtectSameName && d.ParallelWrite && len(reqPath) >= 2 && !all {
-			return nil, errs.NotImplement
+	}
+
+	// Try select one that has space info
+	selected, ok := selectRandom(details, func(d *model.StorageDetails) uint64 {
+		if d == nil || d.FreeSpace < objSize {
+			return 0
+		}
+		return d.FreeSpace
+	})
+	if !ok {
+		if strict {
+			return nil, false
+		} else {
+			// No strict mode, return any of non-details ones
+			noDetails := make([]int, 0, len(details))
+			for i, d := range details {
+				if d == nil {
+					noDetails = append(noDetails, i)
+				}
+			}
+			if len(noDetails) == 0 {
+				return nil, false
+			}
+			selected = noDetails[rand.Intn(len(noDetails))]
 		}
 	}
-	if len(reqPath) == 0 {
-		return nil, errs.ObjectNotFound
+	return reqPath[selected : selected+1], true
+}
+
+func selectRandom[Item any](arr []Item, getWeight func(Item) uint64) (int, bool) {
+	var totalWeight uint64 = 0
+	for _, i := range arr {
+		totalWeight += getWeight(i)
+	}
+	if totalWeight == 0 {
+		return 0, false
+	}
+	r := rand.Uint64() % totalWeight
+	for i, item := range arr {
+		w := getWeight(item)
+		if r < w {
+			return i, true
+		}
+		r -= w
+	}
+	return 0, false
+}
+
+func (d *Alias) getCopyObjs(ctx context.Context, srcObj, dstDir model.Obj) (BalancedObjs, BalancedObjs, error) {
+	if d.PutConflictPolicy == DisabledWP {
+		return nil, nil, errs.PermissionDenied
+	}
+	dstObjs, err := d.getAllObjs(ctx, dstDir, getWriteAndPutFilterFunc(d.PutConflictPolicy))
+	if err != nil {
+		return nil, nil, err
+	}
+	dstStorageMap := make(map[string][]model.Obj)
+	allocatingDst := make(map[model.Obj]struct{})
+	for _, o := range dstObjs {
+		storage, e := fs.GetStorage(o.GetPath(), &fs.GetStoragesArgs{})
+		if e != nil {
+			return nil, nil, errors.WithMessagef(e, "cannot copy to virtual path [%s]", o.GetPath())
+		}
+		mp := storage.GetStorage().MountPath
+		dstStorageMap[mp] = append(dstStorageMap[mp], o)
+		allocatingDst[o] = struct{}{}
+	}
+	tmpSrcObjs, err := d.getAllObjs(ctx, srcObj, getWriteAndPutFilterFunc(AllRWP))
+	if err != nil {
+		return nil, nil, err
+	}
+	srcObjs := make(BalancedObjs, 0, len(dstObjs))
+	for _, src := range tmpSrcObjs {
+		storage, e := fs.GetStorage(src.GetPath(), &fs.GetStoragesArgs{})
+		if e != nil {
+			continue
+		}
+		mp := storage.GetStorage().MountPath
+		if tmp, ok := dstStorageMap[mp]; ok {
+			for _, dst := range tmp {
+				dstObjs[len(srcObjs)] = dst
+				srcObjs = append(srcObjs, src)
+				delete(allocatingDst, dst)
+			}
+			delete(dstStorageMap, mp)
+		}
+	}
+	dstObjs = dstObjs[:len(srcObjs)]
+	for dst := range allocatingDst {
+		src := tmpSrcObjs[0]
+		if d.ReadConflictPolicy == RandomBalancedRP || d.ReadConflictPolicy == AllRWP {
+			src = tmpSrcObjs[rand.Intn(len(tmpSrcObjs))]
+		}
+		srcObjs = append(srcObjs, src)
+		dstObjs = append(dstObjs, dst)
+	}
+	return srcObjs, dstObjs, nil
+}
+
+func (d *Alias) getMoveObjs(ctx context.Context, srcObj, dstDir model.Obj) (BalancedObjs, BalancedObjs, error) {
+	if d.PutConflictPolicy == DisabledWP {
+		return nil, nil, errs.PermissionDenied
+	}
+	dstObjs, err := d.getAllObjs(ctx, dstDir, getWriteAndPutFilterFunc(d.PutConflictPolicy))
+	if err != nil {
+		return nil, nil, err
+	}
+	tmpSrcObjs, err := d.getAllObjs(ctx, srcObj, getWriteAndPutFilterFunc(AllRWP))
+	if err != nil {
+		return nil, nil, err
+	}
+	if len(tmpSrcObjs) < len(dstObjs) {
+		return nil, nil, ErrNotEnoughSrcObjs
+	}
+	dstStorageMap := make(map[string][]model.Obj)
+	allocatingDst := make(map[model.Obj]struct{})
+	for _, o := range dstObjs {
+		storage, e := fs.GetStorage(o.GetPath(), &fs.GetStoragesArgs{})
+		if e != nil {
+			return nil, nil, errors.WithMessagef(e, "cannot move to virtual path [%s]", o.GetPath())
+		}
+		mp := storage.GetStorage().MountPath
+		dstStorageMap[mp] = append(dstStorageMap[mp], o)
+		allocatingDst[o] = struct{}{}
+	}
+	srcObjs := make(BalancedObjs, 0, len(tmpSrcObjs))
+	restSrcObjs := make(BalancedObjs, 0, len(tmpSrcObjs)-len(dstObjs))
+	for _, src := range tmpSrcObjs {
+		storage, e := fs.GetStorage(src.GetPath(), &fs.GetStoragesArgs{})
+		if e != nil {
+			continue
+		}
+		mp := storage.GetStorage().MountPath
+		if tmp, ok := dstStorageMap[mp]; ok {
+			dst := tmp[0]
+			if len(tmp) == 1 {
+				delete(dstStorageMap, mp)
+			} else {
+				dstStorageMap[mp] = tmp[1:]
+			}
+			dstObjs[len(srcObjs)] = dst
+			srcObjs = append(srcObjs, src)
+			delete(allocatingDst, dst)
+		} else {
+			restSrcObjs = append(restSrcObjs, src)
+		}
+	}
+	dstObjs = dstObjs[:len(srcObjs)]
+	// len(restSrcObjs) >= len(allocatingDst)
+	srcObjs = append(srcObjs, restSrcObjs...)
+	for dst := range allocatingDst {
+		dstObjs = append(dstObjs, dst)
 	}
-	return reqPath, nil
+	return srcObjs, dstObjs, nil
 }
 
-func (d *Alias) getArchiveMeta(ctx context.Context, dst, sub string, args model.ArchiveArgs) (model.ArchiveMeta, error) {
-	reqPath := stdpath.Join(dst, sub)
+func (d *Alias) getArchiveMeta(ctx context.Context, reqPath string, args model.ArchiveArgs) (model.ArchiveMeta, error) {
 	storage, reqActualPath, err := op.GetStorageAndActualPath(reqPath)
 	if err != nil {
 		return nil, err
@@ -170,8 +461,7 @@ func (d *Alias) getArchiveMeta(ctx context.Context, dst, sub string, args model.
 	return nil, errs.NotImplement
 }
 
-func (d *Alias) listArchive(ctx context.Context, dst, sub string, args model.ArchiveInnerArgs) ([]model.Obj, error) {
-	reqPath := stdpath.Join(dst, sub)
+func (d *Alias) listArchive(ctx context.Context, reqPath string, args model.ArchiveInnerArgs) ([]model.Obj, error) {
 	storage, reqActualPath, err := op.GetStorageAndActualPath(reqPath)
 	if err != nil {
 		return nil, err
diff --git a/drivers/alist_v3/driver.go b/drivers/alist_v3/driver.go
new file mode 100644
index 000000000..a9fc44fcb
--- /dev/null
+++ b/drivers/alist_v3/driver.go
@@ -0,0 +1,379 @@
+package alist_v3
+
+import (
+	"context"
+	"fmt"
+	"io"
+	"net/http"
+	"net/url"
+	"path"
+	"strings"
+
+	"github.com/OpenListTeam/OpenList/v4/drivers/base"
+	"github.com/OpenListTeam/OpenList/v4/internal/conf"
+	"github.com/OpenListTeam/OpenList/v4/internal/driver"
+	"github.com/OpenListTeam/OpenList/v4/internal/errs"
+	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+	"github.com/OpenListTeam/OpenList/v4/server/common"
+	"github.com/go-resty/resty/v2"
+	log "github.com/sirupsen/logrus"
+)
+
+type AListV3 struct {
+	model.Storage
+	Addition
+}
+
+func (d *AListV3) Config() driver.Config {
+	return config
+}
+
+func (d *AListV3) GetAddition() driver.Additional {
+	return &d.Addition
+}
+
+func (d *AListV3) Init(ctx context.Context) error {
+	d.Addition.Address = strings.TrimSuffix(d.Addition.Address, "/")
+	var resp common.Resp[MeResp]
+	_, _, err := d.request("/me", http.MethodGet, func(req *resty.Request) {
+		req.SetResult(&resp)
+	})
+	if err != nil {
+		return err
+	}
+	// if the username is not empty and the username is not the same as the current username, then login again
+	if d.Username != resp.Data.Username {
+		err = d.login()
+		if err != nil {
+			return err
+		}
+	}
+	// re-get the user info
+	_, _, err = d.request("/me", http.MethodGet, func(req *resty.Request) {
+		req.SetResult(&resp)
+	})
+	if err != nil {
+		return err
+	}
+	if utils.SliceContains(resp.Data.Role, model.GUEST) {
+		u := d.Address + "/api/public/settings"
+		res, err := base.RestyClient.R().Get(u)
+		if err != nil {
+			return err
+		}
+		allowMounted := utils.Json.Get(res.Body(), "data", conf.AllowMounted).ToString() == "true"
+		if !allowMounted {
+			return fmt.Errorf("the site does not allow mounted")
+		}
+	}
+	return err
+}
+
+func (d *AListV3) Drop(ctx context.Context) error {
+	return nil
+}
+
+func (d *AListV3) List(ctx context.Context, dir model.Obj, args model.ListArgs) ([]model.Obj, error) {
+	var resp common.Resp[FsListResp]
+	_, _, err := d.request("/fs/list", http.MethodPost, func(req *resty.Request) {
+		req.SetResult(&resp).SetBody(ListReq{
+			PageReq: model.PageReq{
+				Page:    1,
+				PerPage: 0,
+			},
+			Path:     dir.GetPath(),
+			Password: d.MetaPassword,
+			Refresh:  false,
+		})
+	})
+	if err != nil {
+		return nil, err
+	}
+	var files []model.Obj
+	for _, f := range resp.Data.Content {
+		file := model.ObjThumb{
+			Object: model.Object{
+				Name:     f.Name,
+				Modified: f.Modified,
+				Ctime:    f.Created,
+				Size:     f.Size,
+				IsFolder: f.IsDir,
+				HashInfo: utils.FromString(f.HashInfo),
+			},
+			Thumbnail: model.Thumbnail{Thumbnail: f.Thumb},
+		}
+		files = append(files, &file)
+	}
+	return files, nil
+}
+
+func (d *AListV3) Link(ctx context.Context, file model.Obj, args model.LinkArgs) (*model.Link, error) {
+	var resp common.Resp[FsGetResp]
+	headers := map[string]string{
+		"User-Agent": base.UserAgent,
+	}
+	// if PassUAToUpsteam is true, then pass the user-agent to the upstream
+	if d.PassUAToUpsteam {
+		userAgent := args.Header.Get("user-agent")
+		if userAgent != "" {
+			headers["User-Agent"] = userAgent
+		}
+	}
+	// if PassIPToUpsteam is true, then pass the ip address to the upstream
+	if d.PassIPToUpsteam {
+		ip := args.IP
+		if ip != "" {
+			headers["X-Forwarded-For"] = ip
+			headers["X-Real-Ip"] = ip
+		}
+	}
+	_, _, err := d.request("/fs/get", http.MethodPost, func(req *resty.Request) {
+		req.SetResult(&resp).SetBody(FsGetReq{
+			Path:     file.GetPath(),
+			Password: d.MetaPassword,
+		}).SetHeaders(headers)
+	})
+	if err != nil {
+		return nil, err
+	}
+	return &model.Link{
+		URL: resp.Data.RawURL,
+	}, nil
+}
+
+func (d *AListV3) MakeDir(ctx context.Context, parentDir model.Obj, dirName string) error {
+	_, _, err := d.request("/fs/mkdir", http.MethodPost, func(req *resty.Request) {
+		req.SetBody(MkdirOrLinkReq{
+			Path: path.Join(parentDir.GetPath(), dirName),
+		})
+	})
+	return err
+}
+
+func (d *AListV3) Move(ctx context.Context, srcObj, dstDir model.Obj) error {
+	_, _, err := d.request("/fs/move", http.MethodPost, func(req *resty.Request) {
+		req.SetBody(MoveCopyReq{
+			SrcDir: path.Dir(srcObj.GetPath()),
+			DstDir: dstDir.GetPath(),
+			Names:  []string{srcObj.GetName()},
+		})
+	})
+	return err
+}
+
+func (d *AListV3) Rename(ctx context.Context, srcObj model.Obj, newName string) error {
+	_, _, err := d.request("/fs/rename", http.MethodPost, func(req *resty.Request) {
+		req.SetBody(RenameReq{
+			Path: srcObj.GetPath(),
+			Name: newName,
+		})
+	})
+	return err
+}
+
+func (d *AListV3) Copy(ctx context.Context, srcObj, dstDir model.Obj) error {
+	_, _, err := d.request("/fs/copy", http.MethodPost, func(req *resty.Request) {
+		req.SetBody(MoveCopyReq{
+			SrcDir: path.Dir(srcObj.GetPath()),
+			DstDir: dstDir.GetPath(),
+			Names:  []string{srcObj.GetName()},
+		})
+	})
+	return err
+}
+
+func (d *AListV3) Remove(ctx context.Context, obj model.Obj) error {
+	_, _, err := d.request("/fs/remove", http.MethodPost, func(req *resty.Request) {
+		req.SetBody(RemoveReq{
+			Dir:   path.Dir(obj.GetPath()),
+			Names: []string{obj.GetName()},
+		})
+	})
+	return err
+}
+
+func (d *AListV3) Put(ctx context.Context, dstDir model.Obj, s model.FileStreamer, up driver.UpdateProgress) error {
+	reader := driver.NewLimitedUploadStream(ctx, &driver.ReaderUpdatingProgress{
+		Reader:         s,
+		UpdateProgress: up,
+	})
+	req, err := http.NewRequestWithContext(ctx, http.MethodPut, d.Address+"/api/fs/put", reader)
+	if err != nil {
+		return err
+	}
+	req.Header.Set("Authorization", d.Token)
+	req.Header.Set("File-Path", path.Join(dstDir.GetPath(), s.GetName()))
+	req.Header.Set("Password", d.MetaPassword)
+	if md5 := s.GetHash().GetHash(utils.MD5); len(md5) > 0 {
+		req.Header.Set("X-File-Md5", md5)
+	}
+	if sha1 := s.GetHash().GetHash(utils.SHA1); len(sha1) > 0 {
+		req.Header.Set("X-File-Sha1", sha1)
+	}
+	if sha256 := s.GetHash().GetHash(utils.SHA256); len(sha256) > 0 {
+		req.Header.Set("X-File-Sha256", sha256)
+	}
+
+	req.ContentLength = s.GetSize()
+	// client := base.NewHttpClient()
+	// client.Timeout = time.Hour * 6
+	res, err := base.HttpClient.Do(req)
+	if err != nil {
+		return err
+	}
+
+	bytes, err := io.ReadAll(res.Body)
+	if err != nil {
+		return err
+	}
+	log.Debugf("[openlist] response body: %s", string(bytes))
+	if res.StatusCode >= 400 {
+		return fmt.Errorf("request failed, status: %s", res.Status)
+	}
+	code := utils.Json.Get(bytes, "code").ToInt()
+	if code != 200 {
+		if code == 401 || code == 403 {
+			err = d.login()
+			if err != nil {
+				return err
+			}
+		}
+		return fmt.Errorf("request failed,code: %d, message: %s", code, utils.Json.Get(bytes, "message").ToString())
+	}
+	return nil
+}
+
+func (d *AListV3) GetArchiveMeta(ctx context.Context, obj model.Obj, args model.ArchiveArgs) (model.ArchiveMeta, error) {
+	if !d.ForwardArchiveReq {
+		return nil, errs.NotImplement
+	}
+	var resp common.Resp[ArchiveMetaResp]
+	_, code, err := d.request("/fs/archive/meta", http.MethodPost, func(req *resty.Request) {
+		req.SetResult(&resp).SetBody(ArchiveMetaReq{
+			ArchivePass: args.Password,
+			Password:    d.MetaPassword,
+			Path:        obj.GetPath(),
+			Refresh:     false,
+		})
+	})
+	if code == 202 {
+		return nil, errs.WrongArchivePassword
+	}
+	if err != nil {
+		return nil, err
+	}
+	var tree []model.ObjTree
+	if resp.Data.Content != nil {
+		tree = make([]model.ObjTree, 0, len(resp.Data.Content))
+		for _, content := range resp.Data.Content {
+			tree = append(tree, &content)
+		}
+	}
+	return &model.ArchiveMetaInfo{
+		Comment:   resp.Data.Comment,
+		Encrypted: resp.Data.Encrypted,
+		Tree:      tree,
+	}, nil
+}
+
+func (d *AListV3) ListArchive(ctx context.Context, obj model.Obj, args model.ArchiveInnerArgs) ([]model.Obj, error) {
+	if !d.ForwardArchiveReq {
+		return nil, errs.NotImplement
+	}
+	var resp common.Resp[ArchiveListResp]
+	_, code, err := d.request("/fs/archive/list", http.MethodPost, func(req *resty.Request) {
+		req.SetResult(&resp).SetBody(ArchiveListReq{
+			ArchiveMetaReq: ArchiveMetaReq{
+				ArchivePass: args.Password,
+				Password:    d.MetaPassword,
+				Path:        obj.GetPath(),
+				Refresh:     false,
+			},
+			PageReq: model.PageReq{
+				Page:    1,
+				PerPage: 0,
+			},
+			InnerPath: args.InnerPath,
+		})
+	})
+	if code == 202 {
+		return nil, errs.WrongArchivePassword
+	}
+	if err != nil {
+		return nil, err
+	}
+	var files []model.Obj
+	for _, f := range resp.Data.Content {
+		file := model.ObjThumb{
+			Object: model.Object{
+				Name:     f.Name,
+				Modified: f.Modified,
+				Ctime:    f.Created,
+				Size:     f.Size,
+				IsFolder: f.IsDir,
+				HashInfo: utils.FromString(f.HashInfo),
+			},
+			Thumbnail: model.Thumbnail{Thumbnail: f.Thumb},
+		}
+		files = append(files, &file)
+	}
+	return files, nil
+}
+
+func (d *AListV3) Extract(ctx context.Context, obj model.Obj, args model.ArchiveInnerArgs) (*model.Link, error) {
+	if !d.ForwardArchiveReq {
+		return nil, errs.NotSupport
+	}
+	var resp common.Resp[ArchiveMetaResp]
+	_, _, err := d.request("/fs/archive/meta", http.MethodPost, func(req *resty.Request) {
+		req.SetResult(&resp).SetBody(ArchiveMetaReq{
+			ArchivePass: args.Password,
+			Password:    d.MetaPassword,
+			Path:        obj.GetPath(),
+			Refresh:     false,
+		})
+	})
+	if err != nil {
+		return nil, err
+	}
+	return &model.Link{
+		URL: fmt.Sprintf("%s?inner=%s&pass=%s&sign=%s",
+			resp.Data.RawURL,
+			utils.EncodePath(args.InnerPath, true),
+			url.QueryEscape(args.Password),
+			resp.Data.Sign),
+	}, nil
+}
+
+func (d *AListV3) ArchiveDecompress(ctx context.Context, srcObj, dstDir model.Obj, args model.ArchiveDecompressArgs) error {
+	if !d.ForwardArchiveReq {
+		return errs.NotImplement
+	}
+	dir, name := path.Split(srcObj.GetPath())
+	_, _, err := d.request("/fs/archive/decompress", http.MethodPost, func(req *resty.Request) {
+		req.SetBody(DecompressReq{
+			ArchivePass:   args.Password,
+			CacheFull:     args.CacheFull,
+			DstDir:        dstDir.GetPath(),
+			InnerPath:     args.InnerPath,
+			Name:          []string{name},
+			PutIntoNewDir: args.PutIntoNewDir,
+			SrcDir:        dir,
+		})
+	})
+	return err
+}
+
+func (d *AListV3) ResolveLinkCacheMode(_ string) driver.LinkCacheMode {
+	var mode driver.LinkCacheMode
+	if d.PassIPToUpsteam {
+		mode |= driver.LinkCacheIP
+	}
+	if d.PassUAToUpsteam {
+		mode |= driver.LinkCacheUA
+	}
+	return mode
+}
+
+var _ driver.Driver = (*AListV3)(nil)
diff --git a/drivers/alist_v3/meta.go b/drivers/alist_v3/meta.go
new file mode 100644
index 000000000..2e5b83f8e
--- /dev/null
+++ b/drivers/alist_v3/meta.go
@@ -0,0 +1,32 @@
+package alist_v3
+
+import (
+	"github.com/OpenListTeam/OpenList/v4/internal/driver"
+	"github.com/OpenListTeam/OpenList/v4/internal/op"
+)
+
+type Addition struct {
+	driver.RootPath
+	Address           string `json:"url" required:"true"`
+	MetaPassword      string `json:"meta_password"`
+	Username          string `json:"username"`
+	Password          string `json:"password"`
+	Token             string `json:"token"`
+	PassIPToUpsteam   bool   `json:"pass_ip_to_upsteam" default:"true"`
+	PassUAToUpsteam   bool   `json:"pass_ua_to_upsteam" default:"true"`
+	ForwardArchiveReq bool   `json:"forward_archive_requests" default:"true"`
+}
+
+var config = driver.Config{
+	Name:             "AList V3",
+	LocalSort:        true,
+	DefaultRoot:      "/",
+	ProxyRangeOption: true,
+	LinkCacheMode:    driver.LinkCacheAuto,
+}
+
+func init() {
+	op.RegisterDriver(func() driver.Driver {
+		return &AListV3{}
+	})
+}
diff --git a/drivers/alist_v3/types.go b/drivers/alist_v3/types.go
new file mode 100644
index 000000000..708e07c72
--- /dev/null
+++ b/drivers/alist_v3/types.go
@@ -0,0 +1,170 @@
+package alist_v3
+
+import (
+	"time"
+
+	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+)
+
+type ListReq struct {
+	model.PageReq
+	Path     string `json:"path" form:"path"`
+	Password string `json:"password" form:"password"`
+	Refresh  bool   `json:"refresh"`
+}
+
+type ObjResp struct {
+	Name     string    `json:"name"`
+	Size     int64     `json:"size"`
+	IsDir    bool      `json:"is_dir"`
+	Modified time.Time `json:"modified"`
+	Created  time.Time `json:"created"`
+	Sign     string    `json:"sign"`
+	Thumb    string    `json:"thumb"`
+	Type     int       `json:"type"`
+	HashInfo string    `json:"hashinfo"`
+}
+
+type FsListResp struct {
+	Content  []ObjResp `json:"content"`
+	Total    int64     `json:"total"`
+	Readme   string    `json:"readme"`
+	Write    bool      `json:"write"`
+	Provider string    `json:"provider"`
+}
+
+type FsGetReq struct {
+	Path     string `json:"path" form:"path"`
+	Password string `json:"password" form:"password"`
+}
+
+type FsGetResp struct {
+	ObjResp
+	RawURL   string    `json:"raw_url"`
+	Readme   string    `json:"readme"`
+	Provider string    `json:"provider"`
+	Related  []ObjResp `json:"related"`
+}
+
+type MkdirOrLinkReq struct {
+	Path string `json:"path" form:"path"`
+}
+
+type MoveCopyReq struct {
+	SrcDir string   `json:"src_dir"`
+	DstDir string   `json:"dst_dir"`
+	Names  []string `json:"names"`
+}
+
+type RenameReq struct {
+	Path string `json:"path"`
+	Name string `json:"name"`
+}
+
+type RemoveReq struct {
+	Dir   string   `json:"dir"`
+	Names []string `json:"names"`
+}
+
+type LoginResp struct {
+	Token string `json:"token"`
+}
+
+type MeResp struct {
+	Id         int    `json:"id"`
+	Username   string `json:"username"`
+	Password   string `json:"password"`
+	BasePath   string `json:"base_path"`
+	Role       []int  `json:"role"`
+	Disabled   bool   `json:"disabled"`
+	Permission int    `json:"permission"`
+	SsoId      string `json:"sso_id"`
+	Otp        bool   `json:"otp"`
+}
+
+type ArchiveMetaReq struct {
+	ArchivePass string `json:"archive_pass"`
+	Password    string `json:"password"`
+	Path        string `json:"path"`
+	Refresh     bool   `json:"refresh"`
+}
+
+type TreeResp struct {
+	ObjResp
+	Children  []TreeResp `json:"children"`
+	hashCache *utils.HashInfo
+}
+
+func (t *TreeResp) GetSize() int64 {
+	return t.Size
+}
+
+func (t *TreeResp) GetName() string {
+	return t.Name
+}
+
+func (t *TreeResp) ModTime() time.Time {
+	return t.Modified
+}
+
+func (t *TreeResp) CreateTime() time.Time {
+	return t.Created
+}
+
+func (t *TreeResp) IsDir() bool {
+	return t.ObjResp.IsDir
+}
+
+func (t *TreeResp) GetHash() utils.HashInfo {
+	return utils.FromString(t.HashInfo)
+}
+
+func (t *TreeResp) GetID() string {
+	return ""
+}
+
+func (t *TreeResp) GetPath() string {
+	return ""
+}
+
+func (t *TreeResp) GetChildren() []model.ObjTree {
+	ret := make([]model.ObjTree, 0, len(t.Children))
+	for _, child := range t.Children {
+		ret = append(ret, &child)
+	}
+	return ret
+}
+
+func (t *TreeResp) Thumb() string {
+	return t.ObjResp.Thumb
+}
+
+type ArchiveMetaResp struct {
+	Comment   string     `json:"comment"`
+	Encrypted bool       `json:"encrypted"`
+	Content   []TreeResp `json:"content"`
+	RawURL    string     `json:"raw_url"`
+	Sign      string     `json:"sign"`
+}
+
+type ArchiveListReq struct {
+	model.PageReq
+	ArchiveMetaReq
+	InnerPath string `json:"inner_path"`
+}
+
+type ArchiveListResp struct {
+	Content []ObjResp `json:"content"`
+	Total   int64     `json:"total"`
+}
+
+type DecompressReq struct {
+	ArchivePass   string   `json:"archive_pass"`
+	CacheFull     bool     `json:"cache_full"`
+	DstDir        string   `json:"dst_dir"`
+	InnerPath     string   `json:"inner_path"`
+	Name          []string `json:"name"`
+	PutIntoNewDir bool     `json:"put_into_new_dir"`
+	SrcDir        string   `json:"src_dir"`
+}
diff --git a/drivers/alist_v3/util.go b/drivers/alist_v3/util.go
new file mode 100644
index 000000000..821fe5465
--- /dev/null
+++ b/drivers/alist_v3/util.go
@@ -0,0 +1,65 @@
+package alist_v3
+
+import (
+	"fmt"
+	"net/http"
+
+	"github.com/OpenListTeam/OpenList/v4/drivers/base"
+	"github.com/OpenListTeam/OpenList/v4/internal/op"
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+	"github.com/OpenListTeam/OpenList/v4/server/common"
+	"github.com/go-resty/resty/v2"
+	log "github.com/sirupsen/logrus"
+)
+
+func (d *AListV3) login() error {
+	if d.Username == "" {
+		return nil
+	}
+	var resp common.Resp[LoginResp]
+	_, _, err := d.request("/auth/login", http.MethodPost, func(req *resty.Request) {
+		req.SetResult(&resp).SetBody(base.Json{
+			"username": d.Username,
+			"password": d.Password,
+		})
+	})
+	if err != nil {
+		return err
+	}
+	d.Token = resp.Data.Token
+	op.MustSaveDriverStorage(d)
+	return nil
+}
+
+func (d *AListV3) request(api, method string, callback base.ReqCallback, retry ...bool) ([]byte, int, error) {
+	url := d.Address + "/api" + api
+	req := base.RestyClient.R()
+	req.SetHeader("Authorization", d.Token)
+	if callback != nil {
+		callback(req)
+	}
+	res, err := req.Execute(method, url)
+	if err != nil {
+		code := 0
+		if res != nil {
+			code = res.StatusCode()
+		}
+		return nil, code, err
+	}
+	log.Debugf("[openlist] response body: %s", res.String())
+	if res.StatusCode() >= 400 {
+		return nil, res.StatusCode(), fmt.Errorf("request failed, status: %s", res.Status())
+	}
+	code := utils.Json.Get(res.Body(), "code").ToInt()
+	if code != 200 {
+		if (code == 401 || code == 403) && !utils.IsBool(retry...) {
+			err = d.login()
+			if err != nil {
+				return nil, code, err
+			}
+			return d.request(api, method, callback, true)
+		}
+		return nil, code, fmt.Errorf("request failed,code: %d, message: %s", code, utils.Json.Get(res.Body(), "message").ToString())
+	}
+	return res.Body(), 200, nil
+}
diff --git a/drivers/aliyundrive_open/driver.go b/drivers/aliyundrive_open/driver.go
index 2a7e69781..81430caa0 100644
--- a/drivers/aliyundrive_open/driver.go
+++ b/drivers/aliyundrive_open/driver.go
@@ -77,7 +77,6 @@ func (d *AliyundriveOpen) GetRoot(ctx context.Context) (model.Obj, error) {
 		ID:       d.RootFolderID,
 		Path:     "/",
 		Name:     "root",
-		Size:     0,
 		Modified: d.Modified,
 		IsFolder: true,
 	}, nil
diff --git a/drivers/aliyundrive_open/upload.go b/drivers/aliyundrive_open/upload.go
index 9114997c2..a4a6c1de1 100644
--- a/drivers/aliyundrive_open/upload.go
+++ b/drivers/aliyundrive_open/upload.go
@@ -242,11 +242,11 @@ func (d *AliyundriveOpen) upload(ctx context.Context, dstDir model.Obj, stream m
 			if err != nil {
 				return nil, err
 			}
-			rateLimitedRd := driver.NewLimitedUploadStream(ctx, rd)
 			err = retry.Do(func() error {
 				rd.Seek(0, io.SeekStart)
-				return d.uploadPart(ctx, rateLimitedRd, createResp.PartInfoList[i])
+				return d.uploadPart(ctx, driver.NewLimitedUploadStream(ctx, rd), createResp.PartInfoList[i])
 			},
+				retry.Context(ctx),
 				retry.Attempts(3),
 				retry.DelayType(retry.BackOffDelay),
 				retry.Delay(time.Second))
diff --git a/drivers/aliyundrive_open/util.go b/drivers/aliyundrive_open/util.go
index d171a7909..22112332a 100644
--- a/drivers/aliyundrive_open/util.go
+++ b/drivers/aliyundrive_open/util.go
@@ -38,7 +38,6 @@ func (d *AliyundriveOpen) _refreshToken(ctx context.Context) (string, string, er
 			return "", "", err
 		}
 		_, err = base.RestyClient.R().
-			SetHeader("User-Agent", "Mozilla/5.0 (Macintosh; Apple macOS 15_5) AppleWebKit/537.36 (KHTML, like Gecko) Safari/537.36 Chrome/138.0.0.0 Openlist/425.6.30").
 			SetResult(&resp).
 			SetQueryParams(map[string]string{
 				"refresh_ui": d.RefreshToken,
diff --git a/drivers/all.go b/drivers/all.go
index 35edd726c..15fbf2b96 100644
--- a/drivers/all.go
+++ b/drivers/all.go
@@ -13,6 +13,7 @@ import (
 	_ "github.com/OpenListTeam/OpenList/v4/drivers/189_tv"
 	_ "github.com/OpenListTeam/OpenList/v4/drivers/189pc"
 	_ "github.com/OpenListTeam/OpenList/v4/drivers/alias"
+	_ "github.com/OpenListTeam/OpenList/v4/drivers/alist_v3"
 	_ "github.com/OpenListTeam/OpenList/v4/drivers/aliyundrive"
 	_ "github.com/OpenListTeam/OpenList/v4/drivers/aliyundrive_open"
 	_ "github.com/OpenListTeam/OpenList/v4/drivers/aliyundrive_share"
@@ -77,11 +78,11 @@ import (
 	_ "github.com/OpenListTeam/OpenList/v4/drivers/webdav"
 	_ "github.com/OpenListTeam/OpenList/v4/drivers/weiyun"
 	_ "github.com/OpenListTeam/OpenList/v4/drivers/wopan"
+	_ "github.com/OpenListTeam/OpenList/v4/drivers/wps"
 	_ "github.com/OpenListTeam/OpenList/v4/drivers/yandex_disk"
 )
 
 // All do nothing,just for import
 // same as _ import
 func All() {
-
 }
diff --git a/drivers/azure_blob/driver.go b/drivers/azure_blob/driver.go
index 888637dc9..ddfe3ff68 100644
--- a/drivers/azure_blob/driver.go
+++ b/drivers/azure_blob/driver.go
@@ -25,12 +25,11 @@ type AzureBlob struct {
 	Addition
 	client          *azblob.Client
 	containerClient *container.Client
-	config          driver.Config
 }
 
 // Config returns the driver configuration.
 func (d *AzureBlob) Config() driver.Config {
-	return d.config
+	return config
 }
 
 // GetAddition returns additional settings specific to Azure Blob Storage.
diff --git a/drivers/azure_blob/meta.go b/drivers/azure_blob/meta.go
index 3aae5044f..d675d4083 100644
--- a/drivers/azure_blob/meta.go
+++ b/drivers/azure_blob/meta.go
@@ -6,17 +6,13 @@ import (
 )
 
 type Addition struct {
+	driver.RootPath
 	Endpoint      string `json:"endpoint" required:"true" default:"https://<accountname>.blob.core.windows.net/" help:"e.g. https://accountname.blob.core.windows.net/. The full endpoint URL for Azure Storage, including the unique storage account name (3 ~ 24 numbers and lowercase letters only)."`
 	AccessKey     string `json:"access_key" required:"true" help:"The access key for Azure Storage, used for authentication. https://learn.microsoft.com/azure/storage/common/storage-account-keys-manage"`
 	ContainerName string `json:"container_name" required:"true" help:"The name of the container in Azure Storage (created in the Azure portal). https://learn.microsoft.com/azure/storage/blobs/blob-containers-portal"`
 	SignURLExpire int    `json:"sign_url_expire" type:"number" default:"4" help:"The expiration time for SAS URLs, in hours."`
 }
 
-// implement GetRootId interface
-func (r Addition) GetRootId() string {
-	return r.ContainerName
-}
-
 var config = driver.Config{
 	Name:        "Azure Blob Storage",
 	LocalSort:   true,
@@ -25,8 +21,6 @@ var config = driver.Config{
 
 func init() {
 	op.RegisterDriver(func() driver.Driver {
-		return &AzureBlob{
-			config: config,
-		}
+		return &AzureBlob{}
 	})
 }
diff --git a/drivers/baidu_netdisk/driver.go b/drivers/baidu_netdisk/driver.go
index f951a8db1..fe77aca38 100644
--- a/drivers/baidu_netdisk/driver.go
+++ b/drivers/baidu_netdisk/driver.go
@@ -1,19 +1,19 @@
 package baidu_netdisk
 
 import (
+	"bytes"
 	"context"
 	"crypto/md5"
 	"encoding/hex"
 	"errors"
-	"fmt"
 	"io"
+	"mime/multipart"
 	"net/http"
 	"net/url"
 	"os"
 	stdpath "path"
 	"strconv"
 	"strings"
-	"sync"
 	"time"
 
 	"github.com/OpenListTeam/OpenList/v4/drivers/base"
@@ -21,11 +21,10 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/driver"
 	"github.com/OpenListTeam/OpenList/v4/internal/errs"
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	"github.com/OpenListTeam/OpenList/v4/internal/net"
 	"github.com/OpenListTeam/OpenList/v4/pkg/errgroup"
-	"github.com/OpenListTeam/OpenList/v4/pkg/singleflight"
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
 	"github.com/avast/retry-go"
-	"github.com/go-resty/resty/v2"
 	log "github.com/sirupsen/logrus"
 )
 
@@ -35,16 +34,6 @@ type BaiduNetdisk struct {
 
 	uploadThread int
 	vipType      int // ä¼šå‘˜ç±»å‹ï¼Œ0æ™®é€šç”¨æˆ·(4G/4M)ã€1æ™®é€šä¼šå‘˜(10G/16M)ã€2è¶…çº§ä¼šå‘˜(20G/32M)
-
-	upClient       *resty.Client // ä¸Šä¼ æ–‡ä»¶ä½¿ç”¨çš„httpå®¢æˆ·ç«¯
-	uploadUrlG     singleflight.Group[string]
-	uploadUrlMu    sync.RWMutex
-	uploadUrlCache map[string]uploadURLCacheEntry
-}
-
-type uploadURLCacheEntry struct {
-	url        string
-	updateTime time.Time
 }
 
 var ErrUploadIDExpired = errors.New("uploadid expired")
@@ -58,17 +47,6 @@ func (d *BaiduNetdisk) GetAddition() driver.Additional {
 }
 
 func (d *BaiduNetdisk) Init(ctx context.Context) error {
-	timeout := DEFAULT_UPLOAD_SLICE_TIMEOUT
-	if d.UploadSliceTimeout > 0 {
-		timeout = time.Second * time.Duration(d.UploadSliceTimeout)
-	}
-
-	d.upClient = base.NewRestyClient().
-		SetTimeout(timeout).
-		SetRetryCount(UPLOAD_RETRY_COUNT).
-		SetRetryWaitTime(UPLOAD_RETRY_WAIT_TIME).
-		SetRetryMaxWaitTime(UPLOAD_RETRY_MAX_WAIT_TIME)
-	d.uploadUrlCache = make(map[string]uploadURLCacheEntry)
 	d.uploadThread, _ = strconv.Atoi(d.UploadThread)
 	if d.uploadThread < 1 {
 		d.uploadThread, d.UploadThread = 1, "1"
@@ -106,9 +84,10 @@ func (d *BaiduNetdisk) List(ctx context.Context, dir model.Obj, args model.ListA
 }
 
 func (d *BaiduNetdisk) Link(ctx context.Context, file model.Obj, args model.LinkArgs) (*model.Link, error) {
-	if d.DownloadAPI == "crack" {
+	switch d.DownloadAPI {
+	case "crack":
 		return d.linkCrack(file, args)
-	} else if d.DownloadAPI == "crack_video" {
+	case "crack_video":
 		return d.linkCrackVideo(file, args)
 	}
 	return d.linkOfficial(file, args)
@@ -225,7 +204,7 @@ func (d *BaiduNetdisk) Put(ctx context.Context, dstDir model.Obj, stream model.F
 		tmpF  *os.File
 		err   error
 	)
-	if _, ok := cache.(io.ReaderAt); !ok {
+	if cache == nil {
 		tmpF, err = os.CreateTemp(conf.Conf.TempDir, "file-*")
 		if err != nil {
 			return nil, err
@@ -315,31 +294,30 @@ func (d *BaiduNetdisk) Put(ctx context.Context, dstDir model.Obj, stream model.F
 		}
 		precreateResp.UploadURL = d.getUploadUrl(path, precreateResp.Uploadid)
 	}
-	ensureUploadURL()
 
 	// step.2 ä¸Šä¼ åˆ†ç‰‡
 uploadLoop:
-	for attempt := 0; attempt < 2; attempt++ {
+	for range 2 {
 		// è·å–ä¸Šä¼ åŸŸå
-		if precreateResp.UploadURL == "" {
-			ensureUploadURL()
-		}
-		uploadUrl := precreateResp.UploadURL
+		ensureUploadURL()
 		// å¹¶å‘ä¸Šä¼ 
 		threadG, upCtx := errgroup.NewGroupWithContext(ctx, d.uploadThread,
-			retry.Attempts(1),
-			retry.Delay(time.Second),
-			retry.DelayType(retry.BackOffDelay))
-
-		cacheReaderAt, okReaderAt := cache.(io.ReaderAt)
-		if !okReaderAt {
-			return nil, fmt.Errorf("cache object must implement io.ReaderAt interface for upload operations")
-		}
+			retry.Attempts(UPLOAD_RETRY_COUNT),
+			retry.Delay(UPLOAD_RETRY_WAIT_TIME),
+			retry.MaxDelay(UPLOAD_RETRY_MAX_WAIT_TIME),
+			retry.DelayType(retry.BackOffDelay),
+			retry.RetryIf(func(err error) bool {
+				return !errors.Is(err, ErrUploadIDExpired)
+			}),
+			retry.LastErrorOnly(true))
 
 		totalParts := len(precreateResp.BlockList)
 
 		for i, partseq := range precreateResp.BlockList {
-			if utils.IsCanceled(upCtx) || partseq < 0 {
+			if utils.IsCanceled(upCtx) {
+				break
+			}
+			if partseq < 0 {
 				continue
 			}
 			i, partseq := i, partseq
@@ -356,15 +334,13 @@ uploadLoop:
 					"uploadid":     precreateResp.Uploadid,
 					"partseq":      strconv.Itoa(partseq),
 				}
-				section := io.NewSectionReader(cacheReaderAt, offset, size)
-				err := d.uploadSlice(ctx, uploadUrl, params, stream.GetName(), driver.NewLimitedUploadStream(ctx, section))
+				section := io.NewSectionReader(cache, offset, size)
+				err := d.uploadSlice(ctx, precreateResp.UploadURL, params, stream.GetName(), section)
 				if err != nil {
 					return err
 				}
 				precreateResp.BlockList[i] = -1
-				// å½“å‰goroutineè¿˜æ²¡é€€å‡ºï¼Œ+1æ‰æ˜¯çœŸæ­£æˆåŠŸçš„æ•°é‡
-				success := threadG.Success() + 1
-				progress := float64(success) * 100 / float64(totalParts)
+				progress := float64(threadG.Success()+1) * 100 / float64(totalParts+1)
 				up(progress)
 				return nil
 			})
@@ -384,7 +360,6 @@ uploadLoop:
 		}
 		if errors.Is(err, ErrUploadIDExpired) {
 			log.Warn("[baidu_netdisk] uploadid expired, will restart from scratch")
-			d.clearUploadUrlCache(precreateResp.Uploadid)
 			// é‡æ–° precreateï¼ˆæ‰€æœ‰åˆ†ç‰‡éƒ½è¦é‡ä¼ ï¼‰
 			newPre, err2 := d.precreate(ctx, path, streamSize, blockListStr, "", "", ctime, mtime)
 			if err2 != nil {
@@ -395,13 +370,13 @@ uploadLoop:
 			}
 			precreateResp = newPre
 			precreateResp.UploadURL = ""
-			ensureUploadURL()
 			// è¦†ç›–æ‰æ—§çš„è¿›åº¦
 			base.SaveUploadProgress(d, precreateResp, d.AccessToken, contentMd5)
 			continue uploadLoop
 		}
 		return nil, err
 	}
+	defer up(100)
 
 	// step.3 åˆ›å»ºæ–‡ä»¶
 	var newFile File
@@ -414,7 +389,6 @@ uploadLoop:
 	newFile.Mtime = mtime
 	// ä¸Šä¼ æˆåŠŸæ¸…ç†è¿›åº¦
 	base.SaveUploadProgress(d, nil, d.AccessToken, contentMd5)
-	d.clearUploadUrlCache(precreateResp.Uploadid)
 	return fileToObj(newFile), nil
 }
 
@@ -453,22 +427,53 @@ func (d *BaiduNetdisk) precreate(ctx context.Context, path string, streamSize in
 	return &precreateResp, nil
 }
 
-func (d *BaiduNetdisk) uploadSlice(ctx context.Context, uploadUrl string, params map[string]string, fileName string, file io.Reader) error {
-	res, err := d.upClient.R().
-		SetContext(ctx).
-		SetQueryParams(params).
-		SetFileReader("file", fileName, file).
-		Post(uploadUrl + "/rest/2.0/pcs/superfile2")
+func (d *BaiduNetdisk) uploadSlice(ctx context.Context, uploadUrl string, params map[string]string, fileName string, file *io.SectionReader) error {
+	b := bytes.NewBuffer(make([]byte, 0, bytes.MinRead))
+	mw := multipart.NewWriter(b)
+	_, err := mw.CreateFormFile("file", fileName)
+	if err != nil {
+		return err
+	}
+	headSize := b.Len()
+	err = mw.Close()
+	if err != nil {
+		return err
+	}
+	head := bytes.NewReader(b.Bytes()[:headSize])
+	tail := bytes.NewReader(b.Bytes()[headSize:])
+	rateLimitedRd := driver.NewLimitedUploadStream(ctx, io.MultiReader(head, file, tail))
+
+	req, err := http.NewRequestWithContext(ctx, http.MethodPost, uploadUrl+"/rest/2.0/pcs/superfile2", rateLimitedRd)
 	if err != nil {
 		return err
 	}
-	log.Debugln(res.RawResponse.Status + res.String())
-	if res.StatusCode() != http.StatusOK {
-		return errs.NewErr(errs.StreamIncomplete, "baidu upload failed, status=%d, body=%s", res.StatusCode(), res.String())
+	query := req.URL.Query()
+	for k, v := range params {
+		query.Set(k, v)
+	}
+	req.URL.RawQuery = query.Encode()
+	req.Header.Set("Content-Type", mw.FormDataContentType())
+	req.ContentLength = int64(b.Len()) + file.Size()
+
+	client := net.NewHttpClient()
+	if d.UploadSliceTimeout > 0 {
+		client.Timeout = time.Second * time.Duration(d.UploadSliceTimeout)
+	} else {
+		client.Timeout = DEFAULT_UPLOAD_SLICE_TIMEOUT
+	}
+	resp, err := client.Do(req)
+	if err != nil {
+		return err
+	}
+	defer resp.Body.Close()
+	b.Reset()
+	_, err = b.ReadFrom(resp.Body)
+	if err != nil {
+		return err
 	}
-	errCode := utils.Json.Get(res.Body(), "error_code").ToInt()
-	errNo := utils.Json.Get(res.Body(), "errno").ToInt()
-	respStr := res.String()
+	body := b.Bytes()
+	respStr := string(body)
+	log.Debugln(respStr)
 	lower := strings.ToLower(respStr)
 	// åˆå¹¶ uploadid è¿‡æœŸæ£€æµ‹é€»è¾‘
 	if strings.Contains(lower, "uploadid") &&
@@ -476,8 +481,10 @@ func (d *BaiduNetdisk) uploadSlice(ctx context.Context, uploadUrl string, params
 		return ErrUploadIDExpired
 	}
 
+	errCode := utils.Json.Get(body, "error_code").ToInt()
+	errNo := utils.Json.Get(body, "errno").ToInt()
 	if errCode != 0 || errNo != 0 {
-		return errs.NewErr(errs.StreamIncomplete, "error uploading to baidu, response=%s", res.String())
+		return errs.NewErr(errs.StreamIncomplete, "error uploading to baidu, response=%s", respStr)
 	}
 	return nil
 }
diff --git a/drivers/baidu_netdisk/types.go b/drivers/baidu_netdisk/types.go
index 03e84b396..35886ce76 100644
--- a/drivers/baidu_netdisk/types.go
+++ b/drivers/baidu_netdisk/types.go
@@ -7,7 +7,6 @@ import (
 	"time"
 
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
-	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
 )
 
 var (
@@ -76,9 +75,7 @@ func fileToObj(f File) *model.ObjThumb {
 			Modified: time.Unix(f.ServerMtime, 0),
 			Ctime:    time.Unix(f.ServerCtime, 0),
 			IsFolder: f.Isdir == 1,
-
-			// ç›´æ¥è·å–çš„MD5æ˜¯é”™è¯¯çš„
-			HashInfo: utils.NewHashInfo(utils.MD5, DecryptMd5(f.Md5)),
+			// ç™¾åº¦APIè¿”å›çš„MD5ä¸å¯ä¿¡ï¼Œä¸ä½¿ç”¨HashInfo
 		},
 		Thumbnail: model.Thumbnail{Thumbnail: f.Thumbs.Url3},
 	}
diff --git a/drivers/baidu_netdisk/util.go b/drivers/baidu_netdisk/util.go
index 70c1f4c2b..8f55911d1 100644
--- a/drivers/baidu_netdisk/util.go
+++ b/drivers/baidu_netdisk/util.go
@@ -42,7 +42,6 @@ func (d *BaiduNetdisk) _refreshToken() error {
 			ErrorMessage string `json:"text"`
 		}
 		_, err := base.RestyClient.R().
-			SetHeader("User-Agent", "Mozilla/5.0 (Macintosh; Apple macOS 15_5) AppleWebKit/537.36 (KHTML, like Gecko) Safari/537.36 Chrome/138.0.0.0 Openlist/425.6.30").
 			SetResult(&resp).
 			SetQueryParams(map[string]string{
 				"refresh_ui": d.RefreshToken,
@@ -122,7 +121,7 @@ func (d *BaiduNetdisk) request(furl string, method string, callback base.ReqCall
 				}
 			}
 
-			if 31023 == errno && d.DownloadAPI == "crack_video" {
+			if errno == 31023 && d.DownloadAPI == "crack_video" {
 				result = res.Body()
 				return nil
 			}
@@ -247,7 +246,7 @@ func (d *BaiduNetdisk) linkCrack(file model.Obj, _ model.LinkArgs) (*model.Link,
 func (d *BaiduNetdisk) linkCrackVideo(file model.Obj, _ model.LinkArgs) (*model.Link, error) {
 	param := map[string]string{
 		"type":       "VideoURL",
-		"path":       fmt.Sprintf("%s", file.GetPath()),
+		"path":       file.GetPath(),
 		"fs_id":      file.GetID(),
 		"devuid":     "0%1",
 		"clienttype": "1",
@@ -400,59 +399,14 @@ func (d *BaiduNetdisk) getUploadUrl(path, uploadId string) string {
 	if !d.UseDynamicUploadAPI || uploadId == "" {
 		return d.UploadAPI
 	}
-	getCachedUrlFunc := func() (string, bool) {
-		d.uploadUrlMu.RLock()
-		defer d.uploadUrlMu.RUnlock()
-		if entry, ok := d.uploadUrlCache[uploadId]; ok {
-			return entry.url, true
-		}
-		return "", false
-	}
-	// æ£€æŸ¥åœ°å€ç¼“å­˜
-	if uploadUrl, ok := getCachedUrlFunc(); ok {
-		return uploadUrl
-	}
-
-	uploadUrlGetFunc := func() (string, error) {
-		// åŒé‡æ£€æŸ¥ç¼“å­˜
-		if uploadUrl, ok := getCachedUrlFunc(); ok {
-			return uploadUrl, nil
-		}
-
-		uploadUrl, err := d.requestForUploadUrl(path, uploadId)
-		if err != nil {
-			return "", err
-		}
 
-		d.uploadUrlMu.Lock()
-		d.uploadUrlCache[uploadId] = uploadURLCacheEntry{
-			url:        uploadUrl,
-			updateTime: time.Now(),
-		}
-		d.uploadUrlMu.Unlock()
-		return uploadUrl, nil
-	}
-
-	uploadUrl, err, _ := d.uploadUrlG.Do(uploadId, uploadUrlGetFunc)
+	uploadUrl, err := d.requestForUploadUrl(path, uploadId)
 	if err != nil {
-		fallback := d.UploadAPI
-		log.Warnf("[baidu_netdisk] get upload URL failed (%v), will use fallback URL: %s", err, fallback)
-		return fallback
+		return d.UploadAPI
 	}
 	return uploadUrl
 }
 
-func (d *BaiduNetdisk) clearUploadUrlCache(uploadId string) {
-	if uploadId == "" {
-		return
-	}
-	d.uploadUrlMu.Lock()
-	if _, ok := d.uploadUrlCache[uploadId]; ok {
-		delete(d.uploadUrlCache, uploadId)
-	}
-	d.uploadUrlMu.Unlock()
-}
-
 // requestForUploadUrl è¯·æ±‚è·å–ä¸Šä¼ åœ°å€ã€‚
 // å®æµ‹æ­¤æ¥å£ä¸éœ€è¦è®¤è¯ï¼Œä¼ methodå’Œupload_versionå°±è¡Œï¼Œä¸è¿‡è¿˜æ˜¯æŒ‰æ–‡æ¡£è§„èŒƒè°ƒç”¨ã€‚
 // https://pan.baidu.com/union/doc/Mlvw5hfnr
diff --git a/drivers/baidu_photo/driver.go b/drivers/baidu_photo/driver.go
index 00e36ee65..1d5d5105d 100644
--- a/drivers/baidu_photo/driver.go
+++ b/drivers/baidu_photo/driver.go
@@ -371,7 +371,7 @@ func (d *BaiduPhoto) Put(ctx context.Context, dstDir model.Obj, stream model.Fil
 				if err != nil {
 					return err
 				}
-				up(float64(threadG.Success()) * 100 / float64(len(precreateResp.BlockList)))
+				up(float64(threadG.Success()+1) * 100 / float64(len(precreateResp.BlockList)+1))
 				precreateResp.BlockList[i] = -1
 				return nil
 			})
@@ -383,6 +383,7 @@ func (d *BaiduPhoto) Put(ctx context.Context, dstDir model.Obj, stream model.Fil
 			}
 			return nil, err
 		}
+		defer up(100)
 		fallthrough
 	case 2: //step.4 åˆ›å»ºæ–‡ä»¶
 		params["uploadid"] = precreateResp.UploadID
diff --git a/drivers/base/client.go b/drivers/base/client.go
index 819d1d789..196b078da 100644
--- a/drivers/base/client.go
+++ b/drivers/base/client.go
@@ -15,9 +15,12 @@ var (
 	RestyClient      *resty.Client
 	HttpClient       *http.Client
 )
-var UserAgent = "Mozilla/5.0 (Macintosh; Apple macOS 15_5) AppleWebKit/537.36 (KHTML, like Gecko) Safari/537.36 Chrome/138.0.0.0"
+
 var DefaultTimeout = time.Second * 30
 
+const UserAgent = "Mozilla/5.0 (Macintosh; Apple macOS 26_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Safari/537.36 Chrome/142.0.0.0 OpenList/425.6.30"
+const UserAgentNT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Safari/537.36 Chrome/142.0.0.0 OpenList/425.6.30"
+
 func InitClient() {
 	NoRedirectClient = resty.New().SetRedirectPolicy(
 		resty.RedirectPolicyFunc(func(req *http.Request, via []*http.Request) error {
diff --git a/drivers/chaoxing/driver.go b/drivers/chaoxing/driver.go
index ac9ff115f..dfd25d195 100644
--- a/drivers/chaoxing/driver.go
+++ b/drivers/chaoxing/driver.go
@@ -226,16 +226,13 @@ func (d *ChaoXing) Put(ctx context.Context, dstDir model.Obj, file model.FileStr
 	if resp.Result != 1 {
 		return errors.New("get upload data error")
 	}
-	body := &bytes.Buffer{}
+	body := bytes.NewBuffer(make([]byte, 0, bytes.MinRead))
 	writer := multipart.NewWriter(body)
-	filePart, err := writer.CreateFormFile("file", file.GetName())
-	if err != nil {
-		return err
-	}
-	_, err = utils.CopyWithBuffer(filePart, file)
+	_, err = writer.CreateFormFile("file", file.GetName())
 	if err != nil {
 		return err
 	}
+	headSize := body.Len()
 	err = writer.WriteField("_token", resp.Msg.Token)
 	if err != nil {
 		return err
@@ -249,30 +246,34 @@ func (d *ChaoXing) Put(ctx context.Context, dstDir model.Obj, file model.FileStr
 	if err != nil {
 		return err
 	}
+	head := bytes.NewReader(body.Bytes()[:headSize])
+	tail := bytes.NewReader(body.Bytes()[headSize:])
 	r := driver.NewLimitedUploadStream(ctx, &driver.ReaderUpdatingProgress{
 		Reader: &driver.SimpleReaderWithSize{
-			Reader: body,
-			Size:   int64(body.Len()),
+			Reader: io.MultiReader(head, file, tail),
+			Size:   int64(body.Len()) + file.GetSize(),
 		},
 		UpdateProgress: up,
 	})
+
 	req, err := http.NewRequestWithContext(ctx, http.MethodPost, "https://pan-yz.chaoxing.com/upload", r)
 	if err != nil {
 		return err
 	}
 	req.Header.Set("Content-Type", writer.FormDataContentType())
-	req.Header.Set("Content-Length", strconv.Itoa(body.Len()))
+	req.ContentLength = int64(body.Len()) + file.GetSize()
 	resps, err := http.DefaultClient.Do(req)
 	if err != nil {
 		return err
 	}
 	defer resps.Body.Close()
-	bodys, err := io.ReadAll(resps.Body)
+	body.Reset()
+	_, err = body.ReadFrom(resps.Body)
 	if err != nil {
 		return err
 	}
 	var fileRsp UploadFileDataRsp
-	err = json.Unmarshal(bodys, &fileRsp)
+	err = json.Unmarshal(body.Bytes(), &fileRsp)
 	if err != nil {
 		return err
 	}
diff --git a/drivers/chunk/driver.go b/drivers/chunk/driver.go
index 572f9936b..b544391dd 100644
--- a/drivers/chunk/driver.go
+++ b/drivers/chunk/driver.go
@@ -10,6 +10,7 @@ import (
 	"strconv"
 	"strings"
 
+	"github.com/OpenListTeam/OpenList/v4/internal/conf"
 	"github.com/OpenListTeam/OpenList/v4/internal/driver"
 	"github.com/OpenListTeam/OpenList/v4/internal/errs"
 	"github.com/OpenListTeam/OpenList/v4/internal/fs"
@@ -52,14 +53,11 @@ func (d *Chunk) Drop(ctx context.Context) error {
 	return nil
 }
 
+func (Addition) GetRootPath() string {
+	return "/"
+}
+
 func (d *Chunk) Get(ctx context.Context, path string) (model.Obj, error) {
-	if utils.PathEqual(path, "/") {
-		return &model.Object{
-			Name:     "Root",
-			IsFolder: true,
-			Path:     "/",
-		}, nil
-	}
 	remoteStorage, remoteActualPath, err := op.GetStorageAndActualPath(d.RemotePath)
 	if err != nil {
 		return nil, err
@@ -272,17 +270,13 @@ func (d *Chunk) Link(ctx context.Context, file model.Obj, args model.LinkArgs) (
 	// æ£€æŸ¥0å·å—ä¸ç­‰äº-1 ä»¥æ”¯æŒç©ºæ–‡ä»¶
 	// å¦‚æœå—æ•°é‡å¤§äº1 æœ€åä¸€å—ä¸å¯èƒ½ä¸º0
 	// åªæ£€æŸ¥ä¸­é—´å—æ˜¯å¦æœ‰0
-	for i, l := 0, len(chunkFile.chunkSizes)-2; ; i++ {
-		if i == 0 {
-			if chunkFile.chunkSizes[i] == -1 {
-				return nil, fmt.Errorf("chunk part[%d] are missing", i)
-			}
-		} else if chunkFile.chunkSizes[i] == 0 {
+	if chunkFile.chunkSizes[0] == -1 {
+		return nil, fmt.Errorf("chunk part[%d] are missing", 0)
+	}
+	for i, l := 1, len(chunkFile.chunkSizes)-1; i < l; i++ {
+		if chunkFile.chunkSizes[i] == 0 {
 			return nil, fmt.Errorf("chunk part[%d] are missing", i)
 		}
-		if i >= l {
-			break
-		}
 	}
 	fileSize := chunkFile.GetSize()
 	mergedRrf := func(ctx context.Context, httpRange http_range.Range) (io.ReadCloser, error) {
@@ -429,9 +423,10 @@ func (d *Chunk) Put(ctx context.Context, dstDir model.Obj, file model.FileStream
 		UpdateProgress: up,
 	}
 	dst := stdpath.Join(remoteActualPath, dstDir.GetPath(), d.ChunkPrefix+file.GetName())
+	skipHookCtx := context.WithValue(ctx, conf.SkipHookKey, struct{}{})
 	if d.StoreHash {
 		for ht, value := range file.GetHash().All() {
-			_ = op.Put(ctx, remoteStorage, dst, &stream.FileStream{
+			_ = op.Put(skipHookCtx, remoteStorage, dst, &stream.FileStream{
 				Obj: &model.Object{
 					Name:     fmt.Sprintf("hash_%s_%s%s", ht.Name, value, d.CustomExt),
 					Size:     1,
@@ -439,7 +434,7 @@ func (d *Chunk) Put(ctx context.Context, dstDir model.Obj, file model.FileStream
 				},
 				Mimetype: "application/octet-stream",
 				Reader:   bytes.NewReader([]byte{0}), // å…¼å®¹ä¸æ”¯æŒç©ºæ–‡ä»¶çš„é©±åŠ¨
-			}, nil, true)
+			}, nil)
 		}
 	}
 	fullPartCount := int(file.GetSize() / d.PartSize)
@@ -450,7 +445,7 @@ func (d *Chunk) Put(ctx context.Context, dstDir model.Obj, file model.FileStream
 	}
 	partIndex := 0
 	for partIndex < fullPartCount {
-		err = op.Put(ctx, remoteStorage, dst, &stream.FileStream{
+		err = op.Put(skipHookCtx, remoteStorage, dst, &stream.FileStream{
 			Obj: &model.Object{
 				Name:     d.getPartName(partIndex),
 				Size:     d.PartSize,
@@ -458,7 +453,7 @@ func (d *Chunk) Put(ctx context.Context, dstDir model.Obj, file model.FileStream
 			},
 			Mimetype: file.GetMimetype(),
 			Reader:   io.LimitReader(upReader, d.PartSize),
-		}, nil, true)
+		}, nil)
 		if err != nil {
 			_ = op.Remove(ctx, remoteStorage, dst)
 			return err
diff --git a/drivers/cloudreve/util.go b/drivers/cloudreve/util.go
index c9894b3a1..6d5e5aae1 100644
--- a/drivers/cloudreve/util.go
+++ b/drivers/cloudreve/util.go
@@ -291,6 +291,7 @@ func (d *Cloudreve) upRemote(ctx context.Context, stream model.FileStreamer, u U
 				}
 				return nil
 			},
+			retry.Context(ctx),
 			retry.Attempts(3),
 			retry.DelayType(retry.BackOffDelay),
 			retry.Delay(time.Second),
@@ -351,7 +352,9 @@ func (d *Cloudreve) upOneDrive(ctx context.Context, stream model.FileStreamer, u
 				default:
 					return nil
 				}
-			}, retry.Attempts(3),
+			},
+			retry.Context(ctx),
+			retry.Attempts(3),
 			retry.DelayType(retry.BackOffDelay),
 			retry.Delay(time.Second),
 		)
@@ -414,7 +417,9 @@ func (d *Cloudreve) upS3(ctx context.Context, stream model.FileStreamer, u Uploa
 					etags = append(etags, etag)
 					return nil
 				}
-			}, retry.Attempts(3),
+			},
+			retry.Context(ctx),
+			retry.Attempts(3),
 			retry.DelayType(retry.BackOffDelay),
 			retry.Delay(time.Second),
 		)
diff --git a/drivers/cloudreve_v4/driver.go b/drivers/cloudreve_v4/driver.go
index c16309e49..eb8707b47 100644
--- a/drivers/cloudreve_v4/driver.go
+++ b/drivers/cloudreve_v4/driver.go
@@ -299,7 +299,9 @@ func (d *CloudreveV4) Put(ctx context.Context, dstDir model.Obj, file model.File
 		case "onedrive":
 			err = d.upOneDrive(ctx, file, u, up)
 		case "s3":
-			err = d.upS3(ctx, file, u, up)
+			err = d.upS3(ctx, file, u, up, "s3")
+		case "ks3":
+			err = d.upS3(ctx, file, u, up, "ks3")
 		default:
 			return errs.NotImplement
 		}
diff --git a/drivers/cloudreve_v4/util.go b/drivers/cloudreve_v4/util.go
index 200dfbb69..853df9ad6 100644
--- a/drivers/cloudreve_v4/util.go
+++ b/drivers/cloudreve_v4/util.go
@@ -447,7 +447,9 @@ func (d *CloudreveV4) upRemote(ctx context.Context, file model.FileStreamer, u F
 					return errors.New(up.Msg)
 				}
 				return nil
-			}, retry.Attempts(3),
+			},
+			retry.Context(ctx),
+			retry.Attempts(3),
 			retry.DelayType(retry.BackOffDelay),
 			retry.Delay(time.Second),
 		)
@@ -508,7 +510,9 @@ func (d *CloudreveV4) upOneDrive(ctx context.Context, file model.FileStreamer, u
 				default:
 					return nil
 				}
-			}, retry.Attempts(3),
+			},
+			retry.Context(ctx),
+			retry.Attempts(3),
 			retry.DelayType(retry.BackOffDelay),
 			retry.Delay(time.Second),
 		)
@@ -525,7 +529,7 @@ func (d *CloudreveV4) upOneDrive(ctx context.Context, file model.FileStreamer, u
 	}, nil)
 }
 
-func (d *CloudreveV4) upS3(ctx context.Context, file model.FileStreamer, u FileUploadResp, up driver.UpdateProgress) error {
+func (d *CloudreveV4) upS3(ctx context.Context, file model.FileStreamer, u FileUploadResp, up driver.UpdateProgress, s3Type string) error {
 	DEFAULT := int64(u.ChunkSize)
 	ss, err := stream.NewStreamSectionReader(file, int(DEFAULT), &up)
 	if err != nil {
@@ -556,6 +560,9 @@ func (d *CloudreveV4) upS3(ctx context.Context, file model.FileStreamer, u FileU
 				}
 				req.ContentLength = byteSize
 				req.Header.Set("User-Agent", d.getUA())
+				if s3Type == "ks3" {
+					req.Header.Set("Content-Type", "application/octet-stream")
+				}
 				res, err := base.HttpClient.Do(req)
 				if err != nil {
 					return err
@@ -572,6 +579,7 @@ func (d *CloudreveV4) upS3(ctx context.Context, file model.FileStreamer, u FileU
 					return nil
 				}
 			},
+			retry.Context(ctx),
 			retry.Attempts(3),
 			retry.DelayType(retry.BackOffDelay),
 			retry.Delay(time.Second),
@@ -604,7 +612,11 @@ func (d *CloudreveV4) upS3(ctx context.Context, file model.FileStreamer, u FileU
 	if err != nil {
 		return err
 	}
-	req.Header.Set("Content-Type", "application/xml")
+	if s3Type == "ks3" {
+		req.Header.Set("Content-Type", "application/octet-stream")
+	} else {
+		req.Header.Set("Content-Type", "application/xml")
+	}
 	req.Header.Set("User-Agent", d.getUA())
 	res, err := base.HttpClient.Do(req)
 	if err != nil {
@@ -617,7 +629,5 @@ func (d *CloudreveV4) upS3(ctx context.Context, file model.FileStreamer, u FileU
 	}
 
 	// ä¸Šä¼ æˆåŠŸå‘é€å›è°ƒè¯·æ±‚
-	return d.request(http.MethodGet, "/callback/s3/"+u.SessionID+"/"+u.CallbackSecret, func(req *resty.Request) {
-		req.SetBody("{}")
-	}, nil)
+	return d.request(http.MethodGet, "/callback/"+s3Type+"/"+u.SessionID+"/"+u.CallbackSecret, nil, nil)
 }
diff --git a/drivers/cnb_releases/driver.go b/drivers/cnb_releases/driver.go
index d80e69584..09ec153c8 100644
--- a/drivers/cnb_releases/driver.go
+++ b/drivers/cnb_releases/driver.go
@@ -50,7 +50,8 @@ func (d *CnbReleases) Drop(ctx context.Context) error {
 }
 
 func (d *CnbReleases) List(ctx context.Context, dir model.Obj, args model.ListArgs) ([]model.Obj, error) {
-	if dir.GetPath() == "/" {
+	dirID := dir.GetID()
+	if dirID == "" {
 		// get all releases for root dir
 		var resp ReleaseList
 
@@ -75,36 +76,32 @@ func (d *CnbReleases) List(ctx context.Context, dir model.Obj, args model.ListAr
 				IsFolder: true,
 			}, nil
 		})
-	} else {
-		// get release info by release id
-		releaseID := dir.GetID()
-		if releaseID == "" {
-			return nil, errs.ObjectNotFound
-		}
-		var resp Release
-		err := d.Request(http.MethodGet, "/{repo}/-/releases/{release_id}", func(req *resty.Request) {
-			req.SetPathParam("repo", d.Repo)
-			req.SetPathParam("release_id", releaseID)
-		}, &resp)
-		if err != nil {
-			return nil, err
-		}
+	}
 
-		return utils.SliceConvert(resp.Assets, func(src ReleaseAsset) (model.Obj, error) {
-			return &Object{
-				Object: model.Object{
-					ID:       src.ID,
-					Path:     src.Path,
-					Name:     src.Name,
-					Size:     src.Size,
-					Ctime:    src.CreatedAt,
-					Modified: src.UpdatedAt,
-					IsFolder: false,
-				},
-				ParentID: dir.GetID(),
-			}, nil
-		})
+	var resp Release
+	err := d.Request(http.MethodGet, "/{repo}/-/releases/{release_id}", func(req *resty.Request) {
+		req.SetPathParam("repo", d.Repo)
+		req.SetPathParam("release_id", dirID)
+	}, &resp)
+	if err != nil {
+		return nil, err
 	}
+
+	return utils.SliceConvert(resp.Assets, func(src ReleaseAsset) (model.Obj, error) {
+		return &Object{
+			Object: model.Object{
+				ID:       src.ID,
+				Path:     src.Path,
+				Name:     src.Name,
+				Size:     src.Size,
+				Ctime:    src.CreatedAt,
+				Modified: src.UpdatedAt,
+				IsFolder: false,
+			},
+			ParentID: dirID,
+		}, nil
+	})
+
 }
 
 func (d *CnbReleases) Link(ctx context.Context, file model.Obj, args model.LinkArgs) (*model.Link, error) {
@@ -200,15 +197,20 @@ func (d *CnbReleases) Put(ctx context.Context, dstDir model.Obj, file model.File
 	if err != nil {
 		return err
 	}
-
 	head := bytes.NewReader(b.Bytes()[:headSize])
 	tail := bytes.NewReader(b.Bytes()[headSize:])
-	rateLimitedRd := driver.NewLimitedUploadStream(ctx, io.MultiReader(head, file, tail))
+	r := driver.NewLimitedUploadStream(ctx, &driver.ReaderUpdatingProgress{
+		Reader: &driver.SimpleReaderWithSize{
+			Reader: io.MultiReader(head, file, tail),
+			Size:   int64(b.Len()) + file.GetSize(),
+		},
+		UpdateProgress: up,
+	})
 
 	// use net/http to upload file
 	ctxWithTimeout, cancel := context.WithTimeout(ctx, time.Duration(resp.ExpiresInSec+1)*time.Second)
 	defer cancel()
-	req, err := http.NewRequestWithContext(ctxWithTimeout, http.MethodPost, resp.UploadURL, rateLimitedRd)
+	req, err := http.NewRequestWithContext(ctxWithTimeout, http.MethodPost, resp.UploadURL, r)
 	if err != nil {
 		return err
 	}
diff --git a/drivers/cnb_releases/meta.go b/drivers/cnb_releases/meta.go
index 2894d8a2b..7301861d3 100644
--- a/drivers/cnb_releases/meta.go
+++ b/drivers/cnb_releases/meta.go
@@ -6,7 +6,7 @@ import (
 )
 
 type Addition struct {
-	driver.RootPath
+	driver.RootID
 	Repo          string `json:"repo" type:"string" required:"true"`
 	Token         string `json:"token" type:"string" required:"true"`
 	UseTagName    bool   `json:"use_tag_name" type:"bool" default:"false" help:"Use tag name instead of release name"`
@@ -14,9 +14,8 @@ type Addition struct {
 }
 
 var config = driver.Config{
-	Name:        "CNB Releases",
-	LocalSort:   true,
-	DefaultRoot: "/",
+	Name:      "CNB Releases",
+	LocalSort: true,
 }
 
 func init() {
diff --git a/drivers/crypt/driver.go b/drivers/crypt/driver.go
index 1398ff1cb..9e8b5c5c7 100644
--- a/drivers/crypt/driver.go
+++ b/drivers/crypt/driver.go
@@ -3,6 +3,7 @@ package crypt
 import (
 	"bytes"
 	"context"
+	"errors"
 	"fmt"
 	"io"
 	stdpath "path"
@@ -29,8 +30,7 @@ import (
 type Crypt struct {
 	model.Storage
 	Addition
-	cipher        *rcCrypt.Cipher
-	remoteStorage driver.Driver
+	cipher *rcCrypt.Cipher
 }
 
 const obfuscatedPrefix = "___Obfuscated___"
@@ -60,15 +60,7 @@ func (d *Crypt) Init(ctx context.Context) error {
 	}
 	d.FileNameEncoding = utils.GetNoneEmpty(d.FileNameEncoding, "base64")
 	d.EncryptedSuffix = utils.GetNoneEmpty(d.EncryptedSuffix, ".bin")
-
-	op.MustSaveDriverStorage(d)
-
-	// need remote storage exist
-	storage, err := fs.GetStorage(d.RemotePath, &fs.GetStoragesArgs{})
-	if err != nil {
-		return fmt.Errorf("can't find remote storage: %w", err)
-	}
-	d.remoteStorage = storage
+	d.RemotePath = utils.FixAndCleanPath(d.RemotePath)
 
 	p, _ := strings.CutPrefix(d.Password, obfuscatedPrefix)
 	p2, _ := strings.CutPrefix(d.Salt, obfuscatedPrefix)
@@ -108,150 +100,146 @@ func (d *Crypt) Drop(ctx context.Context) error {
 }
 
 func (d *Crypt) List(ctx context.Context, dir model.Obj, args model.ListArgs) ([]model.Obj, error) {
-	path := dir.GetPath()
-	// return d.list(ctx, d.RemotePath, path)
-	// remoteFull
-
-	objs, err := fs.List(ctx, d.getPathForRemote(path, true), &fs.ListArgs{NoLog: true, Refresh: args.Refresh})
+	remoteFullPath := dir.GetPath()
+	objs, err := fs.List(ctx, remoteFullPath, &fs.ListArgs{NoLog: true, Refresh: args.Refresh})
 	// the obj must implement the model.SetPath interface
 	// return objs, err
 	if err != nil {
 		return nil, err
 	}
 
-	var result []model.Obj
+	result := make([]model.Obj, 0, len(objs))
 	for _, obj := range objs {
-		if obj.IsDir() {
-			name, err := d.cipher.DecryptDirName(obj.GetName())
-			if err != nil {
-				// filter illegal files
-				continue
-			}
-			if !d.ShowHidden && strings.HasPrefix(name, ".") {
-				continue
-			}
-			objRes := model.Object{
-				Name:     name,
-				Size:     0,
-				Modified: obj.ModTime(),
-				IsFolder: obj.IsDir(),
-				Ctime:    obj.CreateTime(),
-				// discarding hash as it's encrypted
-			}
-			result = append(result, &objRes)
-		} else {
-			thumb, ok := model.GetThumb(obj)
-			size, err := d.cipher.DecryptedSize(obj.GetSize())
-			if err != nil {
-				// filter illegal files
-				continue
-			}
-			name, err := d.cipher.DecryptFileName(obj.GetName())
-			if err != nil {
-				// filter illegal files
-				continue
-			}
-			if !d.ShowHidden && strings.HasPrefix(name, ".") {
-				continue
-			}
-			objRes := model.Object{
-				Name:     name,
-				Size:     size,
-				Modified: obj.ModTime(),
-				IsFolder: obj.IsDir(),
-				Ctime:    obj.CreateTime(),
-				// discarding hash as it's encrypted
-			}
-			if d.Thumbnail && thumb == "" {
-				thumbPath := stdpath.Join(args.ReqPath, ".thumbnails", name+".webp")
-				thumb = fmt.Sprintf("%s/d%s?sign=%s",
-					common.GetApiUrl(ctx),
-					utils.EncodePath(thumbPath, true),
-					sign.Sign(thumbPath))
-			}
-			if !ok && !d.Thumbnail {
-				result = append(result, &objRes)
+		size := obj.GetSize()
+		mask := model.GetObjMask(obj)
+		name := obj.GetName()
+		if mask&model.Virtual == 0 {
+			if obj.IsDir() {
+				name, err = d.cipher.DecryptDirName(model.UnwrapObjName(obj).GetName())
+				if err != nil {
+					// filter illegal files
+					continue
+				}
 			} else {
-				objWithThumb := model.ObjThumb{
-					Object: objRes,
-					Thumbnail: model.Thumbnail{
-						Thumbnail: thumb,
-					},
+				size, err = d.cipher.DecryptedSize(size)
+				if err != nil {
+					// filter illegal files
+					continue
+				}
+				name, err = d.cipher.DecryptFileName(model.UnwrapObjName(obj).GetName())
+				if err != nil {
+					// filter illegal files
+					continue
 				}
-				result = append(result, &objWithThumb)
 			}
 		}
+		if !d.ShowHidden && strings.HasPrefix(name, ".") {
+			continue
+		}
+		objRes := &model.Object{
+			Path:     stdpath.Join(remoteFullPath, obj.GetName()),
+			Name:     name,
+			Size:     size,
+			Modified: obj.ModTime(),
+			IsFolder: obj.IsDir(),
+			Ctime:    obj.CreateTime(),
+			Mask:     mask &^ model.Temp,
+			// discarding hash as it's encrypted
+		}
+		if !d.Thumbnail || !strings.HasPrefix(args.ReqPath, "/") {
+			result = append(result, objRes)
+			continue
+		}
+		thumbPath := stdpath.Join(args.ReqPath, ".thumbnails", name+".webp")
+		thumb := fmt.Sprintf("%s/d%s?sign=%s",
+			common.GetApiUrl(ctx),
+			utils.EncodePath(thumbPath, true),
+			sign.Sign(thumbPath))
+		result = append(result, &model.ObjThumb{
+			Object: *objRes,
+			Thumbnail: model.Thumbnail{
+				Thumbnail: thumb,
+			},
+		})
 	}
 
 	return result, nil
 }
 
+func (a Addition) GetRootPath() string {
+	return a.RemotePath
+}
+
 func (d *Crypt) Get(ctx context.Context, path string) (model.Obj, error) {
-	if utils.PathEqual(path, "/") {
-		return &model.Object{
-			Name:     "Root",
-			IsFolder: true,
-			Path:     "/",
-		}, nil
-	}
-	remoteFullPath := ""
-	var remoteObj model.Obj
-	var err, err2 error
 	firstTryIsFolder, secondTry := guessPath(path)
-	remoteFullPath = d.getPathForRemote(path, firstTryIsFolder)
-	remoteObj, err = fs.Get(ctx, remoteFullPath, &fs.GetArgs{NoLog: true})
+	remoteFullPath := stdpath.Join(d.RemotePath, d.encryptPath(path, firstTryIsFolder))
+	remoteObj, err := fs.Get(ctx, remoteFullPath, &fs.GetArgs{NoLog: true})
 	if err != nil {
-		if errs.IsObjectNotFound(err) && secondTry {
+		if errors.Is(err, errs.StorageNotFound) {
+			remoteFullPath = stdpath.Join(d.RemotePath, path)
+			remoteObj, err = fs.Get(ctx, remoteFullPath, &fs.GetArgs{NoLog: true})
+			if err != nil {
+				// å¯èƒ½æ˜¯ è™šæ‹Ÿè·¯å¾„+å¼€å¯æ–‡ä»¶å¤¹åŠ å¯†ï¼šè¿”å›NotSupportè®©op.Getå»å°è¯•op.ListæŸ¥æ‰¾
+				return nil, errs.NotSupport
+			}
+		} else if secondTry && errs.IsObjectNotFound(err) {
 			// try the opposite
-			remoteFullPath = d.getPathForRemote(path, !firstTryIsFolder)
-			remoteObj, err2 = fs.Get(ctx, remoteFullPath, &fs.GetArgs{NoLog: true})
-			if err2 != nil {
-				return nil, err2
+			remoteFullPath = stdpath.Join(d.RemotePath, d.encryptPath(path, !firstTryIsFolder))
+			remoteObj, err = fs.Get(ctx, remoteFullPath, &fs.GetArgs{NoLog: true})
+			if err != nil {
+				return nil, err
 			}
 		} else {
 			return nil, err
 		}
 	}
-	var size int64 = 0
-	name := ""
-	if !remoteObj.IsDir() {
-		size, err = d.cipher.DecryptedSize(remoteObj.GetSize())
-		if err != nil {
-			log.Warnf("DecryptedSize failed for %s ,will use original size, err:%s", path, err)
-			size = remoteObj.GetSize()
-		}
-		name, err = d.cipher.DecryptFileName(remoteObj.GetName())
-		if err != nil {
-			log.Warnf("DecryptFileName failed for %s ,will use original name, err:%s", path, err)
-			name = remoteObj.GetName()
-		}
-	} else {
-		name, err = d.cipher.DecryptDirName(remoteObj.GetName())
-		if err != nil {
-			log.Warnf("DecryptDirName failed for %s ,will use original name, err:%s", path, err)
-			name = remoteObj.GetName()
+
+	size := remoteObj.GetSize()
+	name := remoteObj.GetName()
+	mask := model.GetObjMask(remoteObj) &^ model.Temp
+	if mask&model.Virtual == 0 {
+		if !remoteObj.IsDir() {
+			decryptedSize, err := d.cipher.DecryptedSize(size)
+			if err != nil {
+				log.Warnf("DecryptedSize failed for %s ,will use original size, err:%s", path, err)
+			} else {
+				size = decryptedSize
+			}
+			decryptedName, err := d.cipher.DecryptFileName(model.UnwrapObjName(remoteObj).GetName())
+			if err != nil {
+				log.Warnf("DecryptFileName failed for %s ,will use original name, err:%s", path, err)
+			} else {
+				name = decryptedName
+			}
+		} else {
+			decryptedName, err := d.cipher.DecryptDirName(model.UnwrapObjName(remoteObj).GetName())
+			if err != nil {
+				log.Warnf("DecryptDirName failed for %s ,will use original name, err:%s", path, err)
+			} else {
+				name = decryptedName
+			}
 		}
 	}
-	obj := &model.Object{
-		Path:     path,
+	return &model.Object{
+		Path:     remoteFullPath,
 		Name:     name,
 		Size:     size,
 		Modified: remoteObj.ModTime(),
 		IsFolder: remoteObj.IsDir(),
-	}
-	return obj, nil
-	// return nil, errs.ObjectNotFound
+		Ctime:    remoteObj.CreateTime(),
+		Mask:     mask,
+	}, nil
 }
 
 // https://github.com/rclone/rclone/blob/v1.67.0/backend/crypt/cipher.go#L37
 const fileHeaderSize = 32
 
-func (d *Crypt) Link(ctx context.Context, file model.Obj, args model.LinkArgs) (*model.Link, error) {
-	dstDirActualPath, err := d.getActualPathForRemote(file.GetPath(), false)
+func (d *Crypt) Link(ctx context.Context, file model.Obj, _ model.LinkArgs) (*model.Link, error) {
+	remoteStorage, remoteActualPath, err := op.GetStorageAndActualPath(file.GetPath())
 	if err != nil {
-		return nil, fmt.Errorf("failed to convert path to remote path: %w", err)
+		return nil, err
 	}
-	remoteLink, remoteFile, err := op.Link(ctx, d.remoteStorage, dstDirActualPath, args)
+	remoteLink, remoteFile, err := op.Link(ctx, remoteStorage, remoteActualPath, model.LinkArgs{})
 	if err != nil {
 		return nil, err
 	}
@@ -323,30 +311,23 @@ func (d *Crypt) Link(ctx context.Context, file model.Obj, args model.LinkArgs) (
 }
 
 func (d *Crypt) MakeDir(ctx context.Context, parentDir model.Obj, dirName string) error {
-	dstDirActualPath, err := d.getActualPathForRemote(parentDir.GetPath(), true)
+	remoteStorage, remoteActualPath, err := op.GetStorageAndActualPath(parentDir.GetPath())
 	if err != nil {
-		return fmt.Errorf("failed to convert path to remote path: %w", err)
+		return err
 	}
-	dir := d.cipher.EncryptDirName(dirName)
-	return op.MakeDir(ctx, d.remoteStorage, stdpath.Join(dstDirActualPath, dir))
+	encryptedName := d.cipher.EncryptDirName(dirName)
+	return op.MakeDir(ctx, remoteStorage, stdpath.Join(remoteActualPath, encryptedName))
 }
 
 func (d *Crypt) Move(ctx context.Context, srcObj, dstDir model.Obj) error {
-	srcRemoteActualPath, err := d.getActualPathForRemote(srcObj.GetPath(), srcObj.IsDir())
-	if err != nil {
-		return fmt.Errorf("failed to convert path to remote path: %w", err)
-	}
-	dstRemoteActualPath, err := d.getActualPathForRemote(dstDir.GetPath(), dstDir.IsDir())
-	if err != nil {
-		return fmt.Errorf("failed to convert path to remote path: %w", err)
-	}
-	return op.Move(ctx, d.remoteStorage, srcRemoteActualPath, dstRemoteActualPath)
+	_, err := fs.Move(ctx, srcObj.GetPath(), dstDir.GetPath())
+	return err
 }
 
 func (d *Crypt) Rename(ctx context.Context, srcObj model.Obj, newName string) error {
-	remoteActualPath, err := d.getActualPathForRemote(srcObj.GetPath(), srcObj.IsDir())
+	remoteStorage, remoteActualPath, err := op.GetStorageAndActualPath(srcObj.GetPath())
 	if err != nil {
-		return fmt.Errorf("failed to convert path to remote path: %w", err)
+		return err
 	}
 	var newEncryptedName string
 	if srcObj.IsDir() {
@@ -354,33 +335,26 @@ func (d *Crypt) Rename(ctx context.Context, srcObj model.Obj, newName string) er
 	} else {
 		newEncryptedName = d.cipher.EncryptFileName(newName)
 	}
-	return op.Rename(ctx, d.remoteStorage, remoteActualPath, newEncryptedName)
+	return op.Rename(ctx, remoteStorage, remoteActualPath, newEncryptedName)
 }
 
 func (d *Crypt) Copy(ctx context.Context, srcObj, dstDir model.Obj) error {
-	srcRemoteActualPath, err := d.getActualPathForRemote(srcObj.GetPath(), srcObj.IsDir())
-	if err != nil {
-		return fmt.Errorf("failed to convert path to remote path: %w", err)
-	}
-	dstRemoteActualPath, err := d.getActualPathForRemote(dstDir.GetPath(), dstDir.IsDir())
-	if err != nil {
-		return fmt.Errorf("failed to convert path to remote path: %w", err)
-	}
-	return op.Copy(ctx, d.remoteStorage, srcRemoteActualPath, dstRemoteActualPath)
+	_, err := fs.Copy(ctx, srcObj.GetPath(), dstDir.GetPath())
+	return err
 }
 
 func (d *Crypt) Remove(ctx context.Context, obj model.Obj) error {
-	remoteActualPath, err := d.getActualPathForRemote(obj.GetPath(), obj.IsDir())
+	remoteStorage, remoteActualPath, err := op.GetStorageAndActualPath(obj.GetPath())
 	if err != nil {
-		return fmt.Errorf("failed to convert path to remote path: %w", err)
+		return err
 	}
-	return op.Remove(ctx, d.remoteStorage, remoteActualPath)
+	return op.Remove(ctx, remoteStorage, remoteActualPath)
 }
 
 func (d *Crypt) Put(ctx context.Context, dstDir model.Obj, streamer model.FileStreamer, up driver.UpdateProgress) error {
-	dstDirActualPath, err := d.getActualPathForRemote(dstDir.GetPath(), true)
+	remoteStorage, remoteActualPath, err := op.GetStorageAndActualPath(dstDir.GetPath())
 	if err != nil {
-		return fmt.Errorf("failed to convert path to remote path: %w", err)
+		return err
 	}
 
 	// Encrypt the data into wrappedIn
@@ -404,15 +378,15 @@ func (d *Crypt) Put(ctx context.Context, dstDir model.Obj, streamer model.FileSt
 		ForceStreamUpload: true,
 		Exist:             streamer.GetExist(),
 	}
-	err = op.Put(ctx, d.remoteStorage, dstDirActualPath, streamOut, up, false)
-	if err != nil {
-		return err
-	}
-	return nil
+	return op.Put(ctx, remoteStorage, remoteActualPath, streamOut, up)
 }
 
 func (d *Crypt) GetDetails(ctx context.Context) (*model.StorageDetails, error) {
-	remoteDetails, err := op.GetStorageDetails(ctx, d.remoteStorage)
+	remoteStorage, _, err := op.GetStorageAndActualPath(d.RemotePath)
+	if err != nil {
+		return nil, errs.NotImplement
+	}
+	remoteDetails, err := op.GetStorageDetails(ctx, remoteStorage)
 	if err != nil {
 		return nil, err
 	}
@@ -421,8 +395,4 @@ func (d *Crypt) GetDetails(ctx context.Context) (*model.StorageDetails, error) {
 	}, nil
 }
 
-//func (d *Safe) Other(ctx context.Context, args model.OtherArgs) (interface{}, error) {
-//	return nil, errs.NotSupport
-//}
-
 var _ driver.Driver = (*Crypt)(nil)
diff --git a/drivers/crypt/meta.go b/drivers/crypt/meta.go
index b2d009ba3..6a4659910 100644
--- a/drivers/crypt/meta.go
+++ b/drivers/crypt/meta.go
@@ -6,11 +6,6 @@ import (
 )
 
 type Addition struct {
-	// Usually one of two
-	//driver.RootPath
-	//driver.RootID
-	// define other
-
 	FileNameEnc string `json:"filename_encryption" type:"select" required:"true" options:"off,standard,obfuscate" default:"off"`
 	DirNameEnc  string `json:"directory_name_encryption" type:"select" required:"true" options:"false,true" default:"false"`
 	RemotePath  string `json:"remote_path" required:"true" help:"This is where the encrypted data stores"`
@@ -32,6 +27,7 @@ var config = driver.Config{
 	NoCache:     true,
 	DefaultRoot: "/",
 	NoLinkURL:   true,
+	CheckStatus: true,
 }
 
 func init() {
diff --git a/drivers/crypt/util.go b/drivers/crypt/util.go
index 417059d38..e0f2bef74 100644
--- a/drivers/crypt/util.go
+++ b/drivers/crypt/util.go
@@ -4,8 +4,6 @@ import (
 	stdpath "path"
 	"path/filepath"
 	"strings"
-
-	"github.com/OpenListTeam/OpenList/v4/internal/op"
 )
 
 // will give the best guessing based on the path
@@ -15,30 +13,17 @@ func guessPath(path string) (isFolder, secondTry bool) {
 		return true, false
 	}
 	lastSlash := strings.LastIndex(path, "/")
-	if strings.Index(path[lastSlash:], ".") < 0 {
+	if !strings.Contains(path[lastSlash:], ".") {
 		//no dot, try folder then try file
 		return true, true
 	}
 	return false, true
 }
 
-func (d *Crypt) getPathForRemote(path string, isFolder bool) (remoteFullPath string) {
-	if isFolder && !strings.HasSuffix(path, "/") {
-		path = path + "/"
+func (d *Crypt) encryptPath(path string, isFolder bool) string {
+	if isFolder {
+		return d.cipher.EncryptDirName(path)
 	}
 	dir, fileName := filepath.Split(path)
-
-	remoteDir := d.cipher.EncryptDirName(dir)
-	remoteFileName := ""
-	if len(strings.TrimSpace(fileName)) > 0 {
-		remoteFileName = d.cipher.EncryptFileName(fileName)
-	}
-	return stdpath.Join(d.RemotePath, remoteDir, remoteFileName)
-
-}
-
-// actual path is used for internal only. any link for user should come from remoteFullPath
-func (d *Crypt) getActualPathForRemote(path string, isFolder bool) (string, error) {
-	_, remoteActualPath, err := op.GetStorageAndActualPath(d.getPathForRemote(path, isFolder))
-	return remoteActualPath, err
+	return stdpath.Join(d.cipher.EncryptDirName(dir), d.cipher.EncryptFileName(fileName))
 }
diff --git a/drivers/doubao/util.go b/drivers/doubao/util.go
index 686608971..b1b38ee92 100644
--- a/drivers/doubao/util.go
+++ b/drivers/doubao/util.go
@@ -10,7 +10,6 @@ import (
 	"fmt"
 	"hash/crc32"
 	"io"
-	"math"
 	"math/rand"
 	"net/http"
 	"net/url"
@@ -18,7 +17,6 @@ import (
 	"sort"
 	"strconv"
 	"strings"
-	"sync"
 	"time"
 
 	"github.com/OpenListTeam/OpenList/v4/drivers/base"
@@ -62,7 +60,7 @@ const (
 	VideoDataType    = "video"
 	DefaultChunkSize = int64(5 * 1024 * 1024) // 5MB
 	MaxRetryAttempts = 3                      // æœ€å¤§é‡è¯•æ¬¡æ•°
-	UserAgent        = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"
+	UserAgent        = base.UserAgentNT
 	Region           = "cn-north-1"
 	UploadTimeout    = 3 * time.Minute
 )
@@ -562,9 +560,7 @@ func (d *Doubao) UploadByMultipart(ctx context.Context, config *UploadConfig, fi
 		retry.MaxJitter(200*time.Millisecond),
 	)
 
-	var partsMutex sync.Mutex
 	// å¹¶è¡Œä¸Šä¼ æ‰€æœ‰åˆ†ç‰‡
-	hash := crc32.NewIEEE()
 	for partIndex := range totalParts {
 		if utils.IsCanceled(uploadCtx) {
 			break
@@ -578,32 +574,38 @@ func (d *Doubao) UploadByMultipart(ctx context.Context, config *UploadConfig, fi
 			size = fileSize - offset
 		}
 		var reader io.ReadSeeker
-		var rateLimitedRd io.Reader
 		crc32Value := ""
 		threadG.GoWithLifecycle(errgroup.Lifecycle{
-			Before: func(ctx context.Context) error {
-				if reader == nil {
-					var err error
-					reader, err = ss.GetSectionReader(offset, size)
-					if err != nil {
-						return err
-					}
-					hash.Reset()
-					w, err := utils.CopyWithBuffer(hash, reader)
+			Before: func(ctx context.Context) (err error) {
+				reader, err = ss.GetSectionReader(offset, size)
+				return
+			},
+			Do: func(ctx context.Context) (err error) {
+				reader.Seek(0, io.SeekStart)
+				if crc32Value == "" {
+					// æŠŠè€—æ—¶çš„è®¡ç®—æ”¾åœ¨è¿™é‡Œï¼Œé¿å…é˜»å¡å…¶ä»–åç¨‹
+					crc32Hash := crc32.NewIEEE()
+					w, err := utils.CopyWithBuffer(crc32Hash, reader)
 					if w != size {
 						return fmt.Errorf("failed to read all data: (expect =%d, actual =%d) %w", size, w, err)
 					}
-					crc32Value = hex.EncodeToString(hash.Sum(nil))
-					rateLimitedRd = driver.NewLimitedUploadStream(ctx, reader)
+					crc32Value = hex.EncodeToString(crc32Hash.Sum(nil))
+					reader.Seek(0, io.SeekStart)
 				}
-				return nil
-			},
-			Do: func(ctx context.Context) error {
-				reader.Seek(0, io.SeekStart)
-				req, err := http.NewRequestWithContext(ctx, http.MethodPost, fmt.Sprintf("%s?uploadid=%s&part_number=%d&phase=transfer", uploadUrl, uploadID, partNumber), rateLimitedRd)
+				req, err := http.NewRequestWithContext(
+					ctx,
+					http.MethodPost,
+					uploadUrl,
+					driver.NewLimitedUploadStream(ctx, reader),
+				)
 				if err != nil {
 					return err
 				}
+				query := req.URL.Query()
+				query.Add("uploadid", uploadID)
+				query.Add("part_number", strconv.FormatInt(partNumber, 10))
+				query.Add("phase", "transfer")
+				req.URL.RawQuery = query.Encode()
 				req.Header = map[string][]string{
 					"Referer":             {BaseURL + "/"},
 					"Origin":              {BaseURL},
@@ -629,16 +631,14 @@ func (d *Doubao) UploadByMultipart(ctx context.Context, config *UploadConfig, fi
 					return fmt.Errorf("upload part failed: crc32 mismatch, expected %s, got %s", crc32Value, uploadResp.Data.Crc32)
 				}
 				// è®°å½•æˆåŠŸä¸Šä¼ çš„åˆ†ç‰‡
-				partsMutex.Lock()
 				parts[partIndex] = UploadPart{
 					PartNumber: strconv.FormatInt(partNumber, 10),
 					Etag:       uploadResp.Data.Etag,
 					Crc32:      crc32Value,
 				}
-				partsMutex.Unlock()
 				// æ›´æ–°è¿›åº¦
-				progress := 10.0 + 90.0*float64(threadG.Success()+1)/float64(totalParts)
-				up(math.Min(progress, 95.0))
+				progress := 95 * float64(threadG.Success()+1) / float64(totalParts)
+				up(progress)
 				return nil
 			},
 			After: func(err error) {
diff --git a/drivers/doubao_share/driver.go b/drivers/doubao_share/driver.go
index 89cda2129..4d23d7022 100644
--- a/drivers/doubao_share/driver.go
+++ b/drivers/doubao_share/driver.go
@@ -40,6 +40,7 @@ func (d *DoubaoShare) Drop(ctx context.Context) error {
 	return nil
 }
 
+// æ½œåœ¨bugï¼šé…ç½®äºŒçº§ç›®å½•æ—¶ï¼Œå¯èƒ½ä¼šå‡ºé—®é¢˜
 func (d *DoubaoShare) List(ctx context.Context, dir model.Obj, args model.ListArgs) ([]model.Obj, error) {
 	// æ£€æŸ¥æ˜¯å¦ä¸ºæ ¹ç›®å½•
 	if dir.GetID() == "" && dir.GetPath() == "/" {
@@ -91,18 +92,17 @@ func (d *DoubaoShare) Link(ctx context.Context, file model.Obj, args model.LinkA
 
 			downloadUrl = r.Data.OriginalMediaInfo.MainURL
 		default:
-			var r GetFileUrlResp
-			_, err := d.request("/alice/message/get_file_url", http.MethodPost, func(req *resty.Request) {
+			var r GetDownloadInfoResp
+			_, err := d.request("/samantha/aispace/get_download_info", http.MethodPost, func(req *resty.Request) {
 				req.SetBody(base.Json{
-					"uris": []string{u.Key},
-					"type": FileNodeType[u.NodeType],
+					"requests": []base.Json{{"node_id": file.GetID()}},
 				})
 			}, &r)
 			if err != nil {
 				return nil, err
 			}
 
-			downloadUrl = r.Data.FileUrls[0].MainURL
+			downloadUrl = r.Data.DownloadInfos[0].MainURL
 		}
 
 		// ç”Ÿæˆæ ‡å‡†çš„Content-Disposition
diff --git a/drivers/doubao_share/types.go b/drivers/doubao_share/types.go
index 4ef12cedb..15e107656 100644
--- a/drivers/doubao_share/types.go
+++ b/drivers/doubao_share/types.go
@@ -115,14 +115,14 @@ type FilePath []struct {
 	UpdateTime          int64  `json:"update_time"`
 }
 
-type GetFileUrlResp struct {
+type GetDownloadInfoResp struct {
 	BaseResp
 	Data struct {
-		FileUrls []struct {
-			URI     string `json:"uri"`
-			MainURL string `json:"main_url"`
-			BackURL string `json:"back_url"`
-		} `json:"file_urls"`
+		DownloadInfos []struct {
+			NodeID    string `json:"node_id"`
+			MainURL   string `json:"main_url"`
+			BackupURL string `json:"backup_url"`
+		} `json:"download_infos"`
 	} `json:"data"`
 }
 
diff --git a/drivers/doubao_share/util.go b/drivers/doubao_share/util.go
index 8e9887152..a52130305 100644
--- a/drivers/doubao_share/util.go
+++ b/drivers/doubao_share/util.go
@@ -43,7 +43,7 @@ const (
 	FileDataType  = "file"
 	ImgDataType   = "image"
 	VideoDataType = "video"
-	UserAgent     = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"
+	UserAgent     = base.UserAgentNT
 )
 
 func (d *DoubaoShare) request(path string, method string, callback base.ReqCallback, resp interface{}) ([]byte, error) {
diff --git a/drivers/dropbox/util.go b/drivers/dropbox/util.go
index d7404a429..ac0bcceeb 100644
--- a/drivers/dropbox/util.go
+++ b/drivers/dropbox/util.go
@@ -24,7 +24,6 @@ func (d *Dropbox) refreshToken() error {
 			ErrorMessage string `json:"text"`
 		}
 		_, err := base.RestyClient.R().
-			SetHeader("User-Agent", "Mozilla/5.0 (Macintosh; Apple macOS 15_5) AppleWebKit/537.36 (KHTML, like Gecko) Safari/537.36 Chrome/138.0.0.0 Openlist/425.6.30").
 			SetResult(&resp).
 			SetQueryParams(map[string]string{
 				"refresh_ui": d.RefreshToken,
@@ -176,12 +175,12 @@ func (d *Dropbox) finishUploadSession(ctx context.Context, toPath string, offset
 	req.Header.Set("Content-Type", "application/octet-stream")
 	req.Header.Set("Authorization", "Bearer "+d.AccessToken)
 	if d.RootNamespaceId != "" {
-	apiPathRootJson, err := d.buildPathRootHeader()
-	if err != nil {
-	    return err
+		apiPathRootJson, err := d.buildPathRootHeader()
+		if err != nil {
+			return err
+		}
+		req.Header.Set("Dropbox-API-Path-Root", apiPathRootJson)
 	}
-	req.Header.Set("Dropbox-API-Path-Root", apiPathRootJson)
-}
 
 	uploadFinishArgs := UploadFinishArgs{
 		Commit: struct {
@@ -227,12 +226,12 @@ func (d *Dropbox) startUploadSession(ctx context.Context) (string, error) {
 	req.Header.Set("Content-Type", "application/octet-stream")
 	req.Header.Set("Authorization", "Bearer "+d.AccessToken)
 	if d.RootNamespaceId != "" {
-	apiPathRootJson, err := d.buildPathRootHeader()
-	if err != nil {
-	    return "", err
+		apiPathRootJson, err := d.buildPathRootHeader()
+		if err != nil {
+			return "", err
+		}
+		req.Header.Set("Dropbox-API-Path-Root", apiPathRootJson)
 	}
-	req.Header.Set("Dropbox-API-Path-Root", apiPathRootJson)
-}
 	req.Header.Set("Dropbox-API-Arg", "{\"close\":false}")
 
 	res, err := base.HttpClient.Do(req)
@@ -249,9 +248,8 @@ func (d *Dropbox) startUploadSession(ctx context.Context) (string, error) {
 }
 
 func (d *Dropbox) buildPathRootHeader() (string, error) {
-    return utils.Json.MarshalToString(map[string]interface{}{
-        ".tag": "root",
-        "root": d.RootNamespaceId,
-    })
+	return utils.Json.MarshalToString(map[string]interface{}{
+		".tag": "root",
+		"root": d.RootNamespaceId,
+	})
 }
-
diff --git a/drivers/github_releases/driver.go b/drivers/github_releases/driver.go
index 2486cbc34..8a8025c5a 100644
--- a/drivers/github_releases/driver.go
+++ b/drivers/github_releases/driver.go
@@ -4,6 +4,7 @@ import (
 	"context"
 	"fmt"
 	"net/http"
+	stdpath "path"
 	"strings"
 
 	"github.com/OpenListTeam/OpenList/v4/internal/driver"
@@ -51,7 +52,7 @@ func (d *GithubReleases) List(ctx context.Context, dir model.Obj, args model.Lis
 				if d.Addition.ShowReadme {
 					files = append(files, point.GetOtherFile(d.GetRequest, args.Refresh)...)
 				}
-				if d.Addition.ShowSourceCode{
+				if d.Addition.ShowSourceCode {
 					files = append(files, point.GetSourceCode()...)
 				}
 			} else if strings.HasPrefix(point.Point, path) { // ä»“åº“ç›®å½•çš„çˆ¶ç›®å½•
@@ -70,7 +71,7 @@ func (d *GithubReleases) List(ctx context.Context, dir model.Obj, args model.Lis
 				}
 				if !hasSameDir {
 					files = append(files, File{
-						Path:     path + "/" + nextDir,
+						Path:     stdpath.Join(path, nextDir),
 						FileName: nextDir,
 						Size:     point.GetLatestSize(),
 						UpdateAt: point.Release.PublishedAt,
@@ -105,7 +106,7 @@ func (d *GithubReleases) List(ctx context.Context, dir model.Obj, args model.Lis
 				if !hasSameDir {
 					files = append(files, File{
 						FileName: nextDir,
-						Path:     path + "/" + nextDir,
+						Path:     stdpath.Join(path, nextDir),
 						Size:     point.GetAllVersionSize(),
 						UpdateAt: (*point.Releases)[0].PublishedAt,
 						CreateAt: (*point.Releases)[0].CreatedAt,
@@ -121,7 +122,7 @@ func (d *GithubReleases) List(ctx context.Context, dir model.Obj, args model.Lis
 
 				files = append(files, point.GetReleaseByTagName(tagName)...)
 
-				if d.Addition.ShowSourceCode{
+				if d.Addition.ShowSourceCode {
 					files = append(files, point.GetSourceCodeByTagName(tagName)...)
 				}
 			}
diff --git a/drivers/github_releases/meta.go b/drivers/github_releases/meta.go
index a7b3a42a4..fc5fad695 100644
--- a/drivers/github_releases/meta.go
+++ b/drivers/github_releases/meta.go
@@ -6,7 +6,7 @@ import (
 )
 
 type Addition struct {
-	driver.RootID
+	driver.RootPath
 	RepoStructure  string `json:"repo_structure" type:"text" required:"true" default:"OpenListTeam/OpenList" help:"structure:[path:]org/repo"`
 	ShowReadme     bool   `json:"show_readme" type:"bool" default:"true" help:"show READMEã€LICENSE file"`
 	Token          string `json:"token" type:"string" required:"false" help:"GitHub token, if you want to access private repositories or increase the rate limit"`
diff --git a/drivers/github_releases/types.go b/drivers/github_releases/types.go
index 6e0fa2398..663aec77e 100644
--- a/drivers/github_releases/types.go
+++ b/drivers/github_releases/types.go
@@ -2,6 +2,7 @@ package github_releases
 
 import (
 	"encoding/json"
+	"path"
 	"strings"
 	"time"
 
@@ -45,10 +46,10 @@ func (m *MountPoint) RequestReleases(get func(url string) (*resty.Response, erro
 
 // è·å–æœ€æ–°ç‰ˆæœ¬
 func (m *MountPoint) GetLatestRelease() []File {
-	files := make([]File, 0)
+	files := make([]File, 0, len(m.Release.Assets))
 	for _, asset := range m.Release.Assets {
 		files = append(files, File{
-			Path:     m.Point + "/" + asset.Name,
+			Path:     path.Join(m.Point, asset.Name),
 			FileName: asset.Name,
 			Size:     asset.Size,
 			Type:     "file",
@@ -74,7 +75,7 @@ func (m *MountPoint) GetAllVersion() []File {
 	files := make([]File, 0)
 	for _, release := range *m.Releases {
 		file := File{
-			Path:     m.Point + "/" + release.TagName,
+			Path:     path.Join(m.Point, release.TagName),
 			FileName: release.TagName,
 			Size:     m.GetSizeByTagName(release.TagName),
 			Type:     "dir",
@@ -97,7 +98,7 @@ func (m *MountPoint) GetReleaseByTagName(tagName string) []File {
 			files := make([]File, 0)
 			for _, asset := range item.Assets {
 				files = append(files, File{
-					Path:     m.Point + "/" + tagName + "/" + asset.Name,
+					Path:     path.Join(m.Point, tagName, asset.Name),
 					FileName: asset.Name,
 					Size:     asset.Size,
 					Type:     "file",
@@ -148,7 +149,7 @@ func (m *MountPoint) GetSourceCode() []File {
 
 	// æ— æ³•è·å–æ–‡ä»¶å¤§å°ï¼Œæ­¤å¤„è®¾ä¸º 1
 	files = append(files, File{
-		Path:     m.Point + "/" + "Source code (zip)",
+		Path:     path.Join(m.Point, "Source code (zip)"),
 		FileName: "Source code (zip)",
 		Size:     1,
 		Type:     "file",
@@ -157,7 +158,7 @@ func (m *MountPoint) GetSourceCode() []File {
 		Url:      m.Release.ZipballUrl,
 	})
 	files = append(files, File{
-		Path:     m.Point + "/" + "Source code (tar.gz)",
+		Path:     path.Join(m.Point, "Source code (tar.gz)"),
 		FileName: "Source code (tar.gz)",
 		Size:     1,
 		Type:     "file",
@@ -174,7 +175,7 @@ func (m *MountPoint) GetSourceCodeByTagName(tagName string) []File {
 		if item.TagName == tagName {
 			files := make([]File, 0)
 			files = append(files, File{
-				Path:     m.Point + "/" + "Source code (zip)",
+				Path:     path.Join(m.Point, "Source code (zip)"),
 				FileName: "Source code (zip)",
 				Size:     1,
 				Type:     "file",
@@ -183,7 +184,7 @@ func (m *MountPoint) GetSourceCodeByTagName(tagName string) []File {
 				Url:      item.ZipballUrl,
 			})
 			files = append(files, File{
-				Path:     m.Point + "/" + "Source code (tar.gz)",
+				Path:     path.Join(m.Point, "Source code (tar.gz)"),
 				FileName: "Source code (tar.gz)",
 				Size:     1,
 				Type:     "file",
@@ -209,7 +210,7 @@ func (m *MountPoint) GetOtherFile(get func(url string) (*resty.Response, error),
 	for _, file := range *m.OtherFile {
 		if strings.HasSuffix(file.Name, ".md") || strings.HasPrefix(file.Name, "LICENSE") {
 			files = append(files, File{
-				Path:     m.Point + "/" + file.Name,
+				Path:     path.Join(m.Point, file.Name),
 				FileName: file.Name,
 				Size:     file.Size,
 				Type:     "file",
diff --git a/drivers/google_drive/util.go b/drivers/google_drive/util.go
index e2e609a89..042abafa4 100644
--- a/drivers/google_drive/util.go
+++ b/drivers/google_drive/util.go
@@ -58,7 +58,6 @@ func (d *GoogleDrive) refreshToken() error {
 			ErrorMessage string `json:"text"`
 		}
 		_, err := base.RestyClient.R().
-			SetHeader("User-Agent", "Mozilla/5.0 (Macintosh; Apple macOS 15_5) AppleWebKit/537.36 (KHTML, like Gecko) Safari/537.36 Chrome/138.0.0.0 Openlist/425.6.30").
 			SetResult(&resp).
 			SetQueryParams(map[string]string{
 				"refresh_ui": d.RefreshToken,
@@ -383,6 +382,7 @@ func (d *GoogleDrive) chunkUpload(ctx context.Context, file model.FileStreamer,
 			up(float64(offset+chunkSize) / float64(file.GetSize()) * 100)
 			return nil
 		},
+			retry.Context(ctx),
 			retry.Attempts(3),
 			retry.DelayType(retry.BackOffDelay),
 			retry.Delay(time.Second))
diff --git a/drivers/halalcloud_open/driver_curd_impl.go b/drivers/halalcloud_open/driver_curd_impl.go
index 48dfaf507..fd93befa1 100644
--- a/drivers/halalcloud_open/driver_curd_impl.go
+++ b/drivers/halalcloud_open/driver_curd_impl.go
@@ -2,7 +2,6 @@ package halalcloudopen
 
 import (
 	"context"
-	"strconv"
 
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
 	sdkModel "github.com/halalcloud/golang-sdk-lite/halalcloud/model"
@@ -19,7 +18,7 @@ func (d *HalalCloudOpen) getFiles(ctx context.Context, dir model.Obj) ([]model.O
 		result, err := d.sdkUserFileService.List(ctx, &sdkUserFile.FileListRequest{
 			Parent: &sdkUserFile.File{Path: dir.GetPath()},
 			ListInfo: &sdkModel.ScanListRequest{
-				Limit: strconv.FormatInt(limit, 10),
+				Limit: limit,
 				Token: token,
 			},
 		})
diff --git a/drivers/halalcloud_open/halalcloud_upload.go b/drivers/halalcloud_open/halalcloud_upload.go
index f5d173f15..16a342fd9 100644
--- a/drivers/halalcloud_open/halalcloud_upload.go
+++ b/drivers/halalcloud_open/halalcloud_upload.go
@@ -16,6 +16,7 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
 	sdkUserFile "github.com/halalcloud/golang-sdk-lite/halalcloud/services/userfile"
 	"github.com/ipfs/go-cid"
+	log "github.com/sirupsen/logrus"
 )
 
 func (d *HalalCloudOpen) put(ctx context.Context, dstDir model.Obj, fileStream model.FileStreamer, up driver.UpdateProgress) (model.Obj, error) {
@@ -51,52 +52,39 @@ func (d *HalalCloudOpen) put(ctx context.Context, dstDir model.Obj, fileStream m
 		Version:  1,
 	}
 	blockSize := uploadTask.BlockSize
-	useSingleUpload := true
 	//
-	if fileStream.GetSize() <= int64(blockSize) || d.uploadThread <= 1 {
-		useSingleUpload = true
-	}
 	// Not sure whether FileStream supports concurrent read and write operations, so currently using single-threaded upload to ensure safety.
 	// read file
-	if useSingleUpload {
-		bufferSize := int(blockSize)
-		buffer := make([]byte, bufferSize)
-		reader := driver.NewLimitedUploadStream(ctx, fileStream)
-		teeReader := io.TeeReader(reader, driver.NewProgress(fileStream.GetSize(), up))
-		// fileStream.Seek(0, os.SEEK_SET)
-		for {
-			n, err := teeReader.Read(buffer)
-			if n > 0 {
-				data := buffer[:n]
-				uploadCid, err := postFileSlice(ctx, data, uploadTask.Task, uploadTask.UploadAddress, prefix, retryTimes)
+	bufferSize := int(blockSize)
+	buffer := make([]byte, bufferSize)
+	offset := 0
+	teeReader := io.TeeReader(fileStream, driver.NewProgress(fileStream.GetSize(), up))
+	for {
+		n, err := teeReader.Read(buffer[offset:]) // è¿™é‡Œ len(buf[offset:]) <= 4MB
+		if n > 0 {
+			offset += n
+			if offset == int(blockSize) {
+				uploadCid, err := postFileSlice(ctx, buffer, uploadTask.Task, uploadTask.UploadAddress, prefix, retryTimes)
 				if err != nil {
 					return nil, err
 				}
 				slicesList = append(slicesList, uploadCid.String())
-			}
-			if err == io.EOF || n == 0 {
-				break
+				offset = 0
 			}
 		}
-	} else {
-		// TODO: implement multipart upload, currently using single-threaded upload to ensure safety.
-		bufferSize := int(blockSize)
-		buffer := make([]byte, bufferSize)
-		reader := driver.NewLimitedUploadStream(ctx, fileStream)
-		teeReader := io.TeeReader(reader, driver.NewProgress(fileStream.GetSize(), up))
-		for {
-			n, err := teeReader.Read(buffer)
-			if n > 0 {
-				data := buffer[:n]
-				uploadCid, err := postFileSlice(ctx, data, uploadTask.Task, uploadTask.UploadAddress, prefix, retryTimes)
-				if err != nil {
-					return nil, err
+
+		if err != nil {
+			if err == io.EOF {
+				if offset > 0 {
+					uploadCid, err := postFileSlice(ctx, buffer[:offset], uploadTask.Task, uploadTask.UploadAddress, prefix, retryTimes)
+					if err != nil {
+						return nil, err
+					}
+					slicesList = append(slicesList, uploadCid.String())
 				}
-				slicesList = append(slicesList, uploadCid.String())
-			}
-			if err == io.EOF || n == 0 {
 				break
 			}
+			return nil, err
 		}
 	}
 	newFile, err := makeFile(ctx, slicesList, uploadTask.Task, uploadTask.UploadAddress, retryTimes)
@@ -118,6 +106,7 @@ func makeFile(ctx context.Context, fileSlice []string, taskID string, uploadAddr
 		if ctx.Err() != nil {
 			return nil, err
 		}
+		log.Errorf("make file slice failed, retrying... error: %s", err.Error())
 		if strings.Contains(err.Error(), "not found") {
 			return nil, err
 		}
@@ -156,15 +145,23 @@ func doMakeFile(fileSlice []string, taskID string, uploadAddress string) (*sdkUs
 	if httpResponse.StatusCode != http.StatusOK && httpResponse.StatusCode != http.StatusCreated {
 		b, _ := io.ReadAll(httpResponse.Body)
 		message := string(b)
+		log.Errorf("make file failed, status code: %d, message: %s", httpResponse.StatusCode, message)
+
 		return nil, fmt.Errorf("mk file slice failed, status code: %d, message: %s", httpResponse.StatusCode, message)
 	}
 	b, _ := io.ReadAll(httpResponse.Body)
-	var result *sdkUserFile.File
+	var result *UploadedFile
 	err = json.Unmarshal(b, &result)
 	if err != nil {
+		log.Errorf("make file failed from response, status code: %d, message: %s", httpResponse.StatusCode, string(b))
 		return nil, err
 	}
-	return result, nil
+	return &sdkUserFile.File{
+		Identity:        result.Identity,
+		Path:            result.Path,
+		Size:            result.Size,
+		ContentIdentity: result.ContentIdentity,
+	}, nil
 }
 func postFileSlice(ctx context.Context, fileSlice []byte, taskID string, uploadAddress string, preix cid.Prefix, retry int) (cid.Cid, error) {
 	var lastError error = nil
@@ -214,9 +211,11 @@ func doPostFileSlice(fileSlice []byte, taskID string, uploadAddress string, prei
 	}
 	httpResponse, err := httpClient.Do(&httpRequest)
 	if err != nil {
+		log.Errorf("access %s failed, method: %s", accessUrl, http.MethodGet)
 		return cid.Undef, err
 	}
 	if httpResponse.StatusCode != http.StatusOK {
+		log.Errorf("access %s failed, method: %s, status code: %d", accessUrl, http.MethodGet, httpResponse.StatusCode)
 		return cid.Undef, fmt.Errorf("upload file slice failed, status code: %d", httpResponse.StatusCode)
 	}
 	var result bool
@@ -250,6 +249,7 @@ func doPostFileSlice(fileSlice []byte, taskID string, uploadAddress string, prei
 	if httpResponse.StatusCode != http.StatusOK && httpResponse.StatusCode != http.StatusCreated {
 		b, _ := io.ReadAll(httpResponse.Body)
 		message := string(b)
+		log.Errorf("upload file slice failed, status code: %d, message: %s", httpResponse.StatusCode, message)
 		return cid.Undef, fmt.Errorf("upload file slice failed, status code: %d, message: %s", httpResponse.StatusCode, message)
 	}
 	//
diff --git a/drivers/halalcloud_open/meta.go b/drivers/halalcloud_open/meta.go
index 9d5b16e7d..62f280b4e 100644
--- a/drivers/halalcloud_open/meta.go
+++ b/drivers/halalcloud_open/meta.go
@@ -30,3 +30,11 @@ func init() {
 		return &HalalCloudOpen{}
 	})
 }
+
+type UploadedFile struct {
+	Identity        string `json:"identity"`
+	UserIdentity    string `json:"user_identity"`
+	Path            string `json:"path"`
+	Size            int64  `json:"size"`
+	ContentIdentity string `json:"content_identity"`
+}
diff --git a/drivers/ilanzou/driver.go b/drivers/ilanzou/driver.go
index 2335cecde..264aa16f5 100644
--- a/drivers/ilanzou/driver.go
+++ b/drivers/ilanzou/driver.go
@@ -152,8 +152,7 @@ func (d *ILanZou) Link(ctx context.Context, file model.Obj, args model.LinkArgs)
 	req := base.NoRedirectClient.R()
 
 	req.SetHeaders(map[string]string{
-		"Referer":    d.conf.site + "/",
-		"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 Edg/125.0.0.0",
+		"Referer": d.conf.site + "/",
 	})
 	if d.Addition.Ip != "" {
 		req.SetHeader("X-Forwarded-For", d.Addition.Ip)
@@ -409,9 +408,10 @@ func (d *ILanZou) GetDetails(ctx context.Context) (*model.StorageDetails, error)
 	if err != nil {
 		return nil, err
 	}
+	vipSize := utils.Json.Get(res, "map", "vipSize").ToUint64() * 1024
 	totalSize := utils.Json.Get(res, "map", "totalSize").ToUint64() * 1024
 	rewardSize := utils.Json.Get(res, "map", "rewardSize").ToUint64() * 1024
-	total := totalSize + rewardSize
+	total := totalSize + rewardSize + vipSize
 	used := utils.Json.Get(res, "map", "usedSize").ToUint64() * 1024
 	return &model.StorageDetails{
 		DiskUsage: driver.DiskUsageFromUsedAndTotal(used, total),
diff --git a/drivers/ilanzou/util.go b/drivers/ilanzou/util.go
index 3d26ebde2..ea03cfd02 100644
--- a/drivers/ilanzou/util.go
+++ b/drivers/ilanzou/util.go
@@ -71,9 +71,8 @@ func (d *ILanZou) request(pathname, method string, callback base.ReqCallback, pr
 	req.SetHeaders(map[string]string{
 		"Origin":          d.conf.site,
 		"Referer":         d.conf.site + "/",
-		"User-Agent":      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 Edg/125.0.0.0",
-		"Accept-Encoding": "gzip, deflate, br, zstd",
-		"Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6,mt;q=0.5",
+		"Accept-Encoding": "gzip",
+		"Accept-Language": "zh-CN,zh;q=0.9,en-US,en;q=0.8",
 	})
 
 	if d.Addition.Ip != "" {
diff --git a/drivers/lanzou/driver.go b/drivers/lanzou/driver.go
index 6fa269930..01d7c1ece 100644
--- a/drivers/lanzou/driver.go
+++ b/drivers/lanzou/driver.go
@@ -31,7 +31,7 @@ func (d *LanZou) GetAddition() driver.Additional {
 
 func (d *LanZou) Init(ctx context.Context) (err error) {
 	if d.UserAgent == "" {
-		d.UserAgent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.39 (KHTML, like Gecko) Chrome/89.0.4389.111 Safari/537.39"
+		d.UserAgent = base.UserAgentNT
 	}
 	switch d.Type {
 	case "account":
diff --git a/drivers/lanzou/meta.go b/drivers/lanzou/meta.go
index 50d88082e..fca9b88f5 100644
--- a/drivers/lanzou/meta.go
+++ b/drivers/lanzou/meta.go
@@ -17,7 +17,7 @@ type Addition struct {
 	SharePassword  string `json:"share_password"`
 	BaseUrl        string `json:"baseUrl" required:"true" default:"https://pc.woozooo.com" help:"basic URL for file operation"`
 	ShareUrl       string `json:"shareUrl" required:"true" default:"https://pan.lanzoui.com" help:"used to get the sharing page"`
-	UserAgent      string `json:"user_agent" required:"true" default:"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.39 (KHTML, like Gecko) Chrome/89.0.4389.111 Safari/537.39"`
+	UserAgent      string `json:"user_agent" required:"true" default:"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.39 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.39"`
 	RepairFileInfo bool   `json:"repair_file_info" help:"To use webdav, you need to enable it"`
 }
 
diff --git a/drivers/lenovonas_share/driver.go b/drivers/lenovonas_share/driver.go
index 0e5045340..012e2e63a 100644
--- a/drivers/lenovonas_share/driver.go
+++ b/drivers/lenovonas_share/driver.go
@@ -2,6 +2,7 @@ package LenovoNasShare
 
 import (
 	"context"
+	"fmt"
 	"net/http"
 	"net/url"
 	"strings"
@@ -47,12 +48,7 @@ func (d *LenovoNasShare) Drop(ctx context.Context) error {
 
 func (d *LenovoNasShare) List(ctx context.Context, dir model.Obj, args model.ListArgs) ([]model.Obj, error) {
 	d.checkStoken() // æ£€æŸ¥stokenæ˜¯å¦è¿‡æœŸ
-	files := make([]File, 0)
-
-	path := dir.GetPath()
-	if path == "" && !d.ShowRootFolder && d.RootFolderPath != "" {
-		path = d.RootFolderPath
-	}
+	path := fmt.Sprintf("/%s", strings.Trim(dir.GetPath(), "/"))
 
 	var resp Files
 	query := map[string]string{
@@ -69,15 +65,14 @@ func (d *LenovoNasShare) List(ctx context.Context, dir model.Obj, args model.Lis
 		return nil, err
 	}
 
-	files = append(files, resp.Data.List...)
-
-	return utils.SliceConvert(files, func(src File) (model.Obj, error) {
+	return utils.SliceConvert(resp.Data.List, func(src File) (model.Obj, error) {
 		if src.IsDir() {
 			return src, nil
 		}
 		return &model.ObjThumb{
 			Object: model.Object{
 				Name:     src.GetName(),
+				Path:     src.GetPath(),
 				Size:     src.GetSize(),
 				Modified: src.ModTime(),
 				IsFolder: src.IsDir(),
diff --git a/drivers/mediafire/driver.go b/drivers/mediafire/driver.go
index bd2502590..d03ce672a 100644
--- a/drivers/mediafire/driver.go
+++ b/drivers/mediafire/driver.go
@@ -60,20 +60,24 @@ func (d *Mediafire) GetAddition() driver.Additional {
 
 // Init initializes the MediaFire driver with session token and cookie validation
 func (d *Mediafire) Init(ctx context.Context) error {
-	if d.SessionToken == "" {
-		return fmt.Errorf("Init :: [MediaFire] {critical} missing sessionToken")
-	}
-
 	if d.Cookie == "" {
 		return fmt.Errorf("Init :: [MediaFire] {critical} missing Cookie")
 	}
+
+	// If SessionToken is empty, try to get it from cookie
+	if d.SessionToken == "" {
+		if _, err := d.getSessionToken(ctx); err != nil {
+			return fmt.Errorf("Init :: [MediaFire] {critical} failed to get session token from cookie: %w", err)
+		}
+	}
+
 	// Setup rate limiter if rate limit is configured
 	if d.LimitRate > 0 {
 		d.limiter = rate.NewLimiter(rate.Limit(d.LimitRate), 1)
 	}
+
 	// Validate and refresh session token if needed
 	if _, err := d.getSessionToken(ctx); err != nil {
-
 		d.renewToken(ctx)
 
 		// Avoids 10 mins token expiry (6- 9)
@@ -387,8 +391,8 @@ func (d *Mediafire) Put(ctx context.Context, dstDir model.Obj, file model.FileSt
 		}
 	} else {
 		pollKey = checkResp.Response.ResumableUpload.UploadKey
-		up(100.0)
 	}
+	defer up(100.0)
 
 	pollResp, err := d.pollUpload(ctx, pollKey)
 	if err != nil {
@@ -429,3 +433,4 @@ func (d *Mediafire) GetDetails(ctx context.Context) (*model.StorageDetails, erro
 }
 
 var _ driver.Driver = (*Mediafire)(nil)
+
diff --git a/drivers/mediafire/meta.go b/drivers/mediafire/meta.go
index 78a5b9b14..1a3d37c8f 100644
--- a/drivers/mediafire/meta.go
+++ b/drivers/mediafire/meta.go
@@ -15,6 +15,7 @@ Final opts by @Suyunjing @j2rong4cn @KirCute @Da3zKi7
 */
 
 import (
+	"github.com/OpenListTeam/OpenList/v4/drivers/base"
 	"github.com/OpenListTeam/OpenList/v4/internal/driver"
 	"github.com/OpenListTeam/OpenList/v4/internal/op"
 )
@@ -23,8 +24,8 @@ type Addition struct {
 	driver.RootPath
 	//driver.RootID
 
-	SessionToken string `json:"session_token" required:"true" type:"string" help:"Required for MediaFire API"`
-	Cookie       string `json:"cookie" required:"true" type:"string" help:"Required for navigation"`
+	SessionToken string `json:"session_token" required:"false" type:"string" help:"Optional for MediaFire API, can be auto-acquired from cookie"`
+	Cookie       string `json:"cookie" required:"true" type:"string" help:"Required for MediaFire API authentication"`
 
 	OrderBy        string  `json:"order_by" type:"select" options:"name,time,size" default:"name"`
 	OrderDirection string  `json:"order_direction" type:"select" options:"asc,desc" default:"asc"`
@@ -49,13 +50,12 @@ var config = driver.Config{
 func init() {
 	op.RegisterDriver(func() driver.Driver {
 		return &Mediafire{
-			appBase:         "https://app.mediafire.com",
-			apiBase:         "https://www.mediafire.com/api/1.5",
-			hostBase:        "https://www.mediafire.com",
-			maxRetries:      3,
-			secChUa:         "\"Not)A;Brand\";v=\"8\", \"Chromium\";v=\"139\", \"Google Chrome\";v=\"139\"",
-			secChUaPlatform: "Windows",
-			userAgent:       "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36",
+			appBase:    "https://app.mediafire.com",
+			apiBase:    "https://www.mediafire.com/api/1.5",
+			hostBase:   "https://www.mediafire.com",
+			maxRetries: 3,
+			userAgent:  base.UserAgent,
 		}
 	})
 }
+
diff --git a/drivers/mediafire/types.go b/drivers/mediafire/types.go
index 4a59ae568..eebc85460 100644
--- a/drivers/mediafire/types.go
+++ b/drivers/mediafire/types.go
@@ -244,3 +244,4 @@ type MediafireUserInfoResponse struct {
 		CurrentAPIVersion string `json:"current_api_version"`
 	} `json:"response"`
 }
+
diff --git a/drivers/mediafire/util.go b/drivers/mediafire/util.go
index 6ded6bdf0..24259d0bc 100644
--- a/drivers/mediafire/util.go
+++ b/drivers/mediafire/util.go
@@ -15,6 +15,7 @@ Final opts by @Suyunjing @j2rong4cn @KirCute @Da3zKi7
 */
 
 import (
+	"compress/gzip"
 	"context"
 	"encoding/json"
 	"fmt"
@@ -60,7 +61,7 @@ func (d *Mediafire) getSessionToken(ctx context.Context) (string, error) {
 	}
 
 	req.Header.Set("Accept", "*/*")
-	req.Header.Set("Accept-Encoding", "gzip, deflate, br, zstd")
+	req.Header.Set("Accept-Encoding", "gzip")
 	req.Header.Set("Accept-Language", "en-US,en;q=0.9")
 	req.Header.Set("Content-Length", "0")
 	req.Header.Set("Cookie", d.Cookie)
@@ -83,7 +84,19 @@ func (d *Mediafire) getSessionToken(ctx context.Context) (string, error) {
 	}
 	defer resp.Body.Close()
 
-	body, err := io.ReadAll(resp.Body)
+	var body []byte
+	// Handle gzip decompression if needed
+	if resp.Header.Get("Content-Encoding") == "gzip" {
+		gzipReader, err := gzip.NewReader(resp.Body)
+		if err != nil {
+			return "", fmt.Errorf("failed to create gzip reader: %w", err)
+		}
+		defer gzipReader.Close()
+		body, _ = io.ReadAll(gzipReader)
+	} else {
+		body, err = io.ReadAll(resp.Body)
+	}
+
 	if err != nil {
 		return "", err
 	}
@@ -468,39 +481,32 @@ func (d *Mediafire) uploadUnits(ctx context.Context, file model.FileStreamer, ch
 		}
 
 		var reader io.ReadSeeker
-		var rateLimitedRd io.Reader
 		var unitHash string
 
 		// Use lifecycle pattern for proper resource management
 		threadG.GoWithLifecycle(errgroup.Lifecycle{
-			Before: func(ctx context.Context) error {
+			Before: func(ctx context.Context) (err error) {
 				// Skip already uploaded units
 				if d.isUnitUploaded(intWords, unitID) {
 					return ss.DiscardSection(start, size)
 				}
-
-				var err error
 				reader, err = ss.GetSectionReader(start, size)
-				if err != nil {
-					return err
-				}
-				rateLimitedRd = driver.NewLimitedUploadStream(ctx, reader)
-				return nil
+				return
 			},
-			Do: func(ctx context.Context) error {
+			Do: func(ctx context.Context) (err error) {
 				if reader == nil {
 					return nil // Skip if reader is not initialized (already uploaded)
 				}
+				reader.Seek(0, io.SeekStart)
 
 				if unitHash == "" {
-					reader.Seek(0, io.SeekStart)
 					var err error
 					unitHash, err = utils.HashReader(utils.SHA256, reader)
 					if err != nil {
 						return err
 					}
+					reader.Seek(0, io.SeekStart)
 				}
-				reader.Seek(0, io.SeekStart)
 
 				// Perform upload
 
@@ -515,7 +521,7 @@ func (d *Mediafire) uploadUnits(ctx context.Context, file model.FileStreamer, ch
 				}
 
 				url := d.apiBase + "/upload/resumable.php"
-				req, err := http.NewRequestWithContext(ctx, http.MethodPost, url, rateLimitedRd)
+				req, err := http.NewRequestWithContext(ctx, http.MethodPost, url, driver.NewLimitedUploadStream(ctx, reader))
 				if err != nil {
 					return err
 				}
@@ -579,10 +585,10 @@ func (d *Mediafire) uploadUnits(ctx context.Context, file model.FileStreamer, ch
 				finalUploadKey = uploadResp.Response.Doupload.Key
 				keyMutex.Unlock()
 
+				up(float64(threadG.Success()+1) * 100 / float64(numUnits+1))
 				return nil
 			},
 			After: func(err error) {
-				up(float64(threadG.Success()) * 100 / float64(numUnits))
 				if reader != nil {
 					// Cleanup resources
 					ss.FreeSectionReader(reader)
@@ -594,7 +600,6 @@ func (d *Mediafire) uploadUnits(ctx context.Context, file model.FileStreamer, ch
 	if err := threadG.Wait(); err != nil {
 		return "", err
 	}
-
 	return finalUploadKey, nil
 }
 
@@ -727,3 +732,4 @@ func (d *Mediafire) getFileByHash(ctx context.Context, hash string) (*model.ObjT
 	file := resp.Response.FileInfo[0]
 	return d.fileToObj(file), nil
 }
+
diff --git a/drivers/mopan/driver.go b/drivers/mopan/driver.go
index c611cf029..d9e920a39 100644
--- a/drivers/mopan/driver.go
+++ b/drivers/mopan/driver.go
@@ -330,7 +330,7 @@ func (d *MoPan) Put(ctx context.Context, dstDir model.Obj, stream model.FileStre
 				if resp.StatusCode != http.StatusOK {
 					return fmt.Errorf("upload err,code=%d", resp.StatusCode)
 				}
-				up(100 * float64(threadG.Success()) / float64(len(parts)))
+				up(100 * float64(threadG.Success()+1) / float64(len(parts)+1))
 				initUpdload.PartInfos[i] = ""
 				return nil
 			})
diff --git a/drivers/netease_music/driver.go b/drivers/netease_music/driver.go
index b03c3b2cc..4fcf433c1 100644
--- a/drivers/netease_music/driver.go
+++ b/drivers/netease_music/driver.go
@@ -42,14 +42,11 @@ func (d *NeteaseMusic) Drop(ctx context.Context) error {
 	return nil
 }
 
-func (d *NeteaseMusic) Get(ctx context.Context, path string) (model.Obj, error) {
-	if path == "/" {
-		return &model.Object{
-			IsFolder: true,
-			Path:     path,
-		}, nil
-	}
+func (Addition) GetRootPath() string {
+	return "/"
+}
 
+func (d *NeteaseMusic) Get(ctx context.Context, path string) (model.Obj, error) {
 	fragments := strings.Split(path, "/")
 	if len(fragments) > 1 {
 		fileName := fragments[1]
diff --git a/drivers/onedrive/driver.go b/drivers/onedrive/driver.go
index 92e070039..b460853ee 100644
--- a/drivers/onedrive/driver.go
+++ b/drivers/onedrive/driver.go
@@ -98,7 +98,9 @@ func (d *Onedrive) List(ctx context.Context, dir model.Obj, args model.ListArgs)
 		return nil, err
 	}
 	return utils.SliceConvert(files, func(src File) (model.Obj, error) {
-		return fileToObj(src, dir.GetID()), nil
+		obj := fileToObj(src, dir.GetID())
+		obj.Path = path.Join(dir.GetPath(), obj.GetName())
+		return obj, nil
 	})
 }
 
diff --git a/drivers/onedrive/util.go b/drivers/onedrive/util.go
index 820f740de..ad300af44 100644
--- a/drivers/onedrive/util.go
+++ b/drivers/onedrive/util.go
@@ -82,7 +82,6 @@ func (d *Onedrive) _refreshToken() error {
 			ErrorMessage string `json:"text"`
 		}
 		_, err := base.RestyClient.R().
-			SetHeader("User-Agent", "Mozilla/5.0 (Macintosh; Apple macOS 15_5) AppleWebKit/537.36 (KHTML, like Gecko) Safari/537.36 Chrome/138.0.0.0 Openlist/425.6.30").
 			SetResult(&resp).
 			SetQueryParams(map[string]string{
 				"refresh_ui": d.RefreshToken,
@@ -285,6 +284,7 @@ func (d *Onedrive) upBig(ctx context.Context, dstDir model.Obj, stream model.Fil
 					return nil
 				}
 			},
+			retry.Context(ctx),
 			retry.Attempts(3),
 			retry.DelayType(retry.BackOffDelay),
 			retry.Delay(time.Second),
diff --git a/drivers/onedrive_app/driver.go b/drivers/onedrive_app/driver.go
index de6b2b7fb..bf604d281 100644
--- a/drivers/onedrive_app/driver.go
+++ b/drivers/onedrive_app/driver.go
@@ -85,7 +85,9 @@ func (d *OnedriveAPP) List(ctx context.Context, dir model.Obj, args model.ListAr
 		return nil, err
 	}
 	return utils.SliceConvert(files, func(src File) (model.Obj, error) {
-		return fileToObj(src, dir.GetID()), nil
+		obj := fileToObj(src, dir.GetID())
+		obj.Path = path.Join(dir.GetPath(), obj.GetName())
+		return obj, nil
 	})
 }
 
diff --git a/drivers/onedrive_app/util.go b/drivers/onedrive_app/util.go
index 7a7dd0bfe..574afb381 100644
--- a/drivers/onedrive_app/util.go
+++ b/drivers/onedrive_app/util.go
@@ -196,6 +196,7 @@ func (d *OnedriveAPP) upBig(ctx context.Context, dstDir model.Obj, stream model.
 					return nil
 				}
 			},
+			retry.Context(ctx),
 			retry.Attempts(3),
 			retry.DelayType(retry.BackOffDelay),
 			retry.Delay(time.Second),
diff --git a/drivers/onedrive_sharelink/driver.go b/drivers/onedrive_sharelink/driver.go
index 42d0f1904..0bc3e79b5 100644
--- a/drivers/onedrive_sharelink/driver.go
+++ b/drivers/onedrive_sharelink/driver.go
@@ -2,21 +2,34 @@ package onedrive_sharelink
 
 import (
 	"context"
+	"fmt"
+	"io"
+	"net/http"
+	stdpath "path"
 	"strings"
+	"sync"
 	"time"
 
 	"github.com/OpenListTeam/OpenList/v4/internal/driver"
 	"github.com/OpenListTeam/OpenList/v4/internal/errs"
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	"github.com/OpenListTeam/OpenList/v4/internal/net"
 	"github.com/OpenListTeam/OpenList/v4/pkg/cron"
+	"github.com/OpenListTeam/OpenList/v4/pkg/http_range"
+	"github.com/OpenListTeam/OpenList/v4/pkg/singleflight"
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
 	log "github.com/sirupsen/logrus"
 )
 
+const headerTTL = 25 * time.Minute
+
 type OnedriveSharelink struct {
 	model.Storage
 	cron *cron.Cron
 	Addition
+
+	headerMu sync.RWMutex
+	sg       singleflight.Group[http.Header]
 }
 
 func (d *OnedriveSharelink) Config() driver.Config {
@@ -38,17 +51,20 @@ func (d *OnedriveSharelink) Init(ctx context.Context) error {
 	d.cron = cron.NewCron(time.Hour * 1)
 	d.cron.Do(func() {
 		var err error
-		d.Headers, err = d.getHeaders(ctx)
+		h, err := d.getHeaders(ctx)
 		if err != nil {
 			log.Errorf("%+v", err)
+			return
 		}
+		d.storeHeaders(h)
 	})
 
 	// Get initial headers
-	d.Headers, err = d.getHeaders(ctx)
+	h, err := d.getHeaders(ctx)
 	if err != nil {
 		return err
 	}
+	d.storeHeaders(h)
 
 	return nil
 }
@@ -58,15 +74,16 @@ func (d *OnedriveSharelink) Drop(ctx context.Context) error {
 }
 
 func (d *OnedriveSharelink) List(ctx context.Context, dir model.Obj, args model.ListArgs) ([]model.Obj, error) {
-	path := dir.GetPath()
-	files, err := d.getFiles(ctx, path)
+	files, err := d.getFiles(ctx, dir.GetPath())
 	if err != nil {
 		return nil, err
 	}
 
 	// Convert the slice of files to the required model.Obj format
 	return utils.SliceConvert(files, func(src Item) (model.Obj, error) {
-		return fileToObj(src), nil
+		obj := fileToObj(src)
+		obj.Path = stdpath.Join(dir.GetPath(), obj.GetName())
+		return obj, nil
 	})
 }
 
@@ -76,21 +93,18 @@ func (d *OnedriveSharelink) Link(ctx context.Context, file model.Obj, args model
 	// Cut the first char and the last char
 	uniqueId = uniqueId[1 : len(uniqueId)-1]
 	url := d.downloadLinkPrefix + uniqueId
-	header := d.Headers
 
-	// If the headers are older than 30 minutes, get new headers
-	if d.HeaderTime < time.Now().Unix()-1800 {
-		var err error
-		log.Debug("headers are older than 30 minutes, get new headers")
-		header, err = d.getHeaders(ctx)
-		if err != nil {
-			return nil, err
-		}
+	header, err := d.getValidHeaders(ctx)
+	if err != nil {
+		return nil, err
 	}
 
 	return &model.Link{
 		URL:    url,
 		Header: header,
+		RangeReader: rangeReaderFunc(func(ctx context.Context, hr http_range.Range) (io.ReadCloser, error) {
+			return d.rangeReadWithRefresh(ctx, url, hr)
+		}),
 	}, nil
 }
 
@@ -129,3 +143,102 @@ func (d *OnedriveSharelink) Put(ctx context.Context, dstDir model.Obj, stream mo
 //}
 
 var _ driver.Driver = (*OnedriveSharelink)(nil)
+
+// rangeReadWithRefresh tries once with current headers, and if the response
+// looks invalid (error status or html login page), it refreshes headers and retries.
+func (d *OnedriveSharelink) rangeReadWithRefresh(ctx context.Context, url string, hr http_range.Range) (io.ReadCloser, error) {
+	tryOnce := func(header http.Header) (io.ReadCloser, error) {
+		h := cloneHeader(header)
+		if h == nil {
+			h = http.Header{}
+		}
+		h = http_range.ApplyRangeToHttpHeader(hr, h)
+		resp, err := net.RequestHttp(ctx, http.MethodGet, h, url)
+		if err != nil {
+			return nil, err
+		}
+		ct := strings.ToLower(resp.Header.Get("Content-Type"))
+		if strings.Contains(ct, "text/html") {
+			_ = resp.Body.Close()
+			return nil, fmt.Errorf("unexpected html response")
+		}
+		return resp.Body, nil
+	}
+
+	header, err := d.getValidHeaders(ctx)
+	if err != nil {
+		return nil, err
+	}
+	if body, err := tryOnce(header); err == nil {
+		return body, nil
+	}
+
+	// refresh and retry once
+	header, err = d.refreshHeaders(ctx)
+	if err != nil {
+		return nil, err
+	}
+	return tryOnce(header)
+}
+
+type rangeReaderFunc func(ctx context.Context, hr http_range.Range) (io.ReadCloser, error)
+
+func (f rangeReaderFunc) RangeRead(ctx context.Context, hr http_range.Range) (io.ReadCloser, error) {
+	return f(ctx, hr)
+}
+
+func cloneHeader(header http.Header) http.Header {
+	if header == nil {
+		return nil
+	}
+	return header.Clone()
+}
+
+func (d *OnedriveSharelink) headerSnapshot() http.Header {
+	d.headerMu.RLock()
+	defer d.headerMu.RUnlock()
+	return cloneHeader(d.Headers)
+}
+
+func (d *OnedriveSharelink) storeHeaders(header http.Header) {
+	if header == nil {
+		return
+	}
+	d.headerMu.Lock()
+	d.Headers = header
+	d.HeaderTime = time.Now().Unix()
+	d.headerMu.Unlock()
+}
+
+func (d *OnedriveSharelink) headersExpired() bool {
+	d.headerMu.RLock()
+	defer d.headerMu.RUnlock()
+	return time.Since(time.Unix(d.HeaderTime, 0)) > headerTTL
+}
+
+func (d *OnedriveSharelink) refreshHeaders(ctx context.Context) (http.Header, error) {
+	header, err, _ := d.sg.Do("refresh", func() (http.Header, error) {
+		h, e := d.getHeaders(ctx)
+		if e != nil {
+			return nil, e
+		}
+		d.storeHeaders(h)
+		return h, nil
+	})
+	return header, err
+}
+
+func (d *OnedriveSharelink) getValidHeaders(ctx context.Context) (http.Header, error) {
+	if h := d.headerSnapshot(); h != nil && !d.headersExpired() {
+		return h, nil
+	}
+	h, err := d.refreshHeaders(ctx)
+	if err != nil {
+		if h2 := d.headerSnapshot(); h2 != nil {
+			log.Warnf("onedrive_sharelink: use cached headers after refresh failure: %+v", err)
+			return h2, nil
+		}
+		return nil, err
+	}
+	return h, nil
+}
diff --git a/drivers/openlist/driver.go b/drivers/openlist/driver.go
index 04f64d0b9..2ca60ff61 100644
--- a/drivers/openlist/driver.go
+++ b/drivers/openlist/driver.go
@@ -95,6 +95,7 @@ func (d *OpenList) List(ctx context.Context, dir model.Obj, args model.ListArgs)
 		file := model.ObjThumb{
 			Object: model.Object{
 				Name:     f.Name,
+				Path:     path.Join(dir.GetPath(), f.Name),
 				Modified: f.Modified,
 				Ctime:    f.Created,
 				Size:     f.Size,
diff --git a/drivers/openlist/meta.go b/drivers/openlist/meta.go
index 10c950a39..16c6a155c 100644
--- a/drivers/openlist/meta.go
+++ b/drivers/openlist/meta.go
@@ -21,7 +21,6 @@ var config = driver.Config{
 	Name:             "OpenList",
 	LocalSort:        true,
 	DefaultRoot:      "/",
-	CheckStatus:      true,
 	ProxyRangeOption: true,
 	LinkCacheMode:    driver.LinkCacheAuto,
 }
diff --git a/drivers/openlist_share/driver.go b/drivers/openlist_share/driver.go
index 416987777..0b99edd07 100644
--- a/drivers/openlist_share/driver.go
+++ b/drivers/openlist_share/driver.go
@@ -68,6 +68,7 @@ func (d *OpenListShare) List(ctx context.Context, dir model.Obj, args model.List
 		file := model.ObjThumb{
 			Object: model.Object{
 				Name:     f.Name,
+				Path:     stdpath.Join(dir.GetPath(), f.Name),
 				Modified: f.Modified,
 				Ctime:    f.Created,
 				Size:     f.Size,
diff --git a/drivers/quark_open/driver.go b/drivers/quark_open/driver.go
index 7b6b31331..f0b8baf09 100644
--- a/drivers/quark_open/driver.go
+++ b/drivers/quark_open/driver.go
@@ -1,7 +1,6 @@
 package quark_open
 
 import (
-	"bytes"
 	"context"
 	"encoding/hex"
 	"errors"
@@ -9,12 +8,15 @@ import (
 	"hash"
 	"io"
 	"net/http"
+	"time"
 
 	"github.com/OpenListTeam/OpenList/v4/drivers/base"
 	"github.com/OpenListTeam/OpenList/v4/internal/driver"
 	"github.com/OpenListTeam/OpenList/v4/internal/errs"
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	streamPkg "github.com/OpenListTeam/OpenList/v4/internal/stream"
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+	"github.com/avast/retry-go"
 	"github.com/go-resty/resty/v2"
 )
 
@@ -174,7 +176,7 @@ func (d *QuarkOpen) Put(ctx context.Context, dstDir model.Obj, stream model.File
 		return err
 	}
 	// å¦‚æœé¢„ä¸Šä¼ å·²ç»å®Œæˆï¼Œç›´æ¥è¿”å›--ç§’ä¼ 
-	if pre.Data.Finish == true {
+	if pre.Data.Finish {
 		up(100)
 		return nil
 	}
@@ -188,46 +190,48 @@ func (d *QuarkOpen) Put(ctx context.Context, dstDir model.Obj, stream model.File
 	}
 
 	// part up
+	ss, err := streamPkg.NewStreamSectionReader(stream, int(pre.Data.PartSize), &up)
+	if err != nil {
+		return err
+	}
 	total := stream.GetSize()
-	left := total
-	part := make([]byte, pre.Data.PartSize)
 	// ç”¨äºå­˜å‚¨æ¯ä¸ªåˆ†ç‰‡çš„ETagï¼Œåç»­commitæ—¶éœ€è¦
-	etags := make([]string, len(partInfo))
+	etags := make([]string, 0, len(partInfo))
 
 	// éå†ä¸Šä¼ æ¯ä¸ªåˆ†ç‰‡
-	for i, urlInfo := range upUrlInfo.UploadUrls {
+	for i := range len(upUrlInfo.UploadUrls) {
 		if utils.IsCanceled(ctx) {
 			return ctx.Err()
 		}
 
-		currentSize := int64(urlInfo.PartSize)
-		if left < currentSize {
-			part = part[:left]
-		} else {
-			part = part[:currentSize]
-		}
-
-		// è¯»å–åˆ†ç‰‡æ•°æ®
-		n, err := io.ReadFull(stream, part)
-		if err != nil && !errors.Is(err, io.ErrUnexpectedEOF) {
+		offset := int64(i) * pre.Data.PartSize
+		size := min(pre.Data.PartSize, total-offset)
+		rd, err := ss.GetSectionReader(offset, size)
+		if err != nil {
 			return err
 		}
-
-		// å‡†å¤‡ä¸Šä¼ åˆ†ç‰‡
-		reader := driver.NewLimitedUploadStream(ctx, bytes.NewReader(part))
-		etag, err := d.upPart(ctx, upUrlInfo, i, reader)
+		err = retry.Do(func() error {
+			rd.Seek(0, io.SeekStart)
+			etag, err := d.upPart(ctx, upUrlInfo, i, driver.NewLimitedUploadStream(ctx, rd))
+			if err != nil {
+				return err
+			}
+			etags = append(etags, etag)
+			return nil
+		},
+			retry.Context(ctx),
+			retry.Attempts(3),
+			retry.DelayType(retry.BackOffDelay),
+			retry.Delay(time.Second))
+		ss.FreeSectionReader(rd)
 		if err != nil {
 			return fmt.Errorf("failed to upload part %d: %w", i, err)
 		}
 
-		// ä¿å­˜ETagï¼Œç”¨äºåç»­commit
-		etags[i] = etag
-
-		// æ›´æ–°å‰©ä½™å¤§å°å’Œè¿›åº¦
-		left -= int64(n)
-		up(float64(total-left) / float64(total) * 100)
+		up(95 * float64(offset+size) / float64(total))
 	}
 
+	defer up(100)
 	return d.upFinish(ctx, pre, partInfo, etags)
 }
 
diff --git a/drivers/quark_open/util.go b/drivers/quark_open/util.go
index 78f4e4a2c..788ca0e99 100644
--- a/drivers/quark_open/util.go
+++ b/drivers/quark_open/util.go
@@ -341,8 +341,7 @@ func (d *QuarkOpen) upPart(ctx context.Context, upUrlInfo UpUrlInfo, partNumber
 	req.Header.Set("User-Agent", "Go-http-client/1.1")
 
 	// å‘é€è¯·æ±‚
-	client := &http.Client{}
-	resp, err := client.Do(req)
+	resp, err := base.HttpClient.Do(req)
 	if err != nil {
 		return "", err
 	}
@@ -441,7 +440,6 @@ func (d *QuarkOpen) _refreshToken() (string, string, error) {
 		u := d.APIAddress
 		var resp RefreshTokenOnlineAPIResp
 		_, err := base.RestyClient.R().
-			SetHeader("User-Agent", "Mozilla/5.0 (Macintosh; Apple macOS 15_5) AppleWebKit/537.36 (KHTML, like Gecko) Safari/537.36 Chrome/138.0.0.0 Openlist/425.6.30").
 			SetResult(&resp).
 			SetQueryParams(map[string]string{
 				"refresh_ui": d.RefreshToken,
diff --git a/drivers/quark_uc/driver.go b/drivers/quark_uc/driver.go
index 68406ea9f..71f3ffca3 100644
--- a/drivers/quark_uc/driver.go
+++ b/drivers/quark_uc/driver.go
@@ -1,7 +1,6 @@
 package quark
 
 import (
-	"bytes"
 	"context"
 	"encoding/hex"
 	"hash"
@@ -13,9 +12,10 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/driver"
 	"github.com/OpenListTeam/OpenList/v4/internal/errs"
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	streamPkg "github.com/OpenListTeam/OpenList/v4/internal/stream"
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+	"github.com/avast/retry-go"
 	"github.com/go-resty/resty/v2"
-	log "github.com/sirupsen/logrus"
 )
 
 type QuarkOrUC struct {
@@ -159,56 +159,63 @@ func (d *QuarkOrUC) Put(ctx context.Context, dstDir model.Obj, stream model.File
 	if err != nil {
 		return err
 	}
-	log.Debugln("hash: ", md5Str, sha1Str)
 	// hash
 	finish, err := d.upHash(md5Str, sha1Str, pre.Data.TaskId)
 	if err != nil {
 		return err
 	}
 	if finish {
+		up(100)
 		return nil
 	}
 	// part up
+	ss, err := streamPkg.NewStreamSectionReader(stream, pre.Metadata.PartSize, &up)
+	if err != nil {
+		return err
+	}
 	total := stream.GetSize()
-	left := total
 	partSize := int64(pre.Metadata.PartSize)
-	part := make([]byte, partSize)
-	count := int(total / partSize)
-	if total%partSize > 0 {
-		count++
-	}
-	md5s := make([]string, 0, count)
-	partNumber := 1
-	for left > 0 {
+	uploadNums := int((total + partSize - 1) / partSize)
+	md5s := make([]string, 0, uploadNums)
+	for partIndex := range uploadNums {
 		if utils.IsCanceled(ctx) {
 			return ctx.Err()
 		}
-		if left < partSize {
-			part = part[:left]
-		}
-		n, err := io.ReadFull(stream, part)
+		offset := int64(partIndex) * partSize
+		size := min(partSize, total-offset)
+		rd, err := ss.GetSectionReader(offset, size)
 		if err != nil {
 			return err
 		}
-		left -= int64(n)
-		log.Debugf("left: %d", left)
-		reader := driver.NewLimitedUploadStream(ctx, bytes.NewReader(part))
-		m, err := d.upPart(ctx, pre, stream.GetMimetype(), partNumber, reader)
-		// m, err := driver.UpPart(pre, file.GetMIMEType(), partNumber, bytes, account, md5Str, sha1Str)
+		err = retry.Do(func() error {
+			rd.Seek(0, io.SeekStart)
+			m, err := d.upPart(ctx, pre, stream.GetMimetype(), partIndex+1, driver.NewLimitedUploadStream(ctx, rd))
+			if err != nil {
+				return err
+			}
+			if m == "finish" {
+				up(100)
+				return nil
+			}
+			md5s = append(md5s, m)
+			return nil
+		},
+			retry.Context(ctx),
+			retry.Attempts(3),
+			retry.DelayType(retry.BackOffDelay),
+			retry.Delay(time.Second))
+		ss.FreeSectionReader(rd)
 		if err != nil {
 			return err
 		}
-		if m == "finish" {
-			return nil
-		}
-		md5s = append(md5s, m)
-		partNumber++
-		up(100 * float64(total-left) / float64(total))
+		up(95 * float64(offset+size) / float64(total))
 	}
+	up(97)
 	err = d.upCommit(pre, md5s)
 	if err != nil {
 		return err
 	}
+	defer up(100)
 	return d.upFinish(pre)
 }
 
diff --git a/drivers/quark_uc/util.go b/drivers/quark_uc/util.go
index 01f63ef0c..3c49f1f3f 100644
--- a/drivers/quark_uc/util.go
+++ b/drivers/quark_uc/util.go
@@ -229,25 +229,30 @@ x-oss-user-agent:aliyun-sdk-js/6.6.1 Chrome 98.0.4758.80 on Windows 10 64-bit
 	//	}
 	//}
 	u := fmt.Sprintf("https://%s.%s/%s", pre.Data.Bucket, pre.Data.UploadUrl[7:], pre.Data.ObjKey)
-	res, err := base.RestyClient.R().SetContext(ctx).
-		SetHeaders(map[string]string{
-			"Authorization":    resp.Data.AuthKey,
-			"Content-Type":     mineType,
-			"Referer":          "https://pan.quark.cn/",
-			"x-oss-date":       timeStr,
-			"x-oss-user-agent": "aliyun-sdk-js/6.6.1 Chrome 98.0.4758.80 on Windows 10 64-bit",
-		}).
-		SetQueryParams(map[string]string{
-			"partNumber": strconv.Itoa(partNumber),
-			"uploadId":   pre.Data.UploadId,
-		}).SetBody(bytes).Put(u)
+	req, err := http.NewRequestWithContext(ctx, http.MethodPut, u, bytes)
 	if err != nil {
 		return "", err
 	}
-	if res.StatusCode() != 200 {
-		return "", fmt.Errorf("up status: %d, error: %s", res.StatusCode(), res.String())
+	req.Header.Set("Authorization", resp.Data.AuthKey)
+	req.Header.Set("Content-Type", mineType)
+	req.Header.Set("Referer", "https://pan.quark.cn/")
+	req.Header.Set("x-oss-date", timeStr)
+	req.Header.Set("x-oss-user-agent", "aliyun-sdk-js/6.6.1 Chrome 98.0.4758.80 on Windows 10 64-bit")
+	q := req.URL.Query()
+	q.Add("partNumber", strconv.Itoa(partNumber))
+	q.Add("uploadId", pre.Data.UploadId)
+	req.URL.RawQuery = q.Encode()
+	res, err := base.HttpClient.Do(req)
+	if err != nil {
+		return "", err
+	}
+	defer res.Body.Close()
+
+	if res.StatusCode != 200 {
+		respBody, _ := io.ReadAll(res.Body)
+		return "", fmt.Errorf("up status: %d, error: %s", res.StatusCode, string(respBody))
 	}
-	return res.Header().Get("Etag"), nil
+	return res.Header.Get("Etag"), nil
 }
 
 func (d *QuarkOrUC) upCommit(pre UpPreResp, md5s []string) error {
diff --git a/drivers/s3/util.go b/drivers/s3/util.go
index 8b0fe4b26..c84380786 100644
--- a/drivers/s3/util.go
+++ b/drivers/s3/util.go
@@ -98,8 +98,8 @@ func getPlaceholderName(placeholder string) string {
 	return placeholder
 }
 
-func (d *S3) listV1(prefix string, args model.ListArgs) ([]model.Obj, error) {
-	prefix = getKey(prefix, true)
+func (d *S3) listV1(dirPath string, args model.ListArgs) ([]model.Obj, error) {
+	prefix := getKey(dirPath, true)
 	log.Debugf("list: %s", prefix)
 	files := make([]model.Obj, 0)
 	marker := ""
@@ -117,7 +117,7 @@ func (d *S3) listV1(prefix string, args model.ListArgs) ([]model.Obj, error) {
 		for _, object := range listObjectsResult.CommonPrefixes {
 			name := path.Base(strings.Trim(*object.Prefix, "/"))
 			file := model.Object{
-				//Id:        *object.Key,
+				Path:     path.Join(dirPath, name),
 				Name:     name,
 				Modified: d.Modified,
 				IsFolder: true,
@@ -130,7 +130,7 @@ func (d *S3) listV1(prefix string, args model.ListArgs) ([]model.Obj, error) {
 				continue
 			}
 			file := model.Object{
-				//Id:        *object.Key,
+				Path:     path.Join(dirPath, name),
 				Name:     name,
 				Size:     *object.Size,
 				Modified: *object.LastModified,
@@ -149,8 +149,8 @@ func (d *S3) listV1(prefix string, args model.ListArgs) ([]model.Obj, error) {
 	return files, nil
 }
 
-func (d *S3) listV2(prefix string, args model.ListArgs) ([]model.Obj, error) {
-	prefix = getKey(prefix, true)
+func (d *S3) listV2(dirPath string, args model.ListArgs) ([]model.Obj, error) {
+	prefix := getKey(dirPath, true)
 	files := make([]model.Obj, 0)
 	var continuationToken, startAfter *string
 	for {
@@ -169,7 +169,7 @@ func (d *S3) listV2(prefix string, args model.ListArgs) ([]model.Obj, error) {
 		for _, object := range listObjectsResult.CommonPrefixes {
 			name := path.Base(strings.Trim(*object.Prefix, "/"))
 			file := model.Object{
-				//Id:        *object.Key,
+				Path:     path.Join(dirPath, name),
 				Name:     name,
 				Modified: d.Modified,
 				IsFolder: true,
@@ -185,7 +185,7 @@ func (d *S3) listV2(prefix string, args model.ListArgs) ([]model.Obj, error) {
 				continue
 			}
 			file := model.Object{
-				//Id:        *object.Key,
+				Path:     path.Join(dirPath, name),
 				Name:     name,
 				Size:     *object.Size,
 				Modified: *object.LastModified,
@@ -217,9 +217,10 @@ func (d *S3) copy(ctx context.Context, src string, dst string, isDir bool) error
 func (d *S3) copyFile(ctx context.Context, src string, dst string) error {
 	srcKey := getKey(src, false)
 	dstKey := getKey(dst, false)
+	encodedKey := strings.ReplaceAll(url.PathEscape(d.Bucket+"/"+srcKey), "+", "%2B")
 	input := &s3.CopyObjectInput{
 		Bucket:     &d.Bucket,
-		CopySource: aws.String(url.PathEscape(d.Bucket + "/" + srcKey)),
+		CopySource: aws.String(encodedKey),
 		Key:        &dstKey,
 	}
 	_, err := d.client.CopyObject(input)
diff --git a/drivers/seafile/driver.go b/drivers/seafile/driver.go
index 73c21645e..646d68055 100644
--- a/drivers/seafile/driver.go
+++ b/drivers/seafile/driver.go
@@ -4,6 +4,7 @@ import (
 	"context"
 	"fmt"
 	"net/http"
+	stdpath "path"
 	"strings"
 	"time"
 
@@ -42,21 +43,20 @@ func (d *Seafile) Drop(ctx context.Context) error {
 
 func (d *Seafile) List(ctx context.Context, dir model.Obj, args model.ListArgs) (result []model.Obj, err error) {
 	path := dir.GetPath()
-	if path == d.RootFolderPath {
+	if path == "/" && d.RepoId == "" {
 		libraries, err := d.listLibraries()
 		if err != nil {
 			return nil, err
 		}
-		if path == "/" && d.RepoId == "" {
-			return utils.SliceConvert(libraries, func(f LibraryItemResp) (model.Obj, error) {
-				return &model.Object{
-					Name:     f.Name,
-					Modified: time.Unix(f.Modified, 0),
-					Size:     f.Size,
-					IsFolder: true,
-				}, nil
-			})
-		}
+		return utils.SliceConvert(libraries, func(f LibraryItemResp) (model.Obj, error) {
+			return &model.Object{
+				Path:     stdpath.Join(path, f.Name),
+				Name:     f.Name,
+				Modified: time.Unix(f.Modified, 0),
+				Size:     f.Size,
+				IsFolder: true,
+			}, nil
+		})
 	}
 	var repo *LibraryInfo
 	repo, path, err = d.getRepoAndPath(path)
@@ -79,14 +79,12 @@ func (d *Seafile) List(ctx context.Context, dir model.Obj, args model.ListArgs)
 		return nil, err
 	}
 	return utils.SliceConvert(resp, func(f RepoDirItemResp) (model.Obj, error) {
-		return &model.ObjThumb{
-			Object: model.Object{
-				Name:     f.Name,
-				Modified: time.Unix(f.Modified, 0),
-				Size:     f.Size,
-				IsFolder: f.Type == "dir",
-			},
-			// Thumbnail: model.Thumbnail{Thumbnail: f.Thumb},
+		return &model.Object{
+			Path:     stdpath.Join(dir.GetPath(), f.Name),
+			Name:     f.Name,
+			Modified: time.Unix(f.Modified, 0),
+			Size:     f.Size,
+			IsFolder: f.Type == "dir",
 		}, nil
 	})
 }
diff --git a/drivers/sftp/types.go b/drivers/sftp/types.go
index 0948834e0..00a32f001 100644
--- a/drivers/sftp/types.go
+++ b/drivers/sftp/types.go
@@ -11,15 +11,16 @@ import (
 
 func (d *SFTP) fileToObj(f os.FileInfo, dir string) (model.Obj, error) {
 	symlink := f.Mode()&os.ModeSymlink != 0
+	path := stdpath.Join(dir, f.Name())
 	if !symlink {
 		return &model.Object{
+			Path:     path,
 			Name:     f.Name(),
 			Size:     f.Size(),
 			Modified: f.ModTime(),
 			IsFolder: f.IsDir(),
 		}, nil
 	}
-	path := stdpath.Join(dir, f.Name())
 	// set target path
 	target, err := d.client.ReadLink(path)
 	if err != nil {
@@ -32,6 +33,7 @@ func (d *SFTP) fileToObj(f os.FileInfo, dir string) (model.Obj, error) {
 	if err != nil {
 		if d.IgnoreSymlinkError {
 			return &model.Object{
+				Path:     path,
 				Name:     f.Name(),
 				Size:     f.Size(),
 				Modified: f.ModTime(),
diff --git a/drivers/smb/driver.go b/drivers/smb/driver.go
index 7d4b0cb94..35ca73346 100644
--- a/drivers/smb/driver.go
+++ b/drivers/smb/driver.go
@@ -3,6 +3,7 @@ package smb
 import (
 	"context"
 	"errors"
+	"path"
 	"path/filepath"
 	"strings"
 
@@ -54,17 +55,17 @@ func (d *SMB) List(ctx context.Context, dir model.Obj, args model.ListArgs) ([]m
 		return nil, err
 	}
 	d.updateLastConnTime()
-	var files []model.Obj
+	files := make([]model.Obj, 0, len(rawFiles))
 	for _, f := range rawFiles {
-		file := model.ObjThumb{
-			Object: model.Object{
-				Name:     f.Name(),
-				Modified: f.ModTime(),
-				Size:     f.Size(),
-				IsFolder: f.IsDir(),
-				Ctime:    f.(*smb2.FileStat).CreationTime,
-			},
+		file := model.Object{
+			Path:     path.Join(fullPath, f.Name()),
+			Name:     f.Name(),
+			Modified: f.ModTime(),
+			Size:     f.Size(),
+			IsFolder: f.IsDir(),
+			Ctime:    f.(*smb2.FileStat).CreationTime,
 		}
+
 		files = append(files, &file)
 	}
 	return files, nil
diff --git a/drivers/strm/driver.go b/drivers/strm/driver.go
index 809378490..422f0e1b1 100644
--- a/drivers/strm/driver.go
+++ b/drivers/strm/driver.go
@@ -117,6 +117,9 @@ func (d *Strm) Init(ctx context.Context) error {
 		d.PathPrefix = "/d"
 		d.Version = 5
 	}
+	if len(d.SaveLocalMode) == 0 {
+		d.SaveLocalMode = SaveLocalInsertMode
+	}
 	return nil
 }
 
@@ -130,14 +133,11 @@ func (d *Strm) Drop(ctx context.Context) error {
 	return nil
 }
 
+func (Addition) GetRootPath() string {
+	return "/"
+}
+
 func (d *Strm) Get(ctx context.Context, path string) (model.Obj, error) {
-	if utils.PathEqual(path, "/") {
-		return &model.Object{
-			Name:     "Root",
-			IsFolder: true,
-			Path:     "/",
-		}, nil
-	}
 	root, sub := d.getRootAndPath(path)
 	dsts, ok := d.pathMap[root]
 	if !ok {
diff --git a/drivers/strm/hook.go b/drivers/strm/hook.go
index 1ac947df5..8e6d1c43a 100644
--- a/drivers/strm/hook.go
+++ b/drivers/strm/hook.go
@@ -1,8 +1,11 @@
 package strm
 
 import (
+	"bytes"
 	"context"
+	"crypto/sha256"
 	"errors"
+	"io"
 	"os"
 	stdpath "path"
 	"strings"
@@ -21,7 +24,7 @@ var strmTrie = patricia.NewTrie()
 func UpdateLocalStrm(ctx context.Context, path string, objs []model.Obj) {
 	path = utils.FixAndCleanPath(path)
 	updateLocal := func(driver *Strm, basePath string, objs []model.Obj) {
-		relParent := strings.TrimPrefix(basePath, driver.MountPath)
+		relParent := strings.TrimPrefix(basePath, utils.GetActualMountPath(driver.MountPath))
 		localParentPath := stdpath.Join(driver.SaveStrmLocalPath, relParent)
 		for _, obj := range objs {
 			localPath := stdpath.Join(localParentPath, obj.GetName())
@@ -89,13 +92,10 @@ func RemoveStrm(dstPath string, d *Strm) {
 }
 
 func generateStrm(ctx context.Context, driver *Strm, obj model.Obj, localPath string) {
-	if obj.IsDir() {
-		err := utils.CreateNestedDirectory(localPath)
-		if err != nil {
-			log.Warnf("failed to generate strm dir %s: failed to create dir: %v", localPath, err)
+	if !obj.IsDir() {
+		if utils.Exists(localPath) && driver.SaveLocalMode == SaveLocalInsertMode {
 			return
 		}
-	} else {
 		link, err := driver.Link(ctx, obj, model.LinkArgs{})
 		if err != nil {
 			log.Warnf("failed to generate strm of obj %s: failed to link: %v", localPath, err)
@@ -117,6 +117,20 @@ func generateStrm(ctx context.Context, driver *Strm, obj model.Obj, localPath st
 			return
 		}
 		defer rc.Close()
+		same, err := isSameContent(localPath, size, rc)
+		if err != nil {
+			log.Warnf("failed to compare content of obj %s: %v", localPath, err)
+			return
+		}
+		if same {
+			return
+		}
+		rc, err = rrf.RangeRead(ctx, http_range.Range{Length: -1})
+		if err != nil {
+			log.Warnf("failed to generate strm of obj %s: failed to reread range: %v", localPath, err)
+			return
+		}
+		defer rc.Close()
 		file, err := utils.CreateNestedFile(localPath)
 		if err != nil {
 			log.Warnf("failed to generate strm of obj %s: failed to create local file: %v", localPath, err)
@@ -129,7 +143,38 @@ func generateStrm(ctx context.Context, driver *Strm, obj model.Obj, localPath st
 	}
 }
 
+func isSameContent(localPath string, size int64, rc io.Reader) (bool, error) {
+	info, err := os.Stat(localPath)
+	if err != nil {
+		if os.IsNotExist(err) {
+			return false, nil
+		}
+		return false, err
+	}
+
+	if info.Size() != size {
+		return false, nil
+	}
+	localFile, err := os.Open(localPath)
+	if err != nil {
+		return false, err
+	}
+	defer localFile.Close()
+	h1 := sha256.New()
+	h2 := sha256.New()
+	if _, err := io.Copy(h1, localFile); err != nil {
+		return false, err
+	}
+	if _, err := io.Copy(h2, rc); err != nil {
+		return false, err
+	}
+	return bytes.Equal(h1.Sum(nil), h2.Sum(nil)), nil
+}
+
 func deleteExtraFiles(driver *Strm, localPath string, objs []model.Obj) {
+	if driver.SaveLocalMode != SaveLocalSyncMode {
+		return
+	}
 	localFiles, err := getLocalFiles(localPath)
 	if err != nil {
 		log.Errorf("Failed to read local files from %s: %v", localPath, err)
@@ -151,15 +196,6 @@ func deleteExtraFiles(driver *Strm, localPath string, objs []model.Obj) {
 
 	for _, localFile := range localFiles {
 		if _, exists := objsSet[localFile]; !exists {
-			ext := utils.Ext(localFile)
-			localFileName := stdpath.Base(localFile)
-			localFileBaseName := strings.TrimSuffix(localFile, utils.SourceExt(localFileName))
-			_, nameExists := objsBaseNameSet[localFileBaseName[:len(localFileBaseName)-1]]
-			_, downloadFile := driver.downloadSuffix[ext]
-			if driver.KeepLocalDownloadFile && nameExists && downloadFile {
-				continue
-			}
-
 			err := os.Remove(localFile)
 			if err != nil {
 				log.Errorf("Failed to delete file: %s, error: %v\n", localFile, err)
diff --git a/drivers/strm/meta.go b/drivers/strm/meta.go
index 3575bc102..efb9defa6 100644
--- a/drivers/strm/meta.go
+++ b/drivers/strm/meta.go
@@ -5,6 +5,12 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/op"
 )
 
+const (
+	SaveLocalInsertMode = "insert"
+	SaveLocalUpdateMode = "update"
+	SaveLocalSyncMode   = "sync"
+)
+
 type Addition struct {
 	Paths                 string `json:"paths" required:"true" type:"text"`
 	SiteUrl               string `json:"siteUrl" type:"text" required:"false" help:"The prefix URL of the strm file"`
@@ -13,9 +19,11 @@ type Addition struct {
 	FilterFileTypes       string `json:"filterFileTypes" type:"text" default:"mp4,mkv,flv,avi,wmv,ts,rmvb,webm,mp3,flac,aac,wav,ogg,m4a,wma,alac" required:"false" help:"Supports suffix name of strm file"`
 	EncodePath            bool   `json:"encodePath" default:"true" required:"true" help:"encode the path in the strm file"`
 	WithoutUrl            bool   `json:"withoutUrl" default:"false" help:"strm file content without URL prefix"`
+	WithSign              bool   `json:"withSign" default:"false"`
 	SaveStrmToLocal       bool   `json:"SaveStrmToLocal" default:"false" help:"save strm file locally"`
 	SaveStrmLocalPath     string `json:"SaveStrmLocalPath" type:"text" help:"save strm file local path"`
 	KeepLocalDownloadFile bool   `json:"KeepLocalDownloadFile" default:"false" help:"keep local download files"`
+	SaveLocalMode         string `json:"SaveLocalMode" type:"select" help:"save strm file locally mode" options:"insert,update,sync" default:"insert"`
 	Version               int
 }
 
diff --git a/drivers/strm/util.go b/drivers/strm/util.go
index 4189ade14..b9a40da5e 100644
--- a/drivers/strm/util.go
+++ b/drivers/strm/util.go
@@ -18,6 +18,7 @@ func (d *Strm) listRoot() []model.Obj {
 	var objs []model.Obj
 	for k := range d.pathMap {
 		obj := model.Object{
+			Path:     "/" + k,
 			Name:     k,
 			IsFolder: true,
 			Modified: d.Modified,
@@ -67,8 +68,8 @@ func (d *Strm) convert2strmObjs(ctx context.Context, reqPath string, objs []mode
 		size := int64(0)
 		if !obj.IsDir() {
 			path = stdpath.Join(reqPath, obj.GetName())
-			ext := strings.ToLower(utils.Ext(name))
 			sourceExt := utils.SourceExt(name)
+			ext := strings.ToLower(sourceExt)
 			if _, ok := d.downloadSuffix[ext]; ok {
 				size = obj.GetSize()
 			} else if _, ok := d.supportSuffix[ext]; ok {
@@ -107,7 +108,7 @@ func (d *Strm) getLink(ctx context.Context, path string) string {
 	if d.EncodePath {
 		finalPath = utils.EncodePath(path, true)
 	}
-	if d.EnableSign {
+	if d.WithSign {
 		signPath := sign.Sign(path)
 		finalPath = fmt.Sprintf("%s?sign=%s", finalPath, signPath)
 	}
diff --git a/drivers/teldrive/driver.go b/drivers/teldrive/driver.go
index 541d2e3be..11ba0971e 100644
--- a/drivers/teldrive/driver.go
+++ b/drivers/teldrive/driver.go
@@ -6,6 +6,7 @@ import (
 	"math"
 	"net/http"
 	"net/url"
+	"path"
 	"strings"
 
 	"github.com/OpenListTeam/OpenList/v4/drivers/base"
@@ -65,6 +66,7 @@ func (d *Teldrive) List(ctx context.Context, dir model.Obj, args model.ListArgs)
 
 	return utils.SliceConvert(listResp.Items, func(src Object) (model.Obj, error) {
 		return &model.Object{
+			Path: path.Join(dir.GetPath(), src.Name),
 			ID:   src.ID,
 			Name: src.Name,
 			Size: func() int64 {
diff --git a/drivers/teldrive/upload.go b/drivers/teldrive/upload.go
index 4f717dc8e..87cffa1ae 100644
--- a/drivers/teldrive/upload.go
+++ b/drivers/teldrive/upload.go
@@ -179,6 +179,7 @@ func (d *Teldrive) doSingleUpload(ctx context.Context, dstDir model.Obj, file mo
 
 			return nil
 		},
+			retry.Context(ctx),
 			retry.Attempts(3),
 			retry.DelayType(retry.BackOffDelay),
 			retry.Delay(time.Second)); err != nil {
diff --git a/drivers/terabox/driver.go b/drivers/terabox/driver.go
index 3c9d265c2..5323b1887 100644
--- a/drivers/terabox/driver.go
+++ b/drivers/terabox/driver.go
@@ -7,7 +7,6 @@ import (
 	"encoding/hex"
 	"fmt"
 	"io"
-	"math"
 	stdpath "path"
 	"strconv"
 
@@ -63,7 +62,9 @@ func (d *Terabox) List(ctx context.Context, dir model.Obj, args model.ListArgs)
 		return nil, err
 	}
 	return utils.SliceConvert(files, func(src File) (model.Obj, error) {
-		return fileToObj(src), nil
+		obj := fileToObj(src)
+		obj.Path = stdpath.Join(dir.GetPath(), obj.Name)
+		return obj, nil
 	})
 }
 
@@ -193,7 +194,7 @@ func (d *Terabox) Put(ctx context.Context, dstDir model.Obj, stream model.FileSt
 	streamSize := stream.GetSize()
 	chunkSize := calculateChunkSize(streamSize)
 	chunkByteData := make([]byte, chunkSize)
-	count := int(math.Ceil(float64(streamSize) / float64(chunkSize)))
+	count := int((streamSize + chunkSize - 1) / chunkSize)
 	left := streamSize
 	uploadBlockList := make([]string, 0, count)
 	h := md5.New()
diff --git a/drivers/url_tree/driver.go b/drivers/url_tree/driver.go
index 36579d3cd..c1af0b3fb 100644
--- a/drivers/url_tree/driver.go
+++ b/drivers/url_tree/driver.go
@@ -44,6 +44,10 @@ func (d *Urls) Drop(ctx context.Context) error {
 	return nil
 }
 
+func (Addition) GetRootPath() string {
+	return "/"
+}
+
 func (d *Urls) Get(ctx context.Context, path string) (model.Obj, error) {
 	d.mutex.RLock()
 	defer d.mutex.RUnlock()
diff --git a/drivers/url_tree/meta.go b/drivers/url_tree/meta.go
index 3dfa83129..9d2f182ba 100644
--- a/drivers/url_tree/meta.go
+++ b/drivers/url_tree/meta.go
@@ -6,10 +6,6 @@ import (
 )
 
 type Addition struct {
-	// Usually one of two
-	// driver.RootPath
-	// driver.RootID
-	// define other
 	UrlStructure string `json:"url_structure" type:"text" required:"true" default:"https://raw.githubusercontent.com/OpenListTeam/OpenList/main/README.md\nhttps://raw.githubusercontent.com/OpenListTeam/OpenList/main/README_cn.md\nfolder:\n  CONTRIBUTING.md:1635:https://raw.githubusercontent.com/OpenListTeam/OpenList/main/CONTRIBUTING.md\n  CODE_OF_CONDUCT.md:2093:https://raw.githubusercontent.com/OpenListTeam/OpenList/main/CODE_OF_CONDUCT.md" help:"structure:FolderName:\n  [FileName:][FileSize:][Modified:]Url"`
 	HeadSize     bool   `json:"head_size" type:"bool" default:"false" help:"Use head method to get file size, but it may be failed."`
 	Writable     bool   `json:"writable" type:"bool" default:"false"`
diff --git a/drivers/uss/driver.go b/drivers/uss/driver.go
index 8f33a5b0b..3606278d7 100644
--- a/drivers/uss/driver.go
+++ b/drivers/uss/driver.go
@@ -62,6 +62,7 @@ func (d *USS) List(ctx context.Context, dir model.Obj, args model.ListArgs) ([]m
 	for obj := range objsChan {
 		t := obj.Time
 		f := model.Object{
+			Path:     path.Join(dir.GetPath(), obj.Name),
 			Name:     obj.Name,
 			Size:     obj.Size,
 			Modified: t,
diff --git a/drivers/webdav/driver.go b/drivers/webdav/driver.go
index a6a18d85d..a6732e9a2 100644
--- a/drivers/webdav/driver.go
+++ b/drivers/webdav/driver.go
@@ -54,6 +54,7 @@ func (d *WebDav) List(ctx context.Context, dir model.Obj, args model.ListArgs) (
 	}
 	return utils.SliceConvert(files, func(src os.FileInfo) (model.Obj, error) {
 		return &model.Object{
+			Path:     path.Join(dir.GetPath(), src.Name()),
 			Name:     src.Name(),
 			Size:     src.Size(),
 			Modified: src.ModTime(),
diff --git a/drivers/weiyun/driver.go b/drivers/weiyun/driver.go
index ef203cfa4..3ce5dda28 100644
--- a/drivers/weiyun/driver.go
+++ b/drivers/weiyun/driver.go
@@ -20,6 +20,7 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
 	"github.com/avast/retry-go"
 	weiyunsdkgo "github.com/foxxorcat/weiyun-sdk-go"
+	"github.com/go-resty/resty/v2"
 )
 
 type WeiYun struct {
@@ -67,7 +68,7 @@ func (d *WeiYun) Init(ctx context.Context) error {
 	})
 
 	// qqCookieä¿æ´»
-	if d.client.LoginType() == 1 {
+	if d.client.LoginType() == weiyunsdkgo.AccountTypeQQ || d.client.LoginType() == weiyunsdkgo.AccountTypeQQOpenID {
 		d.cron = cron.NewCron(time.Minute * 5)
 		d.cron.Do(func() {
 			_ = d.client.KeepAlive()
@@ -391,6 +392,19 @@ func (d *WeiYun) Put(ctx context.Context, dstDir model.Obj, stream model.FileStr
 	}, nil
 }
 
+func (d *WeiYun) GetDetails(ctx context.Context) (*model.StorageDetails, error) {
+	info, err := d.client.DiskUserInfoGet(func(request *resty.Request) {
+		request.SetContext(ctx)
+	})
+	if err != nil {
+		return nil, err
+	}
+
+	return &model.StorageDetails{
+		DiskUsage: driver.DiskUsageFromUsedAndTotal(uint64(info.UsedSpace), uint64(info.TotalSpace)),
+	}, nil
+}
+
 // func (d *WeiYun) Other(ctx context.Context, args model.OtherArgs) (interface{}, error) {
 // 	return nil, errs.NotSupport
 // }
@@ -405,3 +419,4 @@ var _ driver.Remove = (*WeiYun)(nil)
 
 var _ driver.PutResult = (*WeiYun)(nil)
 var _ driver.RenameResult = (*WeiYun)(nil)
+var _ driver.WithDetails = (*WeiYun)(nil)
diff --git a/drivers/wps/driver.go b/drivers/wps/driver.go
new file mode 100644
index 000000000..0450bd34c
--- /dev/null
+++ b/drivers/wps/driver.go
@@ -0,0 +1,78 @@
+package wps
+
+import (
+	"context"
+	"fmt"
+
+	"github.com/OpenListTeam/OpenList/v4/internal/driver"
+	"github.com/OpenListTeam/OpenList/v4/internal/errs"
+	"github.com/OpenListTeam/OpenList/v4/internal/model"
+)
+
+type Wps struct {
+	model.Storage
+	Addition
+	companyID string
+}
+
+func (d *Wps) Config() driver.Config {
+	return config
+}
+
+func (d *Wps) GetAddition() driver.Additional {
+	return &d.Addition
+}
+
+func (d *Wps) Init(ctx context.Context) error {
+	if d.Cookie == "" {
+		return fmt.Errorf("cookie is empty")
+	}
+	return d.ensureCompanyID(ctx)
+}
+
+func (d *Wps) Drop(ctx context.Context) error {
+	return nil
+}
+
+func (d *Wps) List(ctx context.Context, dir model.Obj, _ model.ListArgs) ([]model.Obj, error) {
+	basePath := "/"
+	if dir != nil {
+		if p := dir.GetPath(); p != "" {
+			basePath = p
+		}
+	}
+	return d.list(ctx, basePath)
+}
+
+func (d *Wps) Link(ctx context.Context, file model.Obj, _ model.LinkArgs) (*model.Link, error) {
+	if file == nil {
+		return nil, errs.NotSupport
+	}
+	return d.link(ctx, file.GetPath())
+}
+
+func (d *Wps) MakeDir(ctx context.Context, parentDir model.Obj, dirName string) error {
+	return d.makeDir(ctx, parentDir, dirName)
+}
+
+func (d *Wps) Move(ctx context.Context, srcObj, dstDir model.Obj) error {
+	return d.move(ctx, srcObj, dstDir)
+}
+
+func (d *Wps) Rename(ctx context.Context, srcObj model.Obj, newName string) error {
+	return d.rename(ctx, srcObj, newName)
+}
+
+func (d *Wps) Copy(ctx context.Context, srcObj, dstDir model.Obj) error {
+	return d.copy(ctx, srcObj, dstDir)
+}
+
+func (d *Wps) Remove(ctx context.Context, obj model.Obj) error {
+	return d.remove(ctx, obj)
+}
+
+func (d *Wps) Put(ctx context.Context, dstDir model.Obj, file model.FileStreamer, up driver.UpdateProgress) error {
+	return d.put(ctx, dstDir, file, up)
+}
+
+var _ driver.Driver = (*Wps)(nil)
diff --git a/drivers/wps/meta.go b/drivers/wps/meta.go
new file mode 100644
index 000000000..7a3362f3a
--- /dev/null
+++ b/drivers/wps/meta.go
@@ -0,0 +1,26 @@
+package wps
+
+import (
+	"github.com/OpenListTeam/OpenList/v4/internal/driver"
+	"github.com/OpenListTeam/OpenList/v4/internal/op"
+)
+
+type Addition struct {
+	driver.RootPath
+	Cookie string `json:"cookie" required:"true" type:"text"`
+	Mode   string `json:"mode" type:"select" options:"Personal,Business" default:"Business"`
+}
+
+var config = driver.Config{
+	Name:              "WPS",
+	LocalSort:         true,
+	DefaultRoot:       "/",
+	Alert:             "",
+	NoOverwriteUpload: true,
+}
+
+func init() {
+	op.RegisterDriver(func() driver.Driver {
+		return &Wps{}
+	})
+}
diff --git a/drivers/wps/types.go b/drivers/wps/types.go
new file mode 100644
index 000000000..f057d5257
--- /dev/null
+++ b/drivers/wps/types.go
@@ -0,0 +1,94 @@
+package wps
+
+import (
+	"time"
+
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+)
+
+type workspaceResp struct {
+	Companies []struct {
+		ID int64 `json:"id"`
+	} `json:"companies"`
+}
+
+type Group struct {
+	CompanyID int64  `json:"company_id"`
+	GroupID   int64  `json:"group_id"`
+	Name      string `json:"name"`
+	Type      string `json:"type"`
+}
+
+type groupsResp struct {
+	Groups []Group `json:"groups"`
+}
+
+type filePerms struct {
+	Download int `json:"download"`
+}
+
+type FileInfo struct {
+	GroupID   int64     `json:"groupid"`
+	ParentID  int64     `json:"parentid"`
+	Name      string    `json:"fname"`
+	Size      int64     `json:"fsize"`
+	Type      string    `json:"ftype"`
+	Ctime     int64     `json:"ctime"`
+	Mtime     int64     `json:"mtime"`
+	ID        int64     `json:"id"`
+	Deleted   bool      `json:"deleted"`
+	FilePerms filePerms `json:"file_perms_acl"`
+}
+
+type filesResp struct {
+	Files []FileInfo `json:"files"`
+}
+
+type downloadResp struct {
+	URL    string `json:"url"`
+	Result string `json:"result"`
+}
+
+type Obj struct {
+	id          string
+	name        string
+	size        int64
+	ctime       time.Time
+	mtime       time.Time
+	isDir       bool
+	hash        utils.HashInfo
+	path        string
+	canDownload bool
+}
+
+func (o *Obj) GetSize() int64 {
+	return o.size
+}
+
+func (o *Obj) GetName() string {
+	return o.name
+}
+
+func (o *Obj) ModTime() time.Time {
+	return o.mtime
+}
+
+func (o *Obj) CreateTime() time.Time {
+	return o.ctime
+}
+
+func (o *Obj) IsDir() bool {
+	return o.isDir
+}
+
+func (o *Obj) GetHash() utils.HashInfo {
+	return o.hash
+}
+
+func (o *Obj) GetID() string {
+	return o.id
+}
+
+func (o *Obj) GetPath() string {
+	return o.path
+}
diff --git a/drivers/wps/util.go b/drivers/wps/util.go
new file mode 100644
index 000000000..a08b27005
--- /dev/null
+++ b/drivers/wps/util.go
@@ -0,0 +1,1049 @@
+package wps
+
+import (
+	"bytes"
+	"context"
+	"crypto/sha1"
+	"crypto/sha256"
+	"encoding/hex"
+	"encoding/json"
+	"fmt"
+	"io"
+	"mime/multipart"
+	"net/http"
+	"strconv"
+	"strings"
+	"sync"
+	"time"
+
+	"github.com/OpenListTeam/OpenList/v4/drivers/base"
+	"github.com/OpenListTeam/OpenList/v4/internal/driver"
+	"github.com/OpenListTeam/OpenList/v4/internal/errs"
+	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	"github.com/go-resty/resty/v2"
+)
+
+const endpoint = "https://365.kdocs.cn"
+const personalEndpoint = "https://drive.wps.cn"
+
+type resolvedNode struct {
+	kind  string
+	group Group
+	file  *FileInfo
+}
+
+type resolveCacheEntry struct {
+	node   *resolvedNode
+	expire time.Time
+}
+
+type resolveCacheStore struct {
+	mu sync.RWMutex
+	m  map[string]resolveCacheEntry
+}
+
+var resolveCaches sync.Map
+
+type apiResult struct {
+	Result string `json:"result"`
+	Msg    string `json:"msg"`
+}
+
+type uploadCreateUpdateResp struct {
+	apiResult
+	Method  string `json:"method"`
+	URL     string `json:"url"`
+	Store   string `json:"store"`
+	Request struct {
+		Headers  map[string]string `json:"headers"`
+		FormData map[string]string `json:"formData"`
+	} `json:"request"`
+	Response struct {
+		ExpectCode []int  `json:"expect_code"`
+		ArgsETag   string `json:"args_etag"`
+		ArgsKey    string `json:"args_key"`
+	} `json:"response"`
+}
+
+type uploadPutResp struct {
+	NewFilename string `json:"newfilename"`
+	Sha1        string `json:"sha1"`
+	MD5         string `json:"md5"`
+}
+
+type personalGroupsResp struct {
+	apiResult
+	Groups []struct {
+		ID   int64  `json:"id"`
+		Name string `json:"name"`
+	} `json:"groups"`
+}
+
+type countingWriter struct {
+	n *int64
+}
+
+func (w countingWriter) Write(p []byte) (int, error) {
+	*w.n += int64(len(p))
+	return len(p), nil
+}
+
+func (d *Wps) isPersonal() bool {
+	return strings.TrimSpace(d.Mode) == "Personal"
+}
+
+func (d *Wps) driveHost() string {
+	if d.isPersonal() {
+		return personalEndpoint
+	}
+	return endpoint
+}
+
+func (d *Wps) drivePrefix() string {
+	if d.isPersonal() {
+		return ""
+	}
+	return "/3rd/drive"
+}
+
+func (d *Wps) driveURL(path string) string {
+	return d.driveHost() + d.drivePrefix() + path
+}
+
+func (d *Wps) origin() string {
+	return d.driveHost()
+}
+
+func (d *Wps) canDownload(f *FileInfo) bool {
+	if f == nil || f.Type == "folder" {
+		return false
+	}
+	if f.FilePerms.Download != 0 {
+		return true
+	}
+	return d.isPersonal()
+}
+
+func (d *Wps) request(ctx context.Context) *resty.Request {
+	return base.RestyClient.R().
+		SetHeader("Cookie", d.Cookie).
+		SetHeader("Accept", "application/json").
+		SetContext(ctx)
+}
+
+func (d *Wps) jsonRequest(ctx context.Context) *resty.Request {
+	return d.request(ctx).
+		SetHeader("Content-Type", "application/json").
+		SetHeader("Origin", d.origin())
+}
+
+func statusOK(code int, expect []int) bool {
+	if len(expect) == 0 {
+		return code >= 200 && code < 300
+	}
+	for _, v := range expect {
+		if v == code {
+			return true
+		}
+	}
+	return false
+}
+
+func respArg(arg string, resp *http.Response, body []byte) string {
+	arg = strings.TrimSpace(arg)
+	if arg == "" {
+		return ""
+	}
+	l := strings.ToLower(arg)
+	if strings.HasPrefix(l, "header.") {
+		h := strings.TrimSpace(arg[len("header."):])
+		if h == "" {
+			return ""
+		}
+		return strings.TrimSpace(resp.Header.Get(h))
+	}
+	if strings.HasPrefix(l, "body.") {
+		k := strings.TrimSpace(arg[len("body."):])
+		if k == "" {
+			return ""
+		}
+		var m map[string]interface{}
+		if err := json.Unmarshal(body, &m); err != nil {
+			return ""
+		}
+		if v, ok := m[k]; ok {
+			if s, ok := v.(string); ok {
+				return strings.TrimSpace(s)
+			}
+		}
+	}
+	return ""
+}
+
+func extractXMLTag(v, tag string) string {
+	s := strings.TrimSpace(v)
+	if s == "" {
+		return ""
+	}
+	lt := strings.ToLower(tag)
+	open := "<" + lt + ">"
+	clos := "</" + lt + ">"
+	ls := strings.ToLower(s)
+	i := strings.Index(ls, open)
+	if i < 0 {
+		return ""
+	}
+	i += len(open)
+	j := strings.Index(ls[i:], clos)
+	if j < 0 {
+		return ""
+	}
+	r := strings.TrimSpace(s[i : i+j])
+	r = strings.ReplaceAll(r, "&quot;", "")
+	return strings.Trim(r, `"'`)
+}
+
+func checkAPI(resp *resty.Response, result apiResult) error {
+	if result.Result != "" && result.Result != "ok" {
+		if result.Msg == "" {
+			result.Msg = "unknown error"
+		}
+		return fmt.Errorf("%s: %s", result.Result, result.Msg)
+	}
+	if resp != nil && resp.IsError() {
+		if result.Msg != "" {
+			return fmt.Errorf("%s", result.Msg)
+		}
+		return fmt.Errorf("http error: %d", resp.StatusCode())
+	}
+	return nil
+}
+
+func (d *Wps) ensureCompanyID(ctx context.Context) error {
+	if d.isPersonal() {
+		return nil
+	}
+	if d.companyID != "" {
+		return nil
+	}
+	var resp workspaceResp
+	r, err := d.request(ctx).SetResult(&resp).SetError(&resp).Get(endpoint + "/3rd/plussvr/compose/v1/users/self/workspaces?fields=name&comp_status=active")
+	if err != nil {
+		return err
+	}
+	if r != nil && r.IsError() {
+		return fmt.Errorf("http error: %d", r.StatusCode())
+	}
+	if len(resp.Companies) == 0 {
+		return fmt.Errorf("no company id")
+	}
+	d.companyID = strconv.FormatInt(resp.Companies[0].ID, 10)
+	return nil
+}
+
+func (d *Wps) getGroups(ctx context.Context) ([]Group, error) {
+	if d.isPersonal() {
+		var resp personalGroupsResp
+		r, err := d.request(ctx).SetResult(&resp).SetError(&resp).Get(d.driveURL("/api/v3/groups"))
+		if err != nil {
+			return nil, err
+		}
+		if err := checkAPI(r, resp.apiResult); err != nil {
+			return nil, err
+		}
+		res := make([]Group, 0, len(resp.Groups))
+		for _, g := range resp.Groups {
+			res = append(res, Group{GroupID: g.ID, Name: g.Name})
+		}
+		return res, nil
+	}
+	if err := d.ensureCompanyID(ctx); err != nil {
+		return nil, err
+	}
+	var resp groupsResp
+	url := fmt.Sprintf("%s/3rd/plus/groups/v1/companies/%s/users/self/groups/private", endpoint, d.companyID)
+	r, err := d.request(ctx).SetResult(&resp).SetError(&resp).Get(url)
+	if err != nil {
+		return nil, err
+	}
+	if r != nil && r.IsError() {
+		return nil, fmt.Errorf("http error: %d", r.StatusCode())
+	}
+	return resp.Groups, nil
+}
+
+func (d *Wps) getFiles(ctx context.Context, groupID, parentID int64) ([]FileInfo, error) {
+	var resp filesResp
+	url := fmt.Sprintf("%s/api/v5/groups/%d/files", d.driveHost()+d.drivePrefix(), groupID)
+	r, err := d.request(ctx).
+		SetQueryParam("parentid", strconv.FormatInt(parentID, 10)).
+		SetResult(&resp).
+		SetError(&resp).
+		Get(url)
+	if err != nil {
+		return nil, err
+	}
+	if r != nil && r.IsError() {
+		return nil, fmt.Errorf("http error: %d", r.StatusCode())
+	}
+	return resp.Files, nil
+}
+
+func parseTime(v int64) time.Time {
+	if v <= 0 {
+		return time.Time{}
+	}
+	return time.Unix(v, 0)
+}
+
+func joinPath(basePath, name string) string {
+	if basePath == "" || basePath == "/" {
+		return "/" + name
+	}
+	return strings.TrimRight(basePath, "/") + "/" + name
+}
+
+func normalizePath(path string) string {
+	clean := strings.TrimSpace(path)
+	if clean == "" || clean == "/" {
+		return "/"
+	}
+	return "/" + strings.Trim(clean, "/")
+}
+
+func (d *Wps) resolveCacheStore() *resolveCacheStore {
+	if d == nil {
+		return nil
+	}
+	if v, ok := resolveCaches.Load(d); ok {
+		if s, ok := v.(*resolveCacheStore); ok {
+			return s
+		}
+	}
+	s := &resolveCacheStore{m: make(map[string]resolveCacheEntry)}
+	if v, loaded := resolveCaches.LoadOrStore(d, s); loaded {
+		if s2, ok := v.(*resolveCacheStore); ok {
+			return s2
+		}
+	}
+	return s
+}
+
+func (d *Wps) getResolveCache(path string) (*resolvedNode, bool) {
+	s := d.resolveCacheStore()
+	if s == nil {
+		return nil, false
+	}
+	s.mu.RLock()
+	e, ok := s.m[path]
+	s.mu.RUnlock()
+	if !ok || e.node == nil {
+		return nil, false
+	}
+	if !e.expire.IsZero() && time.Now().After(e.expire) {
+		s.mu.Lock()
+		delete(s.m, path)
+		s.mu.Unlock()
+		return nil, false
+	}
+	return e.node, true
+}
+
+func (d *Wps) setResolveCache(path string, node *resolvedNode) {
+	s := d.resolveCacheStore()
+	if s == nil || node == nil {
+		return
+	}
+	s.mu.Lock()
+	s.m[path] = resolveCacheEntry{node: node, expire: time.Now().Add(10 * time.Minute)}
+	s.mu.Unlock()
+}
+
+func (d *Wps) clearResolveCache() {
+	s := d.resolveCacheStore()
+	if s == nil {
+		return
+	}
+	s.mu.Lock()
+	if len(s.m) != 0 {
+		s.m = make(map[string]resolveCacheEntry)
+	}
+	s.mu.Unlock()
+}
+
+func (d *Wps) resolvePath(ctx context.Context, path string) (*resolvedNode, error) {
+	cacheKey := normalizePath(path)
+	if n, ok := d.getResolveCache(cacheKey); ok {
+		return n, nil
+	}
+	clean := strings.TrimSpace(path)
+	if clean == "" {
+		clean = "/"
+	}
+	clean = strings.Trim(clean, "/")
+	if clean == "" {
+		n := &resolvedNode{kind: "root"}
+		d.setResolveCache("/", n)
+		return n, nil
+	}
+	seg := strings.Split(clean, "/")
+	groups, err := d.getGroups(ctx)
+	if err != nil {
+		return nil, err
+	}
+	var grp *Group
+	for i := range groups {
+		if groups[i].Name == seg[0] {
+			grp = &groups[i]
+			break
+		}
+	}
+	if grp == nil {
+		return nil, fmt.Errorf("group not found")
+	}
+	cur := "/" + seg[0]
+	gn := &resolvedNode{kind: "group", group: *grp}
+	d.setResolveCache(cur, gn)
+	if len(seg) == 1 {
+		return gn, nil
+	}
+	parentID := int64(0)
+	var lastNode *resolvedNode
+	for i := 1; i < len(seg); i++ {
+		files, err := d.getFiles(ctx, grp.GroupID, parentID)
+		if err != nil {
+			return nil, err
+		}
+		var found *FileInfo
+		for j := range files {
+			if files[j].Name == seg[i] {
+				found = &files[j]
+				break
+			}
+		}
+		if found == nil {
+			return nil, fmt.Errorf("path not found")
+		}
+		if i < len(seg)-1 && found.Type != "folder" {
+			return nil, fmt.Errorf("path not found")
+		}
+		fi := *found
+		parentID = fi.ID
+		cur = cur + "/" + seg[i]
+		kind := "file"
+		if fi.Type == "folder" {
+			kind = "folder"
+		}
+		n := &resolvedNode{kind: kind, group: *grp, file: &fi}
+		d.setResolveCache(cur, n)
+		lastNode = n
+	}
+	if lastNode == nil {
+		return nil, fmt.Errorf("path not found")
+	}
+	return lastNode, nil
+}
+
+func (d *Wps) fileToObj(basePath string, f FileInfo) *Obj {
+	name := f.Name
+	path := joinPath(basePath, name)
+	obj := &Obj{
+		id:    path,
+		name:  name,
+		size:  f.Size,
+		ctime: parseTime(f.Ctime),
+		mtime: parseTime(f.Mtime),
+		isDir: f.Type == "folder",
+		path:  path,
+	}
+	if !obj.isDir {
+		obj.canDownload = d.canDownload(&f)
+	}
+	return obj
+}
+
+func (d *Wps) doJSON(ctx context.Context, method, url string, body interface{}) error {
+	var result apiResult
+	req := d.jsonRequest(ctx).SetBody(body).SetResult(&result).SetError(&result)
+	var (
+		resp *resty.Response
+		err  error
+	)
+	switch method {
+	case http.MethodPost:
+		resp, err = req.Post(url)
+	case http.MethodPut:
+		resp, err = req.Put(url)
+	default:
+		return errs.NotSupport
+	}
+	if err != nil {
+		return err
+	}
+	return checkAPI(resp, result)
+}
+
+func (d *Wps) list(ctx context.Context, basePath string) ([]model.Obj, error) {
+	if strings.TrimSpace(basePath) == "" {
+		basePath = "/"
+	}
+	node, err := d.resolvePath(ctx, basePath)
+	if err != nil {
+		return nil, err
+	}
+	if node.kind == "root" {
+		groups, err := d.getGroups(ctx)
+		if err != nil {
+			return nil, err
+		}
+		res := make([]model.Obj, 0, len(groups))
+		for _, g := range groups {
+			path := joinPath(basePath, g.Name)
+			obj := &Obj{
+				id:    path,
+				name:  g.Name,
+				ctime: parseTime(0),
+				mtime: parseTime(0),
+				isDir: true,
+				path:  path,
+			}
+			res = append(res, obj)
+			d.setResolveCache(normalizePath(path), &resolvedNode{kind: "group", group: g})
+		}
+		d.setResolveCache("/", &resolvedNode{kind: "root"})
+		return res, nil
+	}
+	if node.kind != "group" && node.kind != "folder" {
+		return nil, nil
+	}
+	parentID := int64(0)
+	if node.file != nil && node.kind == "folder" {
+		parentID = node.file.ID
+	}
+	files, err := d.getFiles(ctx, node.group.GroupID, parentID)
+	if err != nil {
+		return nil, err
+	}
+	res := make([]model.Obj, 0, len(files))
+	for _, f := range files {
+		res = append(res, d.fileToObj(basePath, f))
+		path := normalizePath(joinPath(basePath, f.Name))
+		fi := f
+		kind := "file"
+		if fi.Type == "folder" {
+			kind = "folder"
+		}
+		d.setResolveCache(path, &resolvedNode{kind: kind, group: node.group, file: &fi})
+	}
+	return res, nil
+}
+
+func (d *Wps) link(ctx context.Context, path string) (*model.Link, error) {
+	node, err := d.resolvePath(ctx, path)
+	if err != nil {
+		return nil, err
+	}
+	if node.kind != "file" || node.file == nil {
+		return nil, errs.NotSupport
+	}
+	if !d.canDownload(node.file) {
+		return nil, fmt.Errorf("no download permission")
+	}
+	url := fmt.Sprintf("%s/api/v5/groups/%d/files/%d/download?support_checksums=sha1", d.driveHost()+d.drivePrefix(), node.group.GroupID, node.file.ID)
+	var resp downloadResp
+	r, err := d.request(ctx).SetResult(&resp).SetError(&resp).Get(url)
+	if err != nil {
+		return nil, err
+	}
+	if r != nil && r.IsError() {
+		return nil, fmt.Errorf("http error: %d", r.StatusCode())
+	}
+	if resp.URL == "" {
+		return nil, fmt.Errorf("empty download url")
+	}
+	return &model.Link{URL: resp.URL, Header: http.Header{}}, nil
+}
+
+func (d *Wps) makeDir(ctx context.Context, parentDir model.Obj, dirName string) error {
+	if parentDir == nil {
+		return errs.NotSupport
+	}
+	node, err := d.resolvePath(ctx, parentDir.GetPath())
+	if err != nil {
+		return err
+	}
+	if node.kind != "group" && node.kind != "folder" {
+		return errs.NotSupport
+	}
+	parentID := int64(0)
+	if node.file != nil && node.kind == "folder" {
+		parentID = node.file.ID
+	}
+	body := map[string]interface{}{
+		"groupid":  node.group.GroupID,
+		"name":     dirName,
+		"parentid": parentID,
+	}
+	if err := d.doJSON(ctx, http.MethodPost, d.driveURL("/api/v5/files/folder"), body); err != nil {
+		return err
+	}
+	d.clearResolveCache()
+	return nil
+}
+
+func (d *Wps) move(ctx context.Context, srcObj, dstDir model.Obj) error {
+	if srcObj == nil || dstDir == nil {
+		return errs.NotSupport
+	}
+	nodeSrc, err := d.resolvePath(ctx, srcObj.GetPath())
+	if err != nil {
+		return err
+	}
+	nodeDst, err := d.resolvePath(ctx, dstDir.GetPath())
+	if err != nil {
+		return err
+	}
+	if nodeSrc.kind != "file" && nodeSrc.kind != "folder" {
+		return errs.NotSupport
+	}
+	if nodeDst.kind != "group" && nodeDst.kind != "folder" {
+		return errs.NotSupport
+	}
+	targetParentID := int64(0)
+	if nodeDst.file != nil && nodeDst.kind == "folder" {
+		targetParentID = nodeDst.file.ID
+	}
+	body := map[string]interface{}{
+		"fileids":         []int64{nodeSrc.file.ID},
+		"target_groupid":  nodeDst.group.GroupID,
+		"target_parentid": targetParentID,
+	}
+	url := fmt.Sprintf("/api/v3/groups/%d/files/batch/move", nodeSrc.group.GroupID)
+	for {
+		var res apiResult
+		resp, err := d.jsonRequest(ctx).
+			SetBody(body).
+			SetResult(&res).
+			SetError(&res).
+			Post(d.driveURL(url))
+		if err != nil {
+			return err
+		}
+
+		if resp.StatusCode() == 403 && res.Result == "fileTaskDuplicated" {
+			time.Sleep(500 * time.Millisecond)
+			continue
+		}
+
+		if err := checkAPI(resp, res); err != nil {
+			return err
+		}
+		break
+	}
+	d.clearResolveCache()
+	return nil
+}
+
+func (d *Wps) rename(ctx context.Context, srcObj model.Obj, newName string) error {
+	if srcObj == nil {
+		return errs.NotSupport
+	}
+	node, err := d.resolvePath(ctx, srcObj.GetPath())
+	if err != nil {
+		return err
+	}
+	if node.kind != "file" && node.kind != "folder" {
+		return errs.NotSupport
+	}
+	url := fmt.Sprintf("/api/v3/groups/%d/files/%d", node.group.GroupID, node.file.ID)
+	body := map[string]string{"fname": newName}
+	if err := d.doJSON(ctx, http.MethodPut, d.driveURL(url), body); err != nil {
+		return err
+	}
+	d.clearResolveCache()
+	return nil
+}
+
+func (d *Wps) copy(ctx context.Context, srcObj, dstDir model.Obj) error {
+	if srcObj == nil || dstDir == nil {
+		return errs.NotSupport
+	}
+	nodeSrc, err := d.resolvePath(ctx, srcObj.GetPath())
+	if err != nil {
+		return err
+	}
+	nodeDst, err := d.resolvePath(ctx, dstDir.GetPath())
+	if err != nil {
+		return err
+	}
+	if nodeSrc.kind != "file" && nodeSrc.kind != "folder" {
+		return errs.NotSupport
+	}
+	if nodeDst.kind != "group" && nodeDst.kind != "folder" {
+		return errs.NotSupport
+	}
+	targetParentID := int64(0)
+	if nodeDst.file != nil && nodeDst.kind == "folder" {
+		targetParentID = nodeDst.file.ID
+	}
+	body := map[string]interface{}{
+		"fileids":               []int64{nodeSrc.file.ID},
+		"groupid":               nodeSrc.group.GroupID,
+		"target_groupid":        nodeDst.group.GroupID,
+		"target_parentid":       targetParentID,
+		"duplicated_name_model": 1,
+	}
+	url := fmt.Sprintf("/api/v3/groups/%d/files/batch/copy", nodeSrc.group.GroupID)
+	for {
+		var res apiResult
+		resp, err := d.jsonRequest(ctx).
+			SetBody(body).
+			SetResult(&res).
+			SetError(&res).
+			Post(d.driveURL(url))
+		if err != nil {
+			return err
+		}
+
+		if resp.StatusCode() == 403 && res.Result == "fileTaskDuplicated" {
+			time.Sleep(500 * time.Millisecond)
+			continue
+		}
+
+		if err := checkAPI(resp, res); err != nil {
+			return err
+		}
+		break
+	}
+	d.clearResolveCache()
+	return nil
+}
+
+func (d *Wps) remove(ctx context.Context, obj model.Obj) error {
+	if obj == nil {
+		return errs.NotSupport
+	}
+	node, err := d.resolvePath(ctx, obj.GetPath())
+	if err != nil {
+		return err
+	}
+	if node.kind != "file" && node.kind != "folder" {
+		return errs.NotSupport
+	}
+
+	body := map[string]interface{}{
+		"fileids": []int64{node.file.ID},
+	}
+	url := fmt.Sprintf("/api/v3/groups/%d/files/batch/delete", node.group.GroupID)
+
+	for {
+		var res apiResult
+		resp, err := d.jsonRequest(ctx).
+			SetBody(body).
+			SetResult(&res).
+			SetError(&res).
+			Post(d.driveURL(url))
+		if err != nil {
+			return err
+		}
+
+		// æ— æ³•è¿ç»­åˆ›å»ºæ–‡ä»¶å¤¹åˆ é™¤ã€‚å¦‚æœä¸€å®šè¦åˆ é™¤ï¼Œæ¯0.5s å°è¯•ä¸€æ¬¡åˆ›å»ºä¸‹ä¸€ä¸ªåˆ é™¤è¯·æ±‚ï¼Œåº”å½“é¿å…é€’å½’åˆ é™¤æ–‡ä»¶å¤¹
+		if resp.StatusCode() == 403 && res.Result == "fileTaskDuplicated" {
+			time.Sleep(500 * time.Millisecond)
+			continue
+		}
+
+		if err := checkAPI(resp, res); err != nil {
+			return err
+		}
+		break
+	}
+	d.clearResolveCache()
+	return nil
+}
+
+func cacheAndHash(file model.FileStreamer, up driver.UpdateProgress) (model.File, int64, string, string, error) {
+	h1 := sha1.New()
+	h256 := sha256.New()
+	size := file.GetSize()
+	var counted int64
+	ws := []io.Writer{h1, h256}
+	if size <= 0 {
+		ws = append(ws, countingWriter{n: &counted})
+	}
+	p := up
+	f, err := file.CacheFullAndWriter(&p, io.MultiWriter(ws...))
+	if err != nil {
+		return nil, 0, "", "", err
+	}
+	if size <= 0 {
+		size = counted
+	}
+	return f, size, hex.EncodeToString(h1.Sum(nil)), hex.EncodeToString(h256.Sum(nil)), nil
+}
+
+func (d *Wps) createUpload(ctx context.Context, groupID, parentID int64, name string, size int64, sha1Hex, sha256Hex string) (*uploadCreateUpdateResp, error) {
+	body := map[string]string{
+		"group_id":  strconv.FormatInt(groupID, 10),
+		"name":      name,
+		"parent_id": strconv.FormatInt(parentID, 10),
+		"sha1":      sha1Hex,
+		"sha256":    sha256Hex,
+		"size":      strconv.FormatInt(size, 10),
+	}
+	var resp uploadCreateUpdateResp
+	r, err := d.jsonRequest(ctx).
+		SetBody(body).
+		SetResult(&resp).
+		SetError(&resp).
+		Put(d.driveURL("/api/v5/files/upload/create_update"))
+	if err != nil {
+		return nil, err
+	}
+	if err := checkAPI(r, resp.apiResult); err != nil {
+		return nil, err
+	}
+	if resp.URL == "" {
+		return nil, fmt.Errorf("empty upload url")
+	}
+	return &resp, nil
+}
+
+func normalizeETag(v string) string {
+	v = strings.TrimSpace(v)
+	if strings.HasPrefix(v, "W/") {
+		v = strings.TrimSpace(strings.TrimPrefix(v, "W/"))
+	}
+	return strings.Trim(v, `"`)
+}
+
+func (d *Wps) commitUpload(ctx context.Context, etag, key string, groupID, parentID int64, name, sha1Hex string, size int64, store string) error {
+	store = strings.TrimSpace(store)
+	if store == "" {
+		store = "ks3"
+	}
+	storeKey := ""
+	if key != "" {
+		storeKey = key
+	}
+	body := map[string]interface{}{
+		"etag":     etag,
+		"groupid":  groupID,
+		"key":      key,
+		"name":     name,
+		"parentid": parentID,
+		"sha1":     sha1Hex,
+		"size":     size,
+		"store":    store,
+		"storekey": storeKey,
+	}
+	return d.doJSON(ctx, http.MethodPost, d.driveURL("/api/v5/files/file"), body)
+}
+
+func (d *Wps) put(ctx context.Context, dstDir model.Obj, file model.FileStreamer, up driver.UpdateProgress) error {
+	if dstDir == nil || file == nil {
+		return errs.NotSupport
+	}
+	if up == nil {
+		up = func(float64) {}
+	}
+	node, err := d.resolvePath(ctx, dstDir.GetPath())
+	if err != nil {
+		return err
+	}
+	if node.kind != "group" && node.kind != "folder" {
+		return errs.NotSupport
+	}
+	parentID := int64(0)
+	if node.file != nil && node.kind == "folder" {
+		parentID = node.file.ID
+	}
+	f, size, sha1Hex, sha256Hex, err := cacheAndHash(file, func(float64) {})
+	if err != nil {
+		return err
+	}
+	if c, ok := f.(io.Closer); ok {
+		defer c.Close()
+	}
+
+	// åœ¨éšè—æ–‡ä»¶åå‰åŠ _ä¸Šä¼ ï¼Œè¿™æ˜¯WPSçš„é™åˆ¶ï¼Œæ— æ³•ä¸Šä¼ éšè—æ–‡ä»¶ï¼Œä¹Ÿæ— æ³•å°†ä»»ä½•æ–‡ä»¶é‡å‘½åä¸ºéšè—æ–‡ä»¶ï¼Œæ‰€æœ‰éšè—æ–‡ä»¶ä¼šè¢«è‡ªåŠ¨åŠ ä¸Š_ ä¸Šä¼ 
+	// ç”šè‡³å¯ä»¥ä¸Šä¼ å‰ç¼€æ˜¯..çš„æ–‡ä»¶ï¼Œä½†æ˜¯å•ä¸ªç‚¹å°±æ˜¯ä¸è¡Œ
+	realName := file.GetName()
+	uploadName := realName
+	if strings.HasPrefix(realName, ".") {
+		uploadName = "_" + realName
+	}
+
+	info, err := d.createUpload(ctx, node.group.GroupID, parentID, uploadName, size, sha1Hex, sha256Hex)
+	if err != nil {
+		return err
+	}
+	if _, err := f.Seek(0, io.SeekStart); err != nil {
+		return err
+	}
+	rf := driver.NewLimitedUploadFile(ctx, f)
+	prog := driver.NewProgress(size, model.UpdateProgressWithRange(up, 0, 1))
+
+	method := strings.ToUpper(strings.TrimSpace(info.Method))
+	if method == "" {
+		method = http.MethodPut
+	}
+
+	var req *http.Request
+	if method == http.MethodPost && len(info.Request.FormData) > 0 {
+		if size == 0 {
+			var buf bytes.Buffer
+			mw := multipart.NewWriter(&buf)
+			for k, v := range info.Request.FormData {
+				if err := mw.WriteField(k, v); err != nil {
+					return err
+				}
+			}
+			part, err := mw.CreateFormFile("file", uploadName)
+			if err != nil {
+				return err
+			}
+			if _, err := io.Copy(part, io.TeeReader(rf, prog)); err != nil {
+				return err
+			}
+			if err := mw.Close(); err != nil {
+				return err
+			}
+			req, err = http.NewRequestWithContext(ctx, method, info.URL, bytes.NewReader(buf.Bytes()))
+			if err != nil {
+				return err
+			}
+			for k, v := range info.Request.Headers {
+				req.Header.Set(k, v)
+			}
+			req.Header.Set("Content-Type", mw.FormDataContentType())
+			req.ContentLength = int64(buf.Len())
+			req.Header.Set("Content-Length", strconv.FormatInt(req.ContentLength, 10))
+		} else {
+			pr, pw := io.Pipe()
+			mw := multipart.NewWriter(pw)
+			req, err = http.NewRequestWithContext(ctx, method, info.URL, pr)
+			if err != nil {
+				return err
+			}
+			for k, v := range info.Request.Headers {
+				req.Header.Set(k, v)
+			}
+			req.Header.Set("Content-Type", mw.FormDataContentType())
+			go func() {
+				for k, v := range info.Request.FormData {
+					if err := mw.WriteField(k, v); err != nil {
+						pw.CloseWithError(err)
+						return
+					}
+				}
+				part, err := mw.CreateFormFile("file", uploadName)
+				if err != nil {
+					pw.CloseWithError(err)
+					return
+				}
+				if _, err := io.Copy(part, io.TeeReader(rf, prog)); err != nil {
+					pw.CloseWithError(err)
+					return
+				}
+				if err := mw.Close(); err != nil {
+					pw.CloseWithError(err)
+					return
+				}
+				pw.Close()
+			}()
+		}
+	} else {
+		var body = io.TeeReader(rf, prog)
+		if size == 0 {
+			body = bytes.NewReader(nil)
+		}
+		req, err = http.NewRequestWithContext(ctx, method, info.URL, body)
+		if err != nil {
+			return err
+		}
+		for k, v := range info.Request.Headers {
+			req.Header.Set(k, v)
+		}
+		req.ContentLength = size
+		req.Header.Set("Content-Length", strconv.FormatInt(size, 10))
+	}
+
+	c := *base.RestyClient.GetClient()
+	c.Timeout = 0
+	resp, err := (&c).Do(req)
+	if err != nil {
+		return err
+	}
+	defer resp.Body.Close()
+
+	if !statusOK(resp.StatusCode, info.Response.ExpectCode) {
+		io.Copy(io.Discard, resp.Body)
+		return fmt.Errorf("http error: %d", resp.StatusCode)
+	}
+
+	body, err := io.ReadAll(resp.Body)
+	if err != nil {
+		return err
+	}
+
+	etag := normalizeETag(respArg(info.Response.ArgsETag, resp, body))
+	if etag == "" {
+		etag = normalizeETag(resp.Header.Get("ETag"))
+	}
+
+	key := strings.TrimSpace(respArg(info.Response.ArgsKey, resp, body))
+	if key == "" {
+		key = strings.TrimSpace(resp.Header.Get("x-obs-save-key"))
+	}
+
+	var pr uploadPutResp
+	sha1FromServer := ""
+	if err := json.Unmarshal(body, &pr); err == nil {
+		sha1FromServer = strings.TrimSpace(pr.NewFilename)
+		if sha1FromServer == "" {
+			sha1FromServer = strings.TrimSpace(pr.Sha1)
+		}
+		if etag == "" && pr.MD5 != "" {
+			etag = strings.TrimSpace(pr.MD5)
+		}
+	}
+
+	if sha1FromServer == "" {
+		if v := extractXMLTag(string(body), "ETag"); v != "" {
+			sha1FromServer = v
+			if etag == "" {
+				etag = v
+			}
+		}
+	}
+	if sha1FromServer == "" && key != "" && len(key) == 40 {
+		sha1FromServer = key
+	}
+	if sha1FromServer == "" {
+		sha1FromServer = sha1Hex
+	}
+
+	if etag == "" {
+		return fmt.Errorf("empty etag")
+	}
+	if sha1FromServer == "" {
+		return fmt.Errorf("empty sha1")
+	}
+
+	store := strings.TrimSpace(info.Store)
+	commitKey := ""
+	if strings.TrimSpace(info.Response.ArgsKey) != "" {
+		commitKey = key
+		if commitKey == "" {
+			commitKey = sha1FromServer
+		}
+	}
+
+	if err := d.commitUpload(ctx, etag, commitKey, node.group.GroupID, parentID, uploadName, sha1FromServer, size, store); err != nil {
+		return err
+	}
+
+	up(1)
+	return nil
+}
diff --git a/drivers/yandex_disk/driver.go b/drivers/yandex_disk/driver.go
index b3591f380..2a7996e22 100644
--- a/drivers/yandex_disk/driver.go
+++ b/drivers/yandex_disk/driver.go
@@ -41,7 +41,9 @@ func (d *YandexDisk) List(ctx context.Context, dir model.Obj, args model.ListArg
 		return nil, err
 	}
 	return utils.SliceConvert(files, func(src File) (model.Obj, error) {
-		return fileToObj(src), nil
+		obj := fileToObj(src)
+		obj.Path = path.Join(dir.GetPath(), obj.Name)
+		return obj, nil
 	})
 }
 
diff --git a/drivers/yandex_disk/types.go b/drivers/yandex_disk/types.go
index 2481f051e..78e6203c5 100644
--- a/drivers/yandex_disk/types.go
+++ b/drivers/yandex_disk/types.go
@@ -42,7 +42,7 @@ type File struct {
 	//Revision   int64     `json:"revision"`
 }
 
-func fileToObj(f File) model.Obj {
+func fileToObj(f File) *model.Object {
 	return &model.Object{
 		Name:     f.Name,
 		Size:     f.Size,
diff --git a/drivers/yandex_disk/util.go b/drivers/yandex_disk/util.go
index e6f4cab06..2da2cb73a 100644
--- a/drivers/yandex_disk/util.go
+++ b/drivers/yandex_disk/util.go
@@ -23,7 +23,6 @@ func (d *YandexDisk) refreshToken() error {
 			ErrorMessage string `json:"text"`
 		}
 		_, err := base.RestyClient.R().
-			SetHeader("User-Agent", "Mozilla/5.0 (Macintosh; Apple macOS 15_5) AppleWebKit/537.36 (KHTML, like Gecko) Safari/537.36 Chrome/138.0.0.0 Openlist/425.6.30").
 			SetResult(&resp).
 			SetQueryParams(map[string]string{
 				"refresh_ui": d.RefreshToken,
diff --git a/go.mod b/go.mod
index df1207a25..82a778d02 100644
--- a/go.mod
+++ b/go.mod
@@ -9,7 +9,7 @@ require (
 	github.com/KirCute/zip v1.0.1
 	github.com/OpenListTeam/go-cache v0.1.0
 	github.com/OpenListTeam/sftpd-openlist v1.0.1
-	github.com/OpenListTeam/tache v0.2.1
+	github.com/OpenListTeam/tache v0.2.2
 	github.com/OpenListTeam/times v0.1.0
 	github.com/OpenListTeam/wopan-sdk-go v0.1.5
 	github.com/ProtonMail/go-crypto v1.3.0
@@ -19,6 +19,7 @@ require (
 	github.com/avast/retry-go v3.0.0+incompatible
 	github.com/aws/aws-sdk-go v1.55.7
 	github.com/blevesearch/bleve/v2 v2.5.2
+	github.com/bmatcuk/doublestar/v4 v4.9.1
 	github.com/caarlos0/env/v9 v9.0.0
 	github.com/charmbracelet/bubbles v0.21.0
 	github.com/charmbracelet/bubbletea v1.3.6
@@ -33,7 +34,7 @@ require (
 	github.com/dustinxie/ecc v0.0.0-20210511000915-959544187564
 	github.com/fclairamb/ftpserverlib v0.26.1-0.20250709223522-4a925d79caf6
 	github.com/foxxorcat/mopan-sdk-go v0.1.6
-	github.com/foxxorcat/weiyun-sdk-go v0.1.3
+	github.com/foxxorcat/weiyun-sdk-go v0.1.4
 	github.com/gin-contrib/cors v1.7.6
 	github.com/gin-gonic/gin v1.10.1
 	github.com/go-resty/resty/v2 v2.16.5
@@ -41,7 +42,7 @@ require (
 	github.com/golang-jwt/jwt/v4 v4.5.2
 	github.com/google/uuid v1.6.0
 	github.com/gorilla/websocket v1.5.3
-	github.com/halalcloud/golang-sdk-lite v0.0.0-20251006164234-3c629727c499
+	github.com/halalcloud/golang-sdk-lite v0.0.0-20251105081800-78cbb6786c38
 	github.com/hekmon/transmissionrpc/v3 v3.0.0
 	github.com/henrybear327/go-proton-api v1.0.0
 	github.com/ipfs/go-ipfs-api v0.7.0
diff --git a/go.sum b/go.sum
index 377e31868..029e5d514 100644
--- a/go.sum
+++ b/go.sum
@@ -55,8 +55,8 @@ github.com/OpenListTeam/gsync v0.1.0 h1:ywzGybOvA3lW8K1BUjKZ2IUlT2FSlzPO4DOazfYX
 github.com/OpenListTeam/gsync v0.1.0/go.mod h1:h/Rvv9aX/6CdW/7B8di3xK3xNV8dUg45Fehrd/ksZ9s=
 github.com/OpenListTeam/sftpd-openlist v1.0.1 h1:j4S3iPFOpnXCUKRPS7uCT4mF2VCl34GyqvH6lqwnkUU=
 github.com/OpenListTeam/sftpd-openlist v1.0.1/go.mod h1:uO/wKnbvbdq3rBLmClMTZXuCnw7XW4wlAq4dZe91a40=
-github.com/OpenListTeam/tache v0.2.1 h1:Uy/xAr05clHuMrr9+5fXAhv0Z5PGJivp4P5DnRez6cw=
-github.com/OpenListTeam/tache v0.2.1/go.mod h1:qmnZ/VpY2DUlmjg3UoDeNFy/LRqrw0biN3hYEEGc/+A=
+github.com/OpenListTeam/tache v0.2.2 h1:CWFn6sr1AIYaEjC8ONdKs+LrxHyuErheenAjEqRhh4k=
+github.com/OpenListTeam/tache v0.2.2/go.mod h1:qmnZ/VpY2DUlmjg3UoDeNFy/LRqrw0biN3hYEEGc/+A=
 github.com/OpenListTeam/times v0.1.0 h1:qknxw+qj5CYKgXAwydA102UEpPcpU8TYNGRmwRyPYpg=
 github.com/OpenListTeam/times v0.1.0/go.mod h1:Jx7qen5NCYzKk2w14YuvU48YYMcPa1P9a+EJePC15Pc=
 github.com/OpenListTeam/wopan-sdk-go v0.1.5 h1:iKKcVzIqBgtGDbn0QbdWrCazSGxXFmYFyrnFBG+U8dI=
@@ -180,6 +180,8 @@ github.com/blevesearch/zapx/v15 v15.4.2 h1:sWxpDE0QQOTjyxYbAVjt3+0ieu8NCE0fDRaFx
 github.com/blevesearch/zapx/v15 v15.4.2/go.mod h1:1pssev/59FsuWcgSnTa0OeEpOzmhtmr/0/11H0Z8+Nw=
 github.com/blevesearch/zapx/v16 v16.2.4 h1:tGgfvleXTAkwsD5mEzgM3zCS/7pgocTCnO1oyAUjlww=
 github.com/blevesearch/zapx/v16 v16.2.4/go.mod h1:Rti/REtuuMmzwsI8/C/qIzRaEoSK/wiFYw5e5ctUKKs=
+github.com/bmatcuk/doublestar/v4 v4.9.1 h1:X8jg9rRZmJd4yRy7ZeNDRnM+T3ZfHv15JiBJ/avrEXE=
+github.com/bmatcuk/doublestar/v4 v4.9.1/go.mod h1:xBQ8jztBU6kakFMg+8WGxn0c6z1fTSPVIjEY1Wr7jzc=
 github.com/bodgit/plumbing v1.3.0 h1:pf9Itz1JOQgn7vEOE7v7nlEfBykYqvUYioC61TwWCFU=
 github.com/bodgit/plumbing v1.3.0/go.mod h1:JOTb4XiRu5xfnmdnDJo6GmSbSbtSyufrsyZFByMtKEs=
 github.com/bodgit/sevenzip v1.6.1 h1:kikg2pUMYC9ljU7W9SaqHXhym5HyKm8/M/jd31fYan4=
@@ -283,8 +285,8 @@ github.com/felixge/httpsnoop v1.0.4 h1:NFTV2Zj1bL4mc9sqWACXbQFVBBg2W3GPvqp8/ESS2
 github.com/felixge/httpsnoop v1.0.4/go.mod h1:m8KPJKqk1gH5J9DgRY2ASl2lWCfGKXixSwevea8zH2U=
 github.com/foxxorcat/mopan-sdk-go v0.1.6 h1:6J37oI4wMZLj8EPgSCcSTTIbnI5D6RCNW/srX8vQd1Y=
 github.com/foxxorcat/mopan-sdk-go v0.1.6/go.mod h1:UaY6D88yBXWGrcu/PcyLWyL4lzrk5pSxSABPHftOvxs=
-github.com/foxxorcat/weiyun-sdk-go v0.1.3 h1:I5c5nfGErhq9DBumyjCVCggRA74jhgriMqRRFu5jeeY=
-github.com/foxxorcat/weiyun-sdk-go v0.1.3/go.mod h1:TPxzN0d2PahweUEHlOBWlwZSA+rELSUlGYMWgXRn9ps=
+github.com/foxxorcat/weiyun-sdk-go v0.1.4 h1:X2tFvdqikkJ7awCBbMH7XXk7+uQoJlQksJz9CUU6ZgA=
+github.com/foxxorcat/weiyun-sdk-go v0.1.4/go.mod h1:TPxzN0d2PahweUEHlOBWlwZSA+rELSUlGYMWgXRn9ps=
 github.com/fsnotify/fsnotify v1.4.7/go.mod h1:jwhsz4b93w/PPRr/qN1Yymfu8t87LnFCMoQvtojpjFo=
 github.com/fxamacker/cbor/v2 v2.9.0 h1:NpKPmjDBgUfBms6tr6JZkTHtfFGcMKsw3eGcmD/sapM=
 github.com/fxamacker/cbor/v2 v2.9.0/go.mod h1:vM4b+DJCtHn+zz7h3FFp/hDAI9WNWCsZj23V5ytsSxQ=
@@ -398,6 +400,8 @@ github.com/gorilla/websocket v1.5.3 h1:saDtZ6Pbx/0u+bgYQ3q96pZgCzfhKXGPqt7kZ72aN
 github.com/gorilla/websocket v1.5.3/go.mod h1:YR8l580nyteQvAITg2hZ9XVh4b55+EU/adAjf1fMHhE=
 github.com/halalcloud/golang-sdk-lite v0.0.0-20251006164234-3c629727c499 h1:4ovnBdiGDFi8putQGxhipuuhXItAgh4/YnzufPYkZkQ=
 github.com/halalcloud/golang-sdk-lite v0.0.0-20251006164234-3c629727c499/go.mod h1:8x1h4rm3s8xMcTyJrq848sQ6BJnKzl57mDY4CNshdPM=
+github.com/halalcloud/golang-sdk-lite v0.0.0-20251105081800-78cbb6786c38 h1:lsK2GVgI2Ox0NkRpQnN09GBOH7jtsjFK5tcIgxXlLr0=
+github.com/halalcloud/golang-sdk-lite v0.0.0-20251105081800-78cbb6786c38/go.mod h1:8x1h4rm3s8xMcTyJrq848sQ6BJnKzl57mDY4CNshdPM=
 github.com/hashicorp/errwrap v1.0.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=
 github.com/hashicorp/errwrap v1.1.0 h1:OxrOeh75EUXMY8TBjag2fzXGZ40LB6IKw45YeGUDY2I=
 github.com/hashicorp/errwrap v1.1.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=
diff --git a/internal/bootstrap/data/setting.go b/internal/bootstrap/data/setting.go
index 6adf90e68..7bff851de 100644
--- a/internal/bootstrap/data/setting.go
+++ b/internal/bootstrap/data/setting.go
@@ -208,6 +208,7 @@ func InitialSettings() []model.SettingItem {
 		// ldap settings
 		{Key: conf.LdapLoginEnabled, Value: "false", Type: conf.TypeBool, Group: model.LDAP, Flag: model.PUBLIC},
 		{Key: conf.LdapServer, Value: "", Type: conf.TypeString, Group: model.LDAP, Flag: model.PRIVATE},
+		{Key: conf.LdapSkipTlsVerify, Value: "false", Type: conf.TypeBool, Group: model.LDAP, Flag: model.PRIVATE},
 		{Key: conf.LdapManagerDN, Value: "", Type: conf.TypeString, Group: model.LDAP, Flag: model.PRIVATE},
 		{Key: conf.LdapManagerPassword, Value: "", Type: conf.TypeString, Group: model.LDAP, Flag: model.PRIVATE},
 		{Key: conf.LdapUserSearchBase, Value: "", Type: conf.TypeString, Group: model.LDAP, Flag: model.PRIVATE},
diff --git a/internal/bootstrap/patch.go b/internal/bootstrap/patch.go
index 1e76190c8..e8baeeac9 100644
--- a/internal/bootstrap/patch.go
+++ b/internal/bootstrap/patch.go
@@ -2,7 +2,6 @@ package bootstrap
 
 import (
 	"fmt"
-
 	"strings"
 
 	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap/patch"
diff --git a/internal/bootstrap/patch/all.go b/internal/bootstrap/patch/all.go
index 44ba17376..d5b94cb4b 100644
--- a/internal/bootstrap/patch/all.go
+++ b/internal/bootstrap/patch/all.go
@@ -4,7 +4,7 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap/patch/v3_24_0"
 	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap/patch/v3_32_0"
 	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap/patch/v3_41_0"
-	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap/patch/v3_all"
+	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap/patch/v4_1_8"
 )
 
 type VersionPatches struct {
@@ -34,9 +34,9 @@ var UpgradePatches = []VersionPatches{
 		},
 	},
 	{
-		Version: "v3.0.0",
+		Version: "v4.1.8",
 		Patches: []func(){
-			v3_all.RenameAlistV3Driver,
+			v4_1_8.FixAliasConfig,
 		},
 	},
 }
diff --git a/internal/bootstrap/patch/v3_24_0/hash_password.go b/internal/bootstrap/patch/v3_24_0/hash_password.go
index 881e3d47b..30a296c47 100644
--- a/internal/bootstrap/patch/v3_24_0/hash_password.go
+++ b/internal/bootstrap/patch/v3_24_0/hash_password.go
@@ -11,7 +11,8 @@ import (
 func HashPwdForOldVersion() {
 	users, _, err := op.GetUsers(1, -1)
 	if err != nil {
-		utils.Log.Fatalf("[hash pwd for old version] failed get users: %v", err)
+		utils.Log.Errorf("[hash pwd for old version] failed get users: %v", err)
+		return
 	}
 	for i := range users {
 		user := users[i]
@@ -19,7 +20,7 @@ func HashPwdForOldVersion() {
 			user.SetPassword(user.Password)
 			user.Password = ""
 			if err := db.UpdateUser(&user); err != nil {
-				utils.Log.Fatalf("[hash pwd for old version] failed update user: %v", err)
+				utils.Log.Errorf("[hash pwd for old version] failed update user: %v", err)
 			}
 		}
 	}
diff --git a/internal/bootstrap/patch/v3_32_0/update_authn.go b/internal/bootstrap/patch/v3_32_0/update_authn.go
index fea4bbfb1..721c3f582 100644
--- a/internal/bootstrap/patch/v3_32_0/update_authn.go
+++ b/internal/bootstrap/patch/v3_32_0/update_authn.go
@@ -11,14 +11,15 @@ import (
 func UpdateAuthnForOldVersion() {
 	users, _, err := op.GetUsers(1, -1)
 	if err != nil {
-		utils.Log.Fatalf("[update authn for old version] failed get users: %v", err)
+		utils.Log.Errorf("[update authn for old version] failed get users: %v", err)
+		return
 	}
 	for i := range users {
 		user := users[i]
 		if user.Authn == "" {
 			user.Authn = "[]"
 			if err := db.UpdateUser(&user); err != nil {
-				utils.Log.Fatalf("[update authn for old version] failed update user: %v", err)
+				utils.Log.Errorf("[update authn for old version] failed update user: %v", err)
 			}
 		}
 	}
diff --git a/internal/bootstrap/patch/v3_all/rename.go b/internal/bootstrap/patch/v3_all/rename.go
deleted file mode 100644
index 323b7391f..000000000
--- a/internal/bootstrap/patch/v3_all/rename.go
+++ /dev/null
@@ -1,33 +0,0 @@
-package v3_all
-
-import (
-	"github.com/OpenListTeam/OpenList/v4/internal/db"
-	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
-)
-
-// Rename Alist V3 driver to OpenList
-func RenameAlistV3Driver() {
-	storages, _, err := db.GetStorages(1, -1)
-	if err != nil {
-		utils.Log.Errorf("[RenameAlistV3Driver] failed to get storages: %s", err.Error())
-		return
-	}
-
-	updatedCount := 0
-	for _, s := range storages {
-		if s.Driver == "AList V3" {
-			utils.Log.Warnf("[RenameAlistV3Driver] rename storage [%d]%s from Alist V3 to OpenList", s.ID, s.MountPath)
-			s.Driver = "OpenList"
-			err = db.UpdateStorage(&s)
-			if err != nil {
-				utils.Log.Errorf("[RenameAlistV3Driver] failed to update storage [%d]%s: %s", s.ID, s.MountPath, err.Error())
-			} else {
-				updatedCount++
-			}
-		}
-	}
-
-	if updatedCount > 0 {
-		utils.Log.Infof("[RenameAlistV3Driver] updated %d storages from Alist V3 to OpenList", updatedCount)
-	}
-}
diff --git a/internal/bootstrap/patch/v4_1_8/alias.go b/internal/bootstrap/patch/v4_1_8/alias.go
new file mode 100644
index 000000000..e41742654
--- /dev/null
+++ b/internal/bootstrap/patch/v4_1_8/alias.go
@@ -0,0 +1,81 @@
+package v4_1_8
+
+import (
+	"github.com/OpenListTeam/OpenList/v4/internal/db"
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+)
+
+// FixAliasConfig upgrade the old version of the Addition of the Alias driver
+func FixAliasConfig() {
+	storages, _, err := db.GetStorages(1, -1)
+	if err != nil {
+		utils.Log.Errorf("[FixAliasConfig] failed to get storages: %s", err.Error())
+		return
+	}
+	for _, s := range storages {
+		if s.Driver != "Alias" {
+			continue
+		}
+		addition := make(map[string]any)
+		err = utils.Json.UnmarshalFromString(s.Addition, &addition)
+		if err != nil {
+			utils.Log.Errorf("[FixAliasConfig] failed to unmarshal addition of [%d]%s: %s", s.ID, s.MountPath, err.Error())
+			continue
+		}
+		if _, ok := addition["read_conflict_policy"]; ok {
+			utils.Log.Infof("[FixAliasConfig] skip fixing [%d]%s because the addition already has \"read_conflict_policy\" key", s.ID, s.MountPath)
+			continue
+		}
+		var protectSameName, parallelWrite, writable bool
+		protectSameNameAny, ok := addition["protect_same_name"]
+		if ok {
+			delete(addition, "protect_same_name")
+			protectSameName, ok = protectSameNameAny.(bool)
+		}
+		if !ok {
+			protectSameName = false
+		}
+		parallelWriteAny, ok := addition["parallel_write"]
+		if ok {
+			delete(addition, "parallel_write")
+			parallelWrite, ok = parallelWriteAny.(bool)
+		}
+		if !ok {
+			parallelWrite = false
+		}
+		writableAny, ok := addition["writable"]
+		if ok {
+			delete(addition, "writable")
+			writable, ok = writableAny.(bool)
+		}
+		if !ok {
+			writable = false
+		}
+		if !writable {
+			addition["write_conflict_policy"] = "disabled"
+			addition["put_conflict_policy"] = "disabled"
+		} else if !protectSameName && !parallelWrite {
+			addition["write_conflict_policy"] = "first"
+			addition["put_conflict_policy"] = "first"
+		} else if protectSameName && !parallelWrite {
+			addition["write_conflict_policy"] = "deterministic"
+			addition["put_conflict_policy"] = "deterministic"
+		} else if !protectSameName && parallelWrite {
+			addition["write_conflict_policy"] = "all"
+			addition["put_conflict_policy"] = "all"
+		} else {
+			addition["write_conflict_policy"] = "deterministic_or_all"
+			addition["put_conflict_policy"] = "deterministic_or_all"
+		}
+		addition["read_conflict_policy"] = "first"
+		s.Addition, err = utils.Json.MarshalToString(addition)
+		if err != nil {
+			utils.Log.Errorf("[FixAliasConfig] failed to marshal addition of [%d]%s: %s", s.ID, s.MountPath, err.Error())
+			continue
+		}
+		err = db.UpdateStorage(&s)
+		if err != nil {
+			utils.Log.Errorf("[FixAliasConfig] failed to update storage [%d]%s: %s", s.ID, s.MountPath, err.Error())
+		}
+	}
+}
diff --git a/internal/bootstrap/run.go b/internal/bootstrap/run.go
new file mode 100644
index 000000000..6740dba65
--- /dev/null
+++ b/internal/bootstrap/run.go
@@ -0,0 +1,404 @@
+package bootstrap
+
+import (
+	"context"
+	"fmt"
+	"net"
+	"net/http"
+	"os"
+	"strconv"
+	"sync"
+	"time"
+
+	"github.com/OpenListTeam/OpenList/v4/cmd/flags"
+	"github.com/OpenListTeam/OpenList/v4/internal/bootstrap/data"
+	"github.com/OpenListTeam/OpenList/v4/internal/conf"
+	"github.com/OpenListTeam/OpenList/v4/internal/db"
+	"github.com/OpenListTeam/OpenList/v4/internal/fs"
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+	"github.com/OpenListTeam/OpenList/v4/server"
+	"github.com/OpenListTeam/OpenList/v4/server/middlewares"
+	"github.com/OpenListTeam/sftpd-openlist"
+	ftpserver "github.com/fclairamb/ftpserverlib"
+	"github.com/gin-gonic/gin"
+	"github.com/google/uuid"
+	"github.com/pkg/errors"
+	"github.com/quic-go/quic-go/http3"
+	log "github.com/sirupsen/logrus"
+	"golang.org/x/net/http2"
+	"golang.org/x/net/http2/h2c"
+)
+
+func Init() {
+	InitConfig()
+	Log()
+	InitDB()
+	data.InitData()
+	InitStreamLimit()
+	InitIndex()
+	InitUpgradePatch()
+}
+
+func Release() {
+	db.Close()
+}
+
+var (
+	running      bool
+	httpSrv      *http.Server
+	httpRunning  bool
+	httpsSrv     *http.Server
+	httpsRunning bool
+	unixSrv      *http.Server
+	unixRunning  bool
+	quicSrv      *http3.Server
+	quicRunning  bool
+	s3Srv        *http.Server
+	s3Running    bool
+	ftpDriver    *server.FtpMainDriver
+	ftpServer    *ftpserver.FtpServer
+	ftpRunning   bool
+	sftpDriver   *server.SftpDriver
+	sftpServer   *sftpd.SftpServer
+	sftpRunning  bool
+)
+
+// Called by OpenList-Mobile
+func IsRunning(t string) bool {
+	switch t {
+	case "http":
+		return httpRunning
+	case "https":
+		return httpsRunning
+	case "unix":
+		return unixRunning
+	case "quic":
+		return quicRunning
+	case "s3":
+		return s3Running
+	case "sftp":
+		return sftpRunning
+	case "ftp":
+		return ftpRunning
+	}
+	return running
+}
+
+func Start() {
+	if conf.Conf.DelayedStart != 0 {
+		utils.Log.Infof("delayed start for %d seconds", conf.Conf.DelayedStart)
+		time.Sleep(time.Duration(conf.Conf.DelayedStart) * time.Second)
+	}
+	InitOfflineDownloadTools()
+	LoadStorages()
+	InitTaskManager()
+	if !flags.Debug && !flags.Dev {
+		gin.SetMode(gin.ReleaseMode)
+	}
+	r := gin.New()
+
+	// gin log
+	if conf.Conf.Log.Filter.Enable {
+		r.Use(middlewares.FilteredLogger())
+	} else {
+		r.Use(gin.LoggerWithWriter(log.StandardLogger().Out))
+	}
+	r.Use(gin.RecoveryWithWriter(log.StandardLogger().Out))
+
+	server.Init(r)
+	var httpHandler http.Handler = r
+	if conf.Conf.Scheme.EnableH2c {
+		httpHandler = h2c.NewHandler(r, &http2.Server{})
+	}
+	if conf.Conf.Scheme.HttpPort != -1 {
+		httpBase := fmt.Sprintf("%s:%d", conf.Conf.Scheme.Address, conf.Conf.Scheme.HttpPort)
+		fmt.Printf("start HTTP server @ %s\n", httpBase)
+		utils.Log.Infof("start HTTP server @ %s", httpBase)
+		httpSrv = &http.Server{Addr: httpBase, Handler: httpHandler}
+		go func() {
+			httpRunning = true
+			err := httpSrv.ListenAndServe()
+			httpRunning = false
+			if err != nil && !errors.Is(err, http.ErrServerClosed) {
+				handleEndpointStartFailedHooks("http", err)
+				utils.Log.Errorf("failed to start http: %s", err.Error())
+			} else {
+				handleEndpointShutdownHooks("http")
+			}
+		}()
+	}
+	if conf.Conf.Scheme.HttpsPort != -1 {
+		httpsBase := fmt.Sprintf("%s:%d", conf.Conf.Scheme.Address, conf.Conf.Scheme.HttpsPort)
+		fmt.Printf("start HTTPS server @ %s\n", httpsBase)
+		utils.Log.Infof("start HTTPS server @ %s", httpsBase)
+		httpsSrv = &http.Server{Addr: httpsBase, Handler: r}
+		go func() {
+			httpsRunning = true
+			err := httpsSrv.ListenAndServeTLS(conf.Conf.Scheme.CertFile, conf.Conf.Scheme.KeyFile)
+			httpsRunning = false
+			if err != nil && !errors.Is(err, http.ErrServerClosed) {
+				handleEndpointStartFailedHooks("https", err)
+				utils.Log.Errorf("failed to start https: %s", err.Error())
+			} else {
+				handleEndpointShutdownHooks("https")
+			}
+		}()
+		if conf.Conf.Scheme.EnableH3 {
+			fmt.Printf("start HTTP3 (quic) server @ %s\n", httpsBase)
+			utils.Log.Infof("start HTTP3 (quic) server @ %s", httpsBase)
+			r.Use(func(c *gin.Context) {
+				if c.Request.TLS != nil {
+					port := conf.Conf.Scheme.HttpsPort
+					c.Header("Alt-Svc", fmt.Sprintf("h3=\":%d\"; ma=86400", port))
+				}
+				c.Next()
+			})
+			quicSrv = &http3.Server{Addr: httpsBase, Handler: r}
+			go func() {
+				quicRunning = true
+				err := quicSrv.ListenAndServeTLS(conf.Conf.Scheme.CertFile, conf.Conf.Scheme.KeyFile)
+				quicRunning = false
+				if err != nil && !errors.Is(err, http.ErrServerClosed) {
+					handleEndpointStartFailedHooks("quic", err)
+					utils.Log.Errorf("failed to start http3 (quic): %s", err.Error())
+				} else {
+					handleEndpointShutdownHooks("quic")
+				}
+			}()
+		}
+	}
+	if conf.Conf.Scheme.UnixFile != "" {
+		fmt.Printf("start unix server @ %s\n", conf.Conf.Scheme.UnixFile)
+		utils.Log.Infof("start unix server @ %s", conf.Conf.Scheme.UnixFile)
+		unixSrv = &http.Server{Handler: httpHandler}
+		go func() {
+			listener, err := net.Listen("unix", conf.Conf.Scheme.UnixFile)
+			if err != nil {
+				utils.Log.Errorf("failed to listen unix: %+v", err)
+				return
+			}
+			unixRunning = true
+			// set socket file permission
+			mode, err := strconv.ParseUint(conf.Conf.Scheme.UnixFilePerm, 8, 32)
+			if err != nil {
+				utils.Log.Errorf("failed to parse socket file permission: %+v", err)
+			} else {
+				err = os.Chmod(conf.Conf.Scheme.UnixFile, os.FileMode(mode))
+				if err != nil {
+					utils.Log.Errorf("failed to chmod socket file: %+v", err)
+				}
+			}
+			err = unixSrv.Serve(listener)
+			unixRunning = false
+			if err != nil && !errors.Is(err, http.ErrServerClosed) {
+				handleEndpointStartFailedHooks("unix", err)
+				utils.Log.Errorf("failed to start unix: %s", err.Error())
+			} else {
+				handleEndpointShutdownHooks("unix")
+			}
+		}()
+	}
+	if conf.Conf.S3.Port != -1 && conf.Conf.S3.Enable {
+		s3r := gin.New()
+		s3r.Use(gin.LoggerWithWriter(log.StandardLogger().Out), gin.RecoveryWithWriter(log.StandardLogger().Out))
+		server.InitS3(s3r)
+		s3Base := fmt.Sprintf("%s:%d", conf.Conf.Scheme.Address, conf.Conf.S3.Port)
+		fmt.Printf("start S3 server @ %s\n", s3Base)
+		utils.Log.Infof("start S3 server @ %s", s3Base)
+		go func() {
+			s3Running = true
+			var err error
+			if conf.Conf.S3.SSL {
+				s3Srv = &http.Server{Addr: s3Base, Handler: s3r}
+				err = s3Srv.ListenAndServeTLS(conf.Conf.Scheme.CertFile, conf.Conf.Scheme.KeyFile)
+			} else {
+				s3Srv = &http.Server{Addr: s3Base, Handler: s3r}
+				err = s3Srv.ListenAndServe()
+			}
+			s3Running = false
+			if err != nil && !errors.Is(err, http.ErrServerClosed) {
+				handleEndpointStartFailedHooks("s3", err)
+				utils.Log.Errorf("failed to start s3 server: %s", err.Error())
+			} else {
+				handleEndpointShutdownHooks("s3")
+			}
+		}()
+	}
+	if conf.Conf.FTP.Listen != "" && conf.Conf.FTP.Enable {
+		var err error
+		ftpDriver, err = server.NewMainDriver()
+		if err != nil {
+			utils.Log.Errorf("failed to start ftp driver: %s", err.Error())
+		} else {
+			fmt.Printf("start ftp server on %s\n", conf.Conf.FTP.Listen)
+			utils.Log.Infof("start ftp server on %s", conf.Conf.FTP.Listen)
+			go func() {
+				ftpServer = ftpserver.NewFtpServer(ftpDriver)
+				ftpRunning = true
+				err = ftpServer.ListenAndServe()
+				ftpRunning = false
+				if err != nil {
+					handleEndpointStartFailedHooks("ftp", err)
+					utils.Log.Errorf("problem ftp server listening: %s", err.Error())
+				} else {
+					handleEndpointShutdownHooks("ftp")
+				}
+			}()
+		}
+	}
+	if conf.Conf.SFTP.Listen != "" && conf.Conf.SFTP.Enable {
+		var err error
+		sftpDriver, err = server.NewSftpDriver()
+		if err != nil {
+			utils.Log.Errorf("failed to start sftp driver: %s", err.Error())
+		} else {
+			fmt.Printf("start sftp server on %s", conf.Conf.SFTP.Listen)
+			utils.Log.Infof("start sftp server on %s", conf.Conf.SFTP.Listen)
+			go func() {
+				sftpServer = sftpd.NewSftpServer(sftpDriver)
+				sftpRunning = true
+				err = sftpServer.RunServer()
+				sftpRunning = false
+				if err != nil {
+					handleEndpointStartFailedHooks("sftp", err)
+					utils.Log.Errorf("problem sftp server listening: %s", err.Error())
+				} else {
+					handleEndpointShutdownHooks("sftp")
+				}
+			}()
+		}
+	}
+	running = true
+}
+
+func Shutdown(timeout time.Duration) {
+	utils.Log.Println("Shutdown server...")
+	fs.ArchiveContentUploadTaskManager.RemoveAll()
+	ctx, cancel := context.WithTimeout(context.Background(), timeout)
+	defer cancel()
+	var wg sync.WaitGroup
+	if httpSrv != nil && conf.Conf.Scheme.HttpPort != -1 {
+		wg.Add(1)
+		go func() {
+			defer wg.Done()
+			if err := httpSrv.Shutdown(ctx); err != nil {
+				utils.Log.Error("HTTP server shutdown err: ", err)
+			}
+			httpSrv = nil
+		}()
+	}
+	if httpsSrv != nil && conf.Conf.Scheme.HttpsPort != -1 {
+		wg.Add(1)
+		go func() {
+			defer wg.Done()
+			if err := httpsSrv.Shutdown(ctx); err != nil {
+				utils.Log.Error("HTTPS server shutdown err: ", err)
+			}
+			httpsSrv = nil
+		}()
+		if quicSrv != nil && conf.Conf.Scheme.EnableH3 {
+			wg.Add(1)
+			go func() {
+				defer wg.Done()
+				if err := quicSrv.Shutdown(ctx); err != nil {
+					utils.Log.Error("HTTP3 (quic) server shutdown err: ", err)
+				}
+				quicSrv = nil
+			}()
+		}
+	}
+	if unixSrv != nil && conf.Conf.Scheme.UnixFile != "" {
+		wg.Add(1)
+		go func() {
+			defer wg.Done()
+			if err := unixSrv.Shutdown(ctx); err != nil {
+				utils.Log.Error("Unix server shutdown err: ", err)
+			}
+			unixSrv = nil
+		}()
+	}
+	if s3Srv != nil && conf.Conf.S3.Port != -1 && conf.Conf.S3.Enable {
+		wg.Add(1)
+		go func() {
+			defer wg.Done()
+			if err := s3Srv.Shutdown(ctx); err != nil {
+				utils.Log.Error("S3 server shutdown err: ", err)
+			}
+			s3Srv = nil
+		}()
+	}
+	if conf.Conf.FTP.Listen != "" && conf.Conf.FTP.Enable && ftpServer != nil {
+		wg.Add(1)
+		go func() {
+			defer wg.Done()
+			if ftpDriver != nil {
+				ftpDriver.Stop()
+				ftpDriver = nil
+			}
+			if err := ftpServer.Stop(); err != nil {
+				utils.Log.Error("FTP server shutdown err: ", err)
+			}
+			ftpServer = nil
+		}()
+	}
+	if conf.Conf.SFTP.Listen != "" && conf.Conf.SFTP.Enable && sftpServer != nil {
+		wg.Add(1)
+		go func() {
+			defer wg.Done()
+			if err := sftpServer.Close(); err != nil {
+				utils.Log.Error("SFTP server shutdown err: ", err)
+			}
+			sftpServer = nil
+			sftpDriver = nil
+		}()
+	}
+	wg.Wait()
+	utils.Log.Println("Server exit")
+	running = false
+}
+
+type EndpointStartFailedHook func(string, string)
+
+type EndpointShutdownHook func(string)
+
+var (
+	endpointStartFailedHooks map[string]EndpointStartFailedHook
+	endpointShutdownHooks    map[string]EndpointShutdownHook
+)
+
+func RegisterEndpointStartFailedHook(hook EndpointStartFailedHook) string {
+	id := uuid.NewString()
+	endpointStartFailedHooks[id] = hook
+	return id
+}
+
+func RemoveEndpointStartFailedHook(id string) {
+	delete(endpointStartFailedHooks, id)
+}
+
+func RegisterEndpointShutdownHook(hook EndpointShutdownHook) string {
+	id := uuid.NewString()
+	endpointShutdownHooks[id] = hook
+	return id
+}
+
+func RemoveEndpointShutdownHook(id string) {
+	delete(endpointShutdownHooks, id)
+}
+
+func handleEndpointStartFailedHooks(t string, err error) {
+	for _, hook := range endpointStartFailedHooks {
+		hook(t, err.Error())
+	}
+}
+
+func handleEndpointShutdownHooks(t string) {
+	for _, hook := range endpointShutdownHooks {
+		hook(t)
+	}
+}
+
+func init() {
+	endpointShutdownHooks = make(map[string]EndpointShutdownHook)
+	endpointStartFailedHooks = make(map[string]EndpointStartFailedHook)
+}
diff --git a/internal/cache/keyed_cache.go b/internal/cache/keyed_cache.go
index 87e71f183..07bf8cd9f 100644
--- a/internal/cache/keyed_cache.go
+++ b/internal/cache/keyed_cache.go
@@ -70,7 +70,7 @@ func (c *KeyedCache[T]) Delete(key string) {
 	delete(c.entries, key)
 }
 
-func (c *KeyedCache[T]) Take(key string) (T, bool) {
+func (c *KeyedCache[T]) Pop(key string) (T, bool) {
 	c.mu.Lock()
 	defer c.mu.Unlock()
 	if entry, exists := c.entries[key]; exists {
diff --git a/internal/conf/const.go b/internal/conf/const.go
index 80337da83..ace486e8e 100644
--- a/internal/conf/const.go
+++ b/internal/conf/const.go
@@ -115,6 +115,7 @@ const (
 	// ldap
 	LdapLoginEnabled      = "ldap_login_enabled"
 	LdapServer            = "ldap_server"
+	LdapSkipTlsVerify     = "ldap_skip_tls_verify"
 	LdapManagerDN         = "ldap_manager_dn"
 	LdapManagerPassword   = "ldap_manager_password"
 	LdapUserSearchBase    = "ldap_user_search_base"
@@ -170,7 +171,7 @@ const (
 )
 
 // ContextKey is the type of context keys.
-type ContextKey int
+type ContextKey int8
 
 const (
 	_ ContextKey = iota
@@ -186,4 +187,5 @@ const (
 	UserAgentKey
 	PathKey
 	SharingIDKey
+	SkipHookKey
 )
diff --git a/internal/driver/driver.go b/internal/driver/driver.go
index 1f73d35b6..373bb5653 100644
--- a/internal/driver/driver.go
+++ b/internal/driver/driver.go
@@ -110,15 +110,6 @@ type PutURL interface {
 	PutURL(ctx context.Context, dstDir model.Obj, name, url string) error
 }
 
-//type WriteResult interface {
-//	MkdirResult
-//	MoveResult
-//	RenameResult
-//	CopyResult
-//	PutResult
-//	Remove
-//}
-
 type MkdirResult interface {
 	MakeDir(ctx context.Context, parentDir model.Obj, dirName string) (model.Obj, error)
 }
diff --git a/internal/fs/archive.go b/internal/fs/archive.go
index 9ab8243d1..784ba587a 100644
--- a/internal/fs/archive.go
+++ b/internal/fs/archive.go
@@ -38,9 +38,6 @@ func (t *ArchiveDownloadTask) GetName() string {
 }
 
 func (t *ArchiveDownloadTask) Run() error {
-	if err := t.ReinitCtx(); err != nil {
-		return err
-	}
 	if t.SrcStorage == nil {
 		if srcStorage, _, err := op.GetStorageAndActualPath(t.SrcStorageMp); err == nil {
 			t.SrcStorage = srcStorage
@@ -155,24 +152,22 @@ func (t *ArchiveContentUploadTask) GetStatus() string {
 }
 
 func (t *ArchiveContentUploadTask) Run() error {
-	if err := t.ReinitCtx(); err != nil {
-		return err
-	}
 	t.ClearEndTime()
 	t.SetStartTime(time.Now())
 	defer func() { t.SetEndTime(time.Now()) }()
 	return t.RunWithNextTaskCallback(func(nextTsk *ArchiveContentUploadTask) error {
+		task_group.TransferCoordinator.AddTask(t.groupID, nil)
 		ArchiveContentUploadTaskManager.Add(nextTsk)
 		return nil
 	})
 }
 
 func (t *ArchiveContentUploadTask) OnSucceeded() {
-	task_group.TransferCoordinator.Done(t.groupID, true)
+	task_group.TransferCoordinator.Done(context.WithoutCancel(t.Ctx()), t.groupID, true)
 }
 
 func (t *ArchiveContentUploadTask) OnFailed() {
-	task_group.TransferCoordinator.Done(t.groupID, false)
+	task_group.TransferCoordinator.Done(context.WithoutCancel(t.Ctx()), t.groupID, false)
 }
 
 func (t *ArchiveContentUploadTask) SetRetry(retry int, maxRetry int) {
@@ -204,8 +199,8 @@ func (t *ArchiveContentUploadTask) RunWithNextTaskCallback(f func(nextTask *Arch
 		if err != nil {
 			return err
 		}
-		if !t.InPlace && len(t.groupID) > 0 {
-			task_group.TransferCoordinator.AppendPayload(t.groupID, task_group.DstPathToRefresh(nextDstActualPath))
+		if !t.InPlace {
+			task_group.TransferCoordinator.AppendPayload(t.groupID, task_group.DstPathToHook(nextDstActualPath))
 		}
 		var es error
 		for _, entry := range entries {
@@ -219,9 +214,6 @@ func (t *ArchiveContentUploadTask) RunWithNextTaskCallback(f func(nextTask *Arch
 				es = stderrors.Join(es, err)
 				continue
 			}
-			if len(t.groupID) > 0 {
-				task_group.TransferCoordinator.AddTask(t.groupID, nil)
-			}
 			err = f(&ArchiveContentUploadTask{
 				TaskExtension: task.TaskExtension{
 					Creator: t.Creator,
@@ -267,7 +259,7 @@ func (t *ArchiveContentUploadTask) RunWithNextTaskCallback(f func(nextTask *Arch
 		}
 		fs.Closers.Add(file)
 		t.status = "uploading"
-		err = op.Put(t.Ctx(), t.dstStorage, t.DstActualPath, fs, t.SetProgress, true)
+		err = op.Put(context.WithValue(t.Ctx(), conf.SkipHookKey, struct{}{}), t.dstStorage, t.DstActualPath, fs, t.SetProgress)
 		if err != nil {
 			return err
 		}
@@ -405,14 +397,22 @@ func archiveDecompress(ctx context.Context, srcObjPath, dstDirPath string, args
 		}
 		defer uploadTask.deleteSrcFile()
 		var callback func(t *ArchiveContentUploadTask) error
+		var hasSuccess bool
 		callback = func(t *ArchiveContentUploadTask) error {
 			t.Base.SetCtx(ctx)
 			e := t.RunWithNextTaskCallback(callback)
+			if e == nil {
+				hasSuccess = true
+			}
 			t.deleteSrcFile()
 			return e
 		}
 		uploadTask.Base.SetCtx(ctx)
-		return nil, uploadTask.RunWithNextTaskCallback(callback)
+		uploadTask.groupID = stdpath.Join(uploadTask.DstStorageMp, uploadTask.DstActualPath)
+		task_group.TransferCoordinator.AddTask(uploadTask.groupID, nil)
+		err = uploadTask.RunWithNextTaskCallback(callback)
+		task_group.TransferCoordinator.Done(context.WithoutCancel(ctx), uploadTask.groupID, hasSuccess)
+		return nil, err
 	} else {
 		tsk.Creator, _ = ctx.Value(conf.UserKey).(*model.User)
 		tsk.ApiUrl = common.GetApiUrl(ctx)
diff --git a/internal/fs/copy_move.go b/internal/fs/copy_move.go
index 57fd7bdb1..3b6d91aec 100644
--- a/internal/fs/copy_move.go
+++ b/internal/fs/copy_move.go
@@ -22,12 +22,15 @@ import (
 type taskType uint8
 
 func (t taskType) String() string {
-	if t == 0 {
+	switch t {
+	case copy:
 		return "copy"
-	} else if t == 1 {
+	case move:
 		return "move"
-	} else {
+	case merge:
 		return "merge"
+	default:
+		return "unknown"
 	}
 }
 
@@ -48,9 +51,6 @@ func (t *FileTransferTask) GetName() string {
 }
 
 func (t *FileTransferTask) Run() error {
-	if err := t.ReinitCtx(); err != nil {
-		return err
-	}
 	if t.SrcStorage == nil {
 		if srcStorage, _, err := op.GetStorageAndActualPath(t.SrcStorageMp); err == nil {
 			t.SrcStorage = srcStorage
@@ -68,7 +68,6 @@ func (t *FileTransferTask) Run() error {
 	t.SetStartTime(time.Now())
 	defer func() { t.SetEndTime(time.Now()) }()
 	return t.RunWithNextTaskCallback(func(nextTask *FileTransferTask) error {
-		nextTask.groupID = t.groupID
 		task_group.TransferCoordinator.AddTask(t.groupID, nil)
 		if t.TaskType == copy || t.TaskType == merge {
 			CopyTaskManager.Add(nextTask)
@@ -80,15 +79,15 @@ func (t *FileTransferTask) Run() error {
 }
 
 func (t *FileTransferTask) OnSucceeded() {
-	task_group.TransferCoordinator.Done(t.groupID, true)
+	task_group.TransferCoordinator.Done(context.WithoutCancel(t.Ctx()), t.groupID, true)
 }
 
 func (t *FileTransferTask) OnFailed() {
-	task_group.TransferCoordinator.Done(t.groupID, false)
+	task_group.TransferCoordinator.Done(context.WithoutCancel(t.Ctx()), t.groupID, false)
 }
 
 func (t *FileTransferTask) SetRetry(retry int, maxRetry int) {
-	t.TaskExtension.SetRetry(retry, maxRetry)
+	t.TaskData.SetRetry(retry, maxRetry)
 	if retry == 0 &&
 		(len(t.groupID) == 0 || // é‡å¯æ¢å¤
 			(t.GetErr() == nil && t.GetState() != tache.StatePending)) { // æ‰‹åŠ¨é‡è¯•
@@ -101,7 +100,7 @@ func (t *FileTransferTask) SetRetry(retry int, maxRetry int) {
 	}
 }
 
-func transfer(ctx context.Context, taskType taskType, srcObjPath, dstDirPath string, lazyCache ...bool) (task.TaskExtensionInfo, error) {
+func transfer(ctx context.Context, taskType taskType, srcObjPath, dstDirPath string, skipHook ...bool) (task.TaskExtensionInfo, error) {
 	srcStorage, srcObjActualPath, err := op.GetStorageAndActualPath(srcObjPath)
 	if err != nil {
 		return nil, errors.WithMessage(err, "failed get src storage")
@@ -112,13 +111,16 @@ func transfer(ctx context.Context, taskType taskType, srcObjPath, dstDirPath str
 	}
 
 	if srcStorage.GetStorage() == dstStorage.GetStorage() {
+		if utils.IsBool(skipHook...) {
+			ctx = context.WithValue(ctx, conf.SkipHookKey, struct{}{})
+		}
 		if taskType == copy || taskType == merge {
-			err = op.Copy(ctx, srcStorage, srcObjActualPath, dstDirActualPath, lazyCache...)
+			err = op.Copy(ctx, srcStorage, srcObjActualPath, dstDirActualPath)
 			if !errors.Is(err, errs.NotImplement) && !errors.Is(err, errs.NotSupport) {
 				return nil, err
 			}
 		} else {
-			err = op.Move(ctx, srcStorage, srcObjActualPath, dstDirActualPath, lazyCache...)
+			err = op.Move(ctx, srcStorage, srcObjActualPath, dstDirActualPath)
 			if !errors.Is(err, errs.NotImplement) && !errors.Is(err, errs.NotSupport) {
 				return nil, err
 			}
@@ -138,6 +140,8 @@ func transfer(ctx context.Context, taskType taskType, srcObjPath, dstDirPath str
 		TaskType: taskType,
 	}
 
+	t.groupID = stdpath.Join(t.DstStorageMp, t.DstActualPath)
+	task_group.TransferCoordinator.AddTask(t.groupID, nil)
 	if ctx.Value(conf.NoTaskKey) != nil {
 		var callback func(nextTask *FileTransferTask) error
 		hasSuccess := false
@@ -151,24 +155,19 @@ func transfer(ctx context.Context, taskType taskType, srcObjPath, dstDirPath str
 		}
 		t.Base.SetCtx(ctx)
 		err = t.RunWithNextTaskCallback(callback)
-		if hasSuccess || err == nil {
-			if taskType == move {
-				task_group.RefreshAndRemove(dstDirPath, task_group.SrcPathToRemove(srcObjPath))
-			} else {
-				op.Cache.DeleteDirectory(t.DstStorage, dstDirActualPath)
-			}
+		if taskType == move {
+			task_group.TransferCoordinator.AppendPayload(t.groupID, task_group.SrcPathToRemove(srcObjPath))
 		}
+		task_group.TransferCoordinator.Done(context.WithoutCancel(ctx), t.groupID, hasSuccess)
 		return nil, err
 	}
 
 	t.Creator, _ = ctx.Value(conf.UserKey).(*model.User)
 	t.ApiUrl = common.GetApiUrl(ctx)
-	t.groupID = dstDirPath
 	if taskType == copy || taskType == merge {
-		task_group.TransferCoordinator.AddTask(dstDirPath, nil)
 		CopyTaskManager.Add(t)
 	} else {
-		task_group.TransferCoordinator.AddTask(dstDirPath, task_group.SrcPathToRemove(srcObjPath))
+		task_group.TransferCoordinator.AppendPayload(t.groupID, task_group.SrcPathToRemove(srcObjPath))
 		MoveTaskManager.Add(t)
 	}
 	return t, nil
@@ -188,18 +187,18 @@ func (t *FileTransferTask) RunWithNextTaskCallback(f func(nextTask *FileTransfer
 			return errors.WithMessagef(err, "failed list src [%s] objs", t.SrcActualPath)
 		}
 		dstActualPath := stdpath.Join(t.DstActualPath, srcObj.GetName())
-		if t.TaskType == copy || t.TaskType == merge {
-			if t.Ctx().Value(conf.NoTaskKey) != nil {
-				defer op.Cache.DeleteDirectory(t.DstStorage, dstActualPath)
-			} else {
-				task_group.TransferCoordinator.AppendPayload(t.groupID, task_group.DstPathToRefresh(dstActualPath))
-			}
-		}
+		task_group.TransferCoordinator.AppendPayload(t.groupID, task_group.DstPathToHook(dstActualPath))
 
 		existedObjs := make(map[string]bool)
 		if t.TaskType == merge {
-			dstObjs, _ := op.List(t.Ctx(), t.DstStorage, dstActualPath, model.ListArgs{})
+			dstObjs, err := op.List(t.Ctx(), t.DstStorage, dstActualPath, model.ListArgs{})
+			if err != nil {
+				return errors.WithMessagef(err, "failed list dst [%s] objs", dstActualPath)
+			}
 			for _, obj := range dstObjs {
+				if err := t.Ctx().Err(); err != nil {
+					return err
+				}
 				if !obj.IsDir() {
 					existedObjs[obj.GetName()] = true
 				}
@@ -207,8 +206,8 @@ func (t *FileTransferTask) RunWithNextTaskCallback(f func(nextTask *FileTransfer
 		}
 
 		for _, obj := range objs {
-			if utils.IsCanceled(t.Ctx()) {
-				return nil
+			if err := t.Ctx().Err(); err != nil {
+				return err
 			}
 
 			if t.TaskType == merge && !obj.IsDir() && existedObjs[obj.GetName()] {
@@ -230,6 +229,7 @@ func (t *FileTransferTask) RunWithNextTaskCallback(f func(nextTask *FileTransfer
 					SrcStorageMp:  t.SrcStorageMp,
 					DstStorageMp:  t.DstStorageMp,
 				},
+				groupID: t.groupID,
 			})
 			if err != nil {
 				return err
@@ -239,7 +239,8 @@ func (t *FileTransferTask) RunWithNextTaskCallback(f func(nextTask *FileTransfer
 		return nil
 	}
 
-	link, _, err := op.Link(t.Ctx(), t.SrcStorage, t.SrcActualPath, model.LinkArgs{})
+	t.Status = "getting src object link"
+	link, srcObj, err := op.Link(t.Ctx(), t.SrcStorage, t.SrcActualPath, model.LinkArgs{})
 	if err != nil {
 		return errors.WithMessagef(err, "failed get [%s] link", t.SrcActualPath)
 	}
@@ -254,7 +255,7 @@ func (t *FileTransferTask) RunWithNextTaskCallback(f func(nextTask *FileTransfer
 	}
 	t.SetTotalBytes(ss.GetSize())
 	t.Status = "uploading"
-	return op.Put(t.Ctx(), t.DstStorage, t.DstActualPath, ss, t.SetProgress, true)
+	return op.Put(context.WithValue(t.Ctx(), conf.SkipHookKey, struct{}{}), t.DstStorage, t.DstActualPath, ss, t.SetProgress)
 }
 
 var (
diff --git a/internal/fs/fs.go b/internal/fs/fs.go
index 85b7f5403..3d459c6be 100644
--- a/internal/fs/fs.go
+++ b/internal/fs/fs.go
@@ -60,40 +60,40 @@ func Link(ctx context.Context, path string, args model.LinkArgs) (*model.Link, m
 	return res, file, nil
 }
 
-func MakeDir(ctx context.Context, path string, lazyCache ...bool) error {
-	err := makeDir(ctx, path, lazyCache...)
+func MakeDir(ctx context.Context, path string) error {
+	err := makeDir(ctx, path)
 	if err != nil {
 		log.Errorf("failed make dir %s: %+v", path, err)
 	}
 	return err
 }
 
-func Move(ctx context.Context, srcPath, dstDirPath string, lazyCache ...bool) (task.TaskExtensionInfo, error) {
-	req, err := transfer(ctx, move, srcPath, dstDirPath, lazyCache...)
+func Move(ctx context.Context, srcPath, dstDirPath string, skipHook ...bool) (task.TaskExtensionInfo, error) {
+	req, err := transfer(ctx, move, srcPath, dstDirPath, skipHook...)
 	if err != nil {
 		log.Errorf("failed move %s to %s: %+v", srcPath, dstDirPath, err)
 	}
 	return req, err
 }
 
-func Copy(ctx context.Context, srcObjPath, dstDirPath string, lazyCache ...bool) (task.TaskExtensionInfo, error) {
-	res, err := transfer(ctx, copy, srcObjPath, dstDirPath, lazyCache...)
+func Copy(ctx context.Context, srcObjPath, dstDirPath string, skipHook ...bool) (task.TaskExtensionInfo, error) {
+	res, err := transfer(ctx, copy, srcObjPath, dstDirPath, skipHook...)
 	if err != nil {
 		log.Errorf("failed copy %s to %s: %+v", srcObjPath, dstDirPath, err)
 	}
 	return res, err
 }
 
-func Merge(ctx context.Context, srcObjPath, dstDirPath string, lazyCache ...bool) (task.TaskExtensionInfo, error) {
-	res, err := transfer(ctx, merge, srcObjPath, dstDirPath, lazyCache...)
+func Merge(ctx context.Context, srcObjPath, dstDirPath string, skipHook ...bool) (task.TaskExtensionInfo, error) {
+	res, err := transfer(ctx, merge, srcObjPath, dstDirPath, skipHook...)
 	if err != nil {
 		log.Errorf("failed merge %s to %s: %+v", srcObjPath, dstDirPath, err)
 	}
 	return res, err
 }
 
-func Rename(ctx context.Context, srcPath, dstName string, lazyCache ...bool) error {
-	err := rename(ctx, srcPath, dstName, lazyCache...)
+func Rename(ctx context.Context, srcPath, dstName string, skipHook ...bool) error {
+	err := rename(ctx, srcPath, dstName, skipHook...)
 	if err != nil {
 		log.Errorf("failed rename %s to %s: %+v", srcPath, dstName, err)
 	}
@@ -108,8 +108,8 @@ func Remove(ctx context.Context, path string) error {
 	return err
 }
 
-func PutDirectly(ctx context.Context, dstDirPath string, file model.FileStreamer, lazyCache ...bool) error {
-	err := putDirectly(ctx, dstDirPath, file, lazyCache...)
+func PutDirectly(ctx context.Context, dstDirPath string, file model.FileStreamer, skipHook ...bool) error {
+	err := putDirectly(ctx, dstDirPath, file, skipHook...)
 	if err != nil {
 		log.Errorf("failed put %s: %+v", dstDirPath, err)
 	}
@@ -175,14 +175,6 @@ func GetStorage(path string, args *GetStoragesArgs) (driver.Driver, error) {
 	return storageDriver, nil
 }
 
-func GetStorageAndActualPath(path string) (driver.Driver, string, error) {
-	return op.GetStorageAndActualPath(path)
-}
-
-func GetByActualPath(ctx context.Context, storage driver.Driver, actualPath string) (model.Obj, error) {
-	return op.Get(ctx, storage, actualPath)
-}
-
 func Other(ctx context.Context, args model.FsOtherArgs) (interface{}, error) {
 	res, err := other(ctx, args)
 	if err != nil {
diff --git a/internal/fs/get.go b/internal/fs/get.go
index 459282ce3..8a920065e 100644
--- a/internal/fs/get.go
+++ b/internal/fs/get.go
@@ -3,7 +3,6 @@ package fs
 import (
 	"context"
 	stdpath "path"
-	"time"
 
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
 	"github.com/OpenListTeam/OpenList/v4/internal/op"
@@ -15,9 +14,10 @@ func get(ctx context.Context, path string, args *GetArgs) (model.Obj, error) {
 	path = utils.FixAndCleanPath(path)
 	// maybe a virtual file
 	if path != "/" {
-		virtualFiles := op.GetStorageVirtualFilesWithDetailsByPath(ctx, stdpath.Dir(path), !args.WithStorageDetails, false)
+		dir, name := stdpath.Split(path)
+		virtualFiles := op.GetStorageVirtualFilesWithDetailsByPath(ctx, dir, !args.WithStorageDetails, false, name)
 		for _, f := range virtualFiles {
-			if f.GetName() == stdpath.Base(path) {
+			if f.GetName() == name {
 				return f, nil
 			}
 		}
@@ -28,9 +28,8 @@ func get(ctx context.Context, path string, args *GetArgs) (model.Obj, error) {
 		if path == "/" {
 			return &model.Object{
 				Name:     "root",
-				Size:     0,
-				Modified: time.Time{},
 				IsFolder: true,
+				Mask:     model.ReadOnly | model.Virtual,
 			}, nil
 		}
 		return nil, errors.WithMessage(err, "failed get storage")
diff --git a/internal/fs/list.go b/internal/fs/list.go
index fc3b25ab5..1f92c7d46 100644
--- a/internal/fs/list.go
+++ b/internal/fs/list.go
@@ -15,7 +15,7 @@ import (
 func list(ctx context.Context, path string, args *ListArgs) ([]model.Obj, error) {
 	meta, _ := ctx.Value(conf.MetaKey).(*model.Meta)
 	user, _ := ctx.Value(conf.UserKey).(*model.User)
-	virtualFiles := op.GetStorageVirtualFilesWithDetailsByPath(ctx, path, !args.WithStorageDetails, args.Refresh)
+	virtualFiles := op.GetStorageVirtualFilesWithDetailsByPath(ctx, path, !args.WithStorageDetails, args.Refresh, "")
 	storage, actualPath, err := op.GetStorageAndActualPath(path)
 	if err != nil && len(virtualFiles) == 0 {
 		return nil, errors.WithMessage(err, "failed get storage")
diff --git a/internal/fs/other.go b/internal/fs/other.go
index 8d16b0003..a23beb73b 100644
--- a/internal/fs/other.go
+++ b/internal/fs/other.go
@@ -3,27 +3,32 @@ package fs
 import (
 	"context"
 
+	"github.com/OpenListTeam/OpenList/v4/internal/conf"
 	"github.com/OpenListTeam/OpenList/v4/internal/driver"
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
 	"github.com/OpenListTeam/OpenList/v4/internal/op"
 	"github.com/OpenListTeam/OpenList/v4/internal/task"
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
 	"github.com/pkg/errors"
 )
 
-func makeDir(ctx context.Context, path string, lazyCache ...bool) error {
+func makeDir(ctx context.Context, path string) error {
 	storage, actualPath, err := op.GetStorageAndActualPath(path)
 	if err != nil {
 		return errors.WithMessage(err, "failed get storage")
 	}
-	return op.MakeDir(ctx, storage, actualPath, lazyCache...)
+	return op.MakeDir(ctx, storage, actualPath)
 }
 
-func rename(ctx context.Context, srcPath, dstName string, lazyCache ...bool) error {
+func rename(ctx context.Context, srcPath, dstName string, skipHook ...bool) error {
 	storage, srcActualPath, err := op.GetStorageAndActualPath(srcPath)
 	if err != nil {
 		return errors.WithMessage(err, "failed get storage")
 	}
-	return op.Rename(ctx, storage, srcActualPath, dstName, lazyCache...)
+	if utils.IsBool(skipHook...) {
+		ctx = context.WithValue(ctx, conf.SkipHookKey, struct{}{})
+	}
+	return op.Rename(ctx, storage, srcActualPath, dstName)
 }
 
 func remove(ctx context.Context, path string) error {
diff --git a/internal/fs/put.go b/internal/fs/put.go
index b4806efef..be829ae47 100644
--- a/internal/fs/put.go
+++ b/internal/fs/put.go
@@ -6,6 +6,7 @@ import (
 	stdpath "path"
 	"time"
 
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
 	"github.com/OpenListTeam/OpenList/v4/server/common"
 
 	"github.com/OpenListTeam/OpenList/v4/internal/conf"
@@ -38,15 +39,15 @@ func (t *UploadTask) Run() error {
 	t.ClearEndTime()
 	t.SetStartTime(time.Now())
 	defer func() { t.SetEndTime(time.Now()) }()
-	return op.Put(t.Ctx(), t.storage, t.dstDirActualPath, t.file, t.SetProgress, true)
+	return op.Put(context.WithValue(t.Ctx(), conf.SkipHookKey, struct{}{}), t.storage, t.dstDirActualPath, t.file, t.SetProgress)
 }
 
 func (t *UploadTask) OnSucceeded() {
-	task_group.TransferCoordinator.Done(stdpath.Join(t.storage.GetStorage().MountPath, t.dstDirActualPath), true)
+	task_group.TransferCoordinator.Done(context.WithoutCancel(t.Ctx()), stdpath.Join(t.storage.GetStorage().MountPath, t.dstDirActualPath), true)
 }
 
 func (t *UploadTask) OnFailed() {
-	task_group.TransferCoordinator.Done(stdpath.Join(t.storage.GetStorage().MountPath, t.dstDirActualPath), false)
+	task_group.TransferCoordinator.Done(context.WithoutCancel(t.Ctx()), stdpath.Join(t.storage.GetStorage().MountPath, t.dstDirActualPath), false)
 }
 
 func (t *UploadTask) SetRetry(retry int, maxRetry int) {
@@ -87,13 +88,13 @@ func putAsTask(ctx context.Context, dstDirPath string, file model.FileStreamer)
 		file:             file,
 	}
 	t.SetTotalBytes(file.GetSize())
-	task_group.TransferCoordinator.AddTask(dstDirPath, nil)
+	task_group.TransferCoordinator.AddTask(stdpath.Join(storage.GetStorage().MountPath, dstDirActualPath), nil)
 	UploadTaskManager.Add(t)
 	return t, nil
 }
 
 // putDirect put the file and return after finish
-func putDirectly(ctx context.Context, dstDirPath string, file model.FileStreamer, lazyCache ...bool) error {
+func putDirectly(ctx context.Context, dstDirPath string, file model.FileStreamer, skipHook ...bool) error {
 	storage, dstDirActualPath, err := op.GetStorageAndActualPath(dstDirPath)
 	if err != nil {
 		_ = file.Close()
@@ -103,7 +104,10 @@ func putDirectly(ctx context.Context, dstDirPath string, file model.FileStreamer
 		_ = file.Close()
 		return errors.WithStack(errs.UploadNotSupported)
 	}
-	return op.Put(ctx, storage, dstDirActualPath, file, nil, lazyCache...)
+	if utils.IsBool(skipHook...) {
+		ctx = context.WithValue(ctx, conf.SkipHookKey, struct{}{})
+	}
+	return op.Put(ctx, storage, dstDirActualPath, file, nil)
 }
 
 func getDirectUploadInfo(ctx context.Context, tool, dstDirPath, dstName string, fileSize int64) (any, error) {
diff --git a/internal/model/args.go b/internal/model/args.go
index b23708783..073c94a63 100644
--- a/internal/model/args.go
+++ b/internal/model/args.go
@@ -15,6 +15,7 @@ type ListArgs struct {
 	S3ShowPlaceholder  bool
 	Refresh            bool
 	WithStorageDetails bool
+	SkipHook           bool
 }
 
 type LinkArgs struct {
diff --git a/internal/model/obj.go b/internal/model/obj.go
index aa5ab75b3..ba7467f74 100644
--- a/internal/model/obj.go
+++ b/internal/model/obj.go
@@ -137,62 +137,55 @@ func WrapObjName(objs Obj) Obj {
 }
 
 func WrapObjsName(objs []Obj) {
-	for i := 0; i < len(objs); i++ {
+	for i := range objs {
 		objs[i] = &ObjWrapName{Name: utils.MappingName(objs[i].GetName()), Obj: objs[i]}
 	}
 }
 
-func UnwrapObj(obj Obj) Obj {
-	if unwrap, ok := obj.(ObjUnwrap); ok {
-		obj = unwrap.Unwrap()
+func UnwrapObjName(obj Obj) Obj {
+	if n, ok := obj.(*ObjWrapName); ok {
+		return n.Obj
 	}
 	return obj
 }
 
 func GetThumb(obj Obj) (thumb string, ok bool) {
-	if obj, ok := obj.(Thumb); ok {
-		return obj.Thumb(), true
-	}
-	if unwrap, ok := obj.(ObjUnwrap); ok {
-		return GetThumb(unwrap.Unwrap())
+	for {
+		switch o := obj.(type) {
+		case Thumb:
+			return o.Thumb(), true
+		case ObjUnwrap:
+			obj = o.Unwrap()
+		default:
+			return
+		}
 	}
-	return thumb, false
 }
 
 func GetUrl(obj Obj) (url string, ok bool) {
-	if obj, ok := obj.(URL); ok {
-		return obj.URL(), true
-	}
-	if unwrap, ok := obj.(ObjUnwrap); ok {
-		return GetUrl(unwrap.Unwrap())
+	for {
+		switch o := obj.(type) {
+		case URL:
+			return o.URL(), true
+		case ObjUnwrap:
+			obj = o.Unwrap()
+		default:
+			return
+		}
 	}
-	return url, false
 }
 
 func GetProvider(obj Obj) (string, bool) {
-	if obj, ok := obj.(ObjWithProvider); ok {
-		return obj.GetProvider(), true
-	}
-	if unwrap, ok := obj.(ObjUnwrap); ok {
-		return GetProvider(unwrap.Unwrap())
-	}
-	return "unknown", false
-}
-
-func GetRawObject(obj Obj) *Object {
-	switch v := obj.(type) {
-	case *ObjThumbURL:
-		return &v.Object
-	case *ObjThumb:
-		return &v.Object
-	case *ObjectURL:
-		return &v.Object
-	case *ObjectProvider:
-		return &v.Object
-	case *Object:
-		return v
+	for {
+		switch o := obj.(type) {
+		case ObjWithProvider:
+			return o.GetProvider(), true
+		case ObjUnwrap:
+			obj = o.Unwrap()
+		default:
+			return "unknown", false
+		}
 	}
-	return nil
 }
 
 // Merge
@@ -242,3 +235,52 @@ func (om *ObjMerge) InitHideReg(hides string) {
 func (om *ObjMerge) Reset() {
 	om.set.Clear()
 }
+
+type ObjMask uint8
+
+func (m ObjMask) GetObjMask() ObjMask {
+	return m
+}
+
+const (
+	Virtual ObjMask = 1 << iota
+	NoRename
+	NoRemove
+	NoMove
+	NoCopy
+	NoWrite
+	Temp
+)
+const (
+	Locked   = NoRename | NoRemove | NoMove
+	ReadOnly = Locked | NoWrite // NoRename | NoDelete | NoMove | NoWrite
+)
+
+type ObjWrapMask struct {
+	Obj
+	Mask ObjMask
+}
+
+func (m *ObjWrapMask) Unwrap() Obj {
+	return m.Obj
+}
+func (m *ObjWrapMask) GetObjMask() ObjMask {
+	return m.Mask
+}
+
+func GetObjMask(obj Obj) ObjMask {
+	for {
+		switch o := obj.(type) {
+		case interface{ GetObjMask() ObjMask }:
+			return o.GetObjMask()
+		case ObjUnwrap:
+			obj = o.Unwrap()
+		default:
+			return 0
+		}
+	}
+}
+
+func ObjHasMask(obj Obj, mask ObjMask) bool {
+	return GetObjMask(obj)&mask != 0
+}
diff --git a/internal/model/object.go b/internal/model/object.go
index 8e5cdf047..b6cb0d7f7 100644
--- a/internal/model/object.go
+++ b/internal/model/object.go
@@ -28,6 +28,7 @@ type Object struct {
 	Ctime    time.Time // file create time
 	IsFolder bool
 	HashInfo utils.HashInfo
+	Mask     ObjMask
 }
 
 func (o *Object) GetName() string {
@@ -68,6 +69,10 @@ func (o *Object) GetHash() utils.HashInfo {
 	return o.HashInfo
 }
 
+func (o *Object) GetObjMask() ObjMask {
+	return o.Mask
+}
+
 type Thumbnail struct {
 	Thumbnail string
 }
diff --git a/internal/model/storage.go b/internal/model/storage.go
index 863464cb3..df8dbe953 100644
--- a/internal/model/storage.go
+++ b/internal/model/storage.go
@@ -5,18 +5,19 @@ import (
 )
 
 type Storage struct {
-	ID              uint      `json:"id" gorm:"primaryKey"`                        // unique key
-	MountPath       string    `json:"mount_path" gorm:"unique" binding:"required"` // must be standardized
-	Order           int       `json:"order"`                                       // use to sort
-	Driver          string    `json:"driver"`                                      // driver used
-	CacheExpiration int       `json:"cache_expiration"`                            // cache expire time
-	Status          string    `json:"status"`
-	Addition        string    `json:"addition" gorm:"type:text"` // Additional information, defined in the corresponding driver
-	Remark          string    `json:"remark"`
-	Modified        time.Time `json:"modified"`
-	Disabled        bool      `json:"disabled"` // if disabled
-	DisableIndex    bool      `json:"disable_index"`
-	EnableSign      bool      `json:"enable_sign"`
+	ID                  uint      `json:"id" gorm:"primaryKey"`                        // unique key
+	MountPath           string    `json:"mount_path" gorm:"unique" binding:"required"` // must be standardized
+	Order               int       `json:"order"`                                       // use to sort
+	Driver              string    `json:"driver"`                                      // driver used
+	CacheExpiration     int       `json:"cache_expiration"`                            // cache expire time
+	CustomCachePolicies string    `json:"custom_cache_policies" gorm:"type:text"`
+	Status              string    `json:"status"`
+	Addition            string    `json:"addition" gorm:"type:text"` // Additional information, defined in the corresponding driver
+	Remark              string    `json:"remark"`
+	Modified            time.Time `json:"modified"`
+	Disabled            bool      `json:"disabled"` // if disabled
+	DisableIndex        bool      `json:"disable_index"`
+	EnableSign          bool      `json:"enable_sign"`
 	Sort
 	Proxy
 }
@@ -79,6 +80,10 @@ type ObjStorageDetails struct {
 	StorageDetailsWithName
 }
 
+func (o *ObjStorageDetails) Unwrap() Obj {
+	return o.Obj
+}
+
 func (o ObjStorageDetails) GetStorageDetails() *StorageDetailsWithName {
 	return &o.StorageDetailsWithName
 }
diff --git a/internal/model/user.go b/internal/model/user.go
index ae2d7d58c..640e3b2e3 100644
--- a/internal/model/user.go
+++ b/internal/model/user.go
@@ -59,6 +59,7 @@ type User struct {
 	OtpSecret  string `json:"-"`
 	SsoID      string `json:"sso_id"` // unique by sso platform
 	Authn      string `gorm:"type:text" json:"-"`
+	AllowLdap  bool   `json:"allow_ldap" gorm:"default:true"`
 }
 
 func (u *User) IsGuest() bool {
@@ -90,64 +91,124 @@ func (u *User) SetPassword(pwd string) *User {
 	return u
 }
 
+func CanSeeHides(permission int32) bool {
+	return permission&1 == 1
+}
+
 func (u *User) CanSeeHides() bool {
-	return u.Permission&1 == 1
+	return CanSeeHides(u.Permission)
+}
+
+func CanAccessWithoutPassword(permission int32) bool {
+	return (permission>>1)&1 == 1
 }
 
 func (u *User) CanAccessWithoutPassword() bool {
-	return (u.Permission>>1)&1 == 1
+	return CanAccessWithoutPassword(u.Permission)
+}
+
+func CanAddOfflineDownloadTasks(permission int32) bool {
+	return (permission>>2)&1 == 1
 }
 
 func (u *User) CanAddOfflineDownloadTasks() bool {
-	return (u.Permission>>2)&1 == 1
+	return CanAddOfflineDownloadTasks(u.Permission)
+}
+
+func CanWrite(permission int32) bool {
+	return (permission>>3)&1 == 1
 }
 
 func (u *User) CanWrite() bool {
-	return (u.Permission>>3)&1 == 1
+	return CanWrite(u.Permission)
+}
+
+func CanRename(permission int32) bool {
+	return (permission>>4)&1 == 1
 }
 
 func (u *User) CanRename() bool {
-	return (u.Permission>>4)&1 == 1
+	return CanRename(u.Permission)
+}
+
+func CanMove(permission int32) bool {
+	return (permission>>5)&1 == 1
 }
 
 func (u *User) CanMove() bool {
-	return (u.Permission>>5)&1 == 1
+	return CanMove(u.Permission)
+}
+
+func CanCopy(permission int32) bool {
+	return (permission>>6)&1 == 1
 }
 
 func (u *User) CanCopy() bool {
-	return (u.Permission>>6)&1 == 1
+	return CanCopy(u.Permission)
+}
+
+func CanRemove(permission int32) bool {
+	return (permission>>7)&1 == 1
 }
 
 func (u *User) CanRemove() bool {
-	return (u.Permission>>7)&1 == 1
+	return CanRemove(u.Permission)
+}
+
+func CanWebdavRead(permission int32) bool {
+	return (permission>>8)&1 == 1
 }
 
 func (u *User) CanWebdavRead() bool {
-	return (u.Permission>>8)&1 == 1
+	return CanWebdavRead(u.Permission)
+}
+
+func CanWebdavManage(permission int32) bool {
+	return (permission>>9)&1 == 1
 }
 
 func (u *User) CanWebdavManage() bool {
-	return (u.Permission>>9)&1 == 1
+	return CanWebdavManage(u.Permission)
+}
+
+func CanFTPAccess(permission int32) bool {
+	return (permission>>10)&1 == 1
 }
 
 func (u *User) CanFTPAccess() bool {
-	return (u.Permission>>10)&1 == 1
+	return CanFTPAccess(u.Permission)
+}
+
+func CanFTPManage(permission int32) bool {
+	return (permission>>11)&1 == 1
 }
 
 func (u *User) CanFTPManage() bool {
-	return (u.Permission>>11)&1 == 1
+	return CanFTPManage(u.Permission)
+}
+
+func CanReadArchives(permission int32) bool {
+	return (permission>>12)&1 == 1
 }
 
 func (u *User) CanReadArchives() bool {
-	return (u.Permission>>12)&1 == 1
+	return CanReadArchives(u.Permission)
+}
+
+func CanDecompress(permission int32) bool {
+	return (permission>>13)&1 == 1
 }
 
 func (u *User) CanDecompress() bool {
-	return (u.Permission>>13)&1 == 1
+	return CanDecompress(u.Permission)
+}
+
+func CanShare(permission int32) bool {
+	return (permission>>14)&1 == 1
 }
 
 func (u *User) CanShare() bool {
-	return (u.Permission>>14)&1 == 1
+	return CanShare(u.Permission)
 }
 
 func (u *User) JoinPath(reqPath string) (string, error) {
diff --git a/internal/offline_download/tool/download.go b/internal/offline_download/tool/download.go
index f6c530817..778d147c0 100644
--- a/internal/offline_download/tool/download.go
+++ b/internal/offline_download/tool/download.go
@@ -2,6 +2,7 @@ package tool
 
 import (
 	"fmt"
+	"path"
 	"time"
 
 	"github.com/OpenListTeam/OpenList/v4/internal/conf"
@@ -32,9 +33,6 @@ type DownloadTask struct {
 }
 
 func (t *DownloadTask) Run() error {
-	if err := t.ReinitCtx(); err != nil {
-		return err
-	}
 	t.ClearEndTime()
 	t.SetStartTime(time.Now())
 	defer func() { t.SetEndTime(time.Now()) }()
@@ -201,11 +199,11 @@ func (t *DownloadTask) Transfer() error {
 				DstStorage:    dstStorage,
 				DstStorageMp:  dstStorage.GetStorage().MountPath,
 			},
-			groupID:      t.DstDirPath,
 			DeletePolicy: t.DeletePolicy,
 			Url:          t.Url,
 		}
 		tsk.SetTotalBytes(t.GetTotalBytes())
+		tsk.groupID = path.Join(tsk.DstStorageMp, tsk.DstActualPath)
 		task_group.TransferCoordinator.AddTask(tsk.groupID, nil)
 		TransferTaskManager.Add(tsk)
 		return nil
diff --git a/internal/offline_download/tool/transfer.go b/internal/offline_download/tool/transfer.go
index 7daf0b171..fd6b8f464 100644
--- a/internal/offline_download/tool/transfer.go
+++ b/internal/offline_download/tool/transfer.go
@@ -4,6 +4,7 @@ import (
 	"context"
 	"fmt"
 	"os"
+	"path"
 	stdpath "path"
 	"path/filepath"
 	"time"
@@ -31,9 +32,6 @@ type TransferTask struct {
 }
 
 func (t *TransferTask) Run() error {
-	if err := t.ReinitCtx(); err != nil {
-		return err
-	}
 	if t.SrcStorage == nil && t.SrcStorageMp != "" {
 		if srcStorage, _, err := op.GetStorageAndActualPath(t.SrcStorageMp); err == nil {
 			t.SrcStorage = srcStorage
@@ -75,7 +73,7 @@ func (t *TransferTask) Run() error {
 				Mimetype: mimetype,
 				Closers:  utils.NewClosers(r),
 			}
-			return op.Put(t.Ctx(), t.DstStorage, t.DstActualPath, s, t.SetProgress)
+			return op.Put(context.WithValue(t.Ctx(), conf.SkipHookKey, struct{}{}), t.DstStorage, t.DstActualPath, s, t.SetProgress)
 		}
 		return transferStdPath(t)
 	}
@@ -97,7 +95,7 @@ func (t *TransferTask) OnSucceeded() {
 			removeObjTemp(t)
 		}
 	}
-	task_group.TransferCoordinator.Done(t.groupID, true)
+	task_group.TransferCoordinator.Done(context.WithoutCancel(t.Ctx()), t.groupID, true)
 }
 
 func (t *TransferTask) OnFailed() {
@@ -108,7 +106,7 @@ func (t *TransferTask) OnFailed() {
 			removeObjTemp(t)
 		}
 	}
-	task_group.TransferCoordinator.Done(t.groupID, false)
+	task_group.TransferCoordinator.Done(context.WithoutCancel(t.Ctx()), t.groupID, false)
 }
 
 func (t *TransferTask) SetRetry(retry int, maxRetry int) {
@@ -118,7 +116,7 @@ func (t *TransferTask) SetRetry(retry int, maxRetry int) {
 		t.groupID = stdpath.Join(t.DstStorageMp, t.DstActualPath)
 		task_group.TransferCoordinator.AddTask(t.groupID, nil)
 	}
-	t.TaskExtension.SetRetry(retry, maxRetry)
+	t.TaskData.SetRetry(retry, maxRetry)
 }
 
 var (
@@ -147,10 +145,10 @@ func transferStd(ctx context.Context, tempDir, dstDirPath string, deletePolicy D
 				DstStorage:    dstStorage,
 				DstStorageMp:  dstStorage.GetStorage().MountPath,
 			},
-			groupID:      dstDirPath,
 			DeletePolicy: deletePolicy,
 		}
-		task_group.TransferCoordinator.AddTask(dstDirPath, nil)
+		t.groupID = path.Join(t.DstStorageMp, t.DstActualPath)
+		task_group.TransferCoordinator.AddTask(t.groupID, nil)
 		TransferTaskManager.Add(t)
 	}
 	return nil
@@ -169,7 +167,7 @@ func transferStdPath(t *TransferTask) error {
 			return err
 		}
 		dstDirActualPath := stdpath.Join(t.DstActualPath, info.Name())
-		task_group.TransferCoordinator.AppendPayload(t.groupID, task_group.DstPathToRefresh(dstDirActualPath))
+		task_group.TransferCoordinator.AppendPayload(t.groupID, task_group.DstPathToHook(dstDirActualPath))
 		for _, entry := range entries {
 			srcRawPath := stdpath.Join(t.SrcActualPath, entry.Name())
 			task := &TransferTask{
@@ -219,7 +217,7 @@ func transferStdFile(t *TransferTask) error {
 		Closers:  utils.NewClosers(rc),
 	}
 	t.SetTotalBytes(info.Size())
-	return op.Put(t.Ctx(), t.DstStorage, t.DstActualPath, s, t.SetProgress)
+	return op.Put(context.WithValue(t.Ctx(), conf.SkipHookKey, struct{}{}), t.DstStorage, t.DstActualPath, s, t.SetProgress)
 }
 
 func removeStdTemp(t *TransferTask) {
@@ -260,10 +258,10 @@ func transferObj(ctx context.Context, tempDir, dstDirPath string, deletePolicy D
 				SrcStorageMp:  srcStorage.GetStorage().MountPath,
 				DstStorageMp:  dstStorage.GetStorage().MountPath,
 			},
-			groupID:      dstDirPath,
 			DeletePolicy: deletePolicy,
 		}
-		task_group.TransferCoordinator.AddTask(dstDirPath, nil)
+		t.groupID = path.Join(t.DstStorageMp, t.DstActualPath)
+		task_group.TransferCoordinator.AddTask(t.groupID, nil)
 		TransferTaskManager.Add(t)
 	}
 	return nil
@@ -282,7 +280,7 @@ func transferObjPath(t *TransferTask) error {
 			return errors.WithMessagef(err, "failed list src [%s] objs", t.SrcActualPath)
 		}
 		dstDirActualPath := stdpath.Join(t.DstActualPath, srcObj.GetName())
-		task_group.TransferCoordinator.AppendPayload(t.groupID, task_group.DstPathToRefresh(dstDirActualPath))
+		task_group.TransferCoordinator.AppendPayload(t.groupID, task_group.DstPathToHook(dstDirActualPath))
 		for _, obj := range objs {
 			if utils.IsCanceled(t.Ctx()) {
 				return nil
@@ -313,11 +311,11 @@ func transferObjPath(t *TransferTask) error {
 }
 
 func transferObjFile(t *TransferTask) error {
-	srcFile, err := op.Get(t.Ctx(), t.SrcStorage, t.SrcActualPath)
+	_, err := op.Get(t.Ctx(), t.SrcStorage, t.SrcActualPath)
 	if err != nil {
 		return errors.WithMessagef(err, "failed get src [%s] file", t.SrcActualPath)
 	}
-	link, _, err := op.Link(t.Ctx(), t.SrcStorage, t.SrcActualPath, model.LinkArgs{})
+	link, srcFile, err := op.Link(t.Ctx(), t.SrcStorage, t.SrcActualPath, model.LinkArgs{})
 	if err != nil {
 		return errors.WithMessagef(err, "failed get [%s] link", t.SrcActualPath)
 	}
@@ -331,7 +329,7 @@ func transferObjFile(t *TransferTask) error {
 		return errors.WithMessagef(err, "failed get [%s] stream", t.SrcActualPath)
 	}
 	t.SetTotalBytes(ss.GetSize())
-	return op.Put(t.Ctx(), t.DstStorage, t.DstActualPath, ss, t.SetProgress)
+	return op.Put(context.WithValue(t.Ctx(), conf.SkipHookKey, struct{}{}), t.DstStorage, t.DstActualPath, ss, t.SetProgress)
 }
 
 func removeObjTemp(t *TransferTask) {
diff --git a/internal/op/archive.go b/internal/op/archive.go
index 05c6249d2..d0a53a919 100644
--- a/internal/op/archive.go
+++ b/internal/op/archive.go
@@ -223,16 +223,10 @@ func ListArchive(ctx context.Context, storage driver.Driver, path string, args m
 		// }
 	}
 	objs, err, _ := archiveListG.Do(key, func() ([]model.Obj, error) {
-		obj, files, err := listArchive(ctx, storage, path, args)
+		files, err := listArchive(ctx, storage, path, args)
 		if err != nil {
 			return nil, errors.Wrapf(err, "failed to list archive [%s]%s: %+v", path, args.InnerPath, err)
 		}
-		// set path
-		for _, f := range files {
-			if s, ok := f.(model.SetPath); ok && f.GetPath() == "" && obj.GetPath() != "" {
-				s.SetPath(stdpath.Join(obj.GetPath(), args.InnerPath, f.GetName()))
-			}
-		}
 		// warp obj name
 		model.WrapObjsName(files)
 		// sort objs
@@ -254,24 +248,24 @@ func ListArchive(ctx context.Context, storage driver.Driver, path string, args m
 	return objs, err
 }
 
-func _listArchive(ctx context.Context, storage driver.Driver, path string, args model.ArchiveListArgs) (model.Obj, []model.Obj, error) {
+func _listArchive(ctx context.Context, storage driver.Driver, path string, args model.ArchiveListArgs) ([]model.Obj, error) {
 	storageAr, ok := storage.(driver.ArchiveReader)
 	if ok {
 		obj, err := GetUnwrap(ctx, storage, path)
 		if err != nil {
-			return nil, nil, errors.WithMessage(err, "failed to get file")
+			return nil, errors.WithMessage(err, "failed to get file")
 		}
 		if obj.IsDir() {
-			return nil, nil, errors.WithStack(errs.NotFile)
+			return nil, errors.WithStack(errs.NotFile)
 		}
 		files, err := storageAr.ListArchive(ctx, obj, args.ArchiveInnerArgs)
 		if !errors.Is(err, errs.NotImplement) {
-			return obj, files, err
+			return files, err
 		}
 	}
-	obj, t, ss, err := GetArchiveToolAndStream(ctx, storage, path, args.LinkArgs)
+	_, t, ss, err := GetArchiveToolAndStream(ctx, storage, path, args.LinkArgs)
 	if err != nil {
-		return nil, nil, err
+		return nil, err
 	}
 	defer func() {
 		var e error
@@ -283,11 +277,11 @@ func _listArchive(ctx context.Context, storage driver.Driver, path string, args
 		}
 	}()
 	files, err := t.List(ss, args.ArchiveInnerArgs)
-	return obj, files, err
+	return files, err
 }
 
-func listArchive(ctx context.Context, storage driver.Driver, path string, args model.ArchiveListArgs) (model.Obj, []model.Obj, error) {
-	obj, files, err := _listArchive(ctx, storage, path, args)
+func listArchive(ctx context.Context, storage driver.Driver, path string, args model.ArchiveListArgs) ([]model.Obj, error) {
+	files, err := _listArchive(ctx, storage, path, args)
 	if errors.Is(err, errs.NotSupport) {
 		var meta model.ArchiveMeta
 		meta, err = GetArchiveMeta(ctx, storage, path, model.ArchiveMetaArgs{
@@ -295,20 +289,17 @@ func listArchive(ctx context.Context, storage driver.Driver, path string, args m
 			Refresh:     args.Refresh,
 		})
 		if err != nil {
-			return nil, nil, err
+			return nil, err
 		}
 		files, err = getChildrenFromArchiveMeta(meta, args.InnerPath)
 		if err != nil {
-			return nil, nil, err
+			return nil, err
 		}
 	}
-	if err == nil && obj == nil {
-		obj, err = GetUnwrap(ctx, storage, path)
-	}
 	if err != nil {
-		return nil, nil, err
+		return nil, err
 	}
-	return obj, files, err
+	return files, err
 }
 
 func getChildrenFromArchiveMeta(meta model.ArchiveMeta, innerPath string) ([]model.Obj, error) {
@@ -520,8 +511,12 @@ func ArchiveDecompress(ctx context.Context, storage driver.Driver, srcPath, dstD
 		newObjs, err = s.ArchiveDecompress(ctx, srcObj, dstDir, args)
 		if err == nil {
 			if len(newObjs) > 0 {
-				for _, newObj := range newObjs {
-					Cache.addDirectoryObject(storage, dstDirPath, model.WrapObjName(newObj))
+				if !storage.Config().NoCache {
+					if cache, exist := Cache.dirCache.Get(Key(storage, dstDirPath)); exist {
+						for _, newObj := range newObjs {
+							cache.UpdateObject(newObj.GetName(), newObj)
+						}
+					}
 				}
 			} else if !utils.IsBool(lazyCache...) {
 				Cache.DeleteDirectory(storage, dstDirPath)
@@ -538,15 +533,15 @@ func ArchiveDecompress(ctx context.Context, storage driver.Driver, srcPath, dstD
 	if !utils.IsBool(lazyCache...) && err == nil && needHandleObjsUpdateHook() {
 		onlyList := false
 		targetPath := dstDirPath
-		if newObjs != nil && len(newObjs) == 1 && newObjs[0].IsDir() {
+		if len(newObjs) == 1 && newObjs[0].IsDir() {
 			targetPath = stdpath.Join(dstDirPath, newObjs[0].GetName())
-		} else if newObjs != nil && len(newObjs) == 1 && !newObjs[0].IsDir() {
+		} else if len(newObjs) == 1 && !newObjs[0].IsDir() {
 			onlyList = true
 		} else if args.PutIntoNewDir {
 			targetPath = stdpath.Join(dstDirPath, strings.TrimSuffix(srcObj.GetName(), stdpath.Ext(srcObj.GetName())))
 		} else if innerBase := stdpath.Base(args.InnerPath); innerBase != "." && innerBase != "/" {
 			targetPath = stdpath.Join(dstDirPath, innerBase)
-			dstObj, e := GetUnwrap(ctx, storage, targetPath)
+			dstObj, e := Get(ctx, storage, targetPath)
 			onlyList = e != nil || !dstObj.IsDir()
 		}
 		if onlyList {
diff --git a/internal/op/cache.go b/internal/op/cache.go
index 52e430b1e..d8d32a74b 100644
--- a/internal/op/cache.go
+++ b/internal/op/cache.go
@@ -8,6 +8,7 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/cache"
 	"github.com/OpenListTeam/OpenList/v4/internal/driver"
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
 )
 
 type CacheManager struct {
@@ -32,39 +33,7 @@ func NewCacheManager() *CacheManager {
 var Cache = NewCacheManager()
 
 func Key(storage driver.Driver, path string) string {
-	return stdpath.Join(storage.GetStorage().MountPath, path)
-}
-
-// update object in dirCache.
-// if it's a directory, remove all its children from dirCache too.
-// if it's a file, remove its link from linkCache.
-func (cm *CacheManager) updateDirectoryObject(storage driver.Driver, dirPath string, oldObj model.Obj, newObj model.Obj) {
-	key := Key(storage, dirPath)
-	if !oldObj.IsDir() {
-		cm.linkCache.DeleteKey(stdpath.Join(key, oldObj.GetName()))
-		cm.linkCache.DeleteKey(stdpath.Join(key, newObj.GetName()))
-	}
-	if storage.Config().NoCache {
-		return
-	}
-
-	if cache, exist := cm.dirCache.Get(key); exist {
-		if oldObj.IsDir() {
-			cm.deleteDirectoryTree(stdpath.Join(key, oldObj.GetName()))
-		}
-		cache.UpdateObject(oldObj.GetName(), newObj)
-	}
-}
-
-// add new object to dirCache
-func (cm *CacheManager) addDirectoryObject(storage driver.Driver, dirPath string, newObj model.Obj) {
-	if storage.Config().NoCache {
-		return
-	}
-	cache, exist := cm.dirCache.Get(Key(storage, dirPath))
-	if exist {
-		cache.UpdateObject(newObj.GetName(), newObj)
-	}
+	return utils.GetFullPath(storage.GetStorage().MountPath, path)
 }
 
 // recursively delete directory and its children from dirCache
@@ -75,10 +44,12 @@ func (cm *CacheManager) DeleteDirectoryTree(storage driver.Driver, dirPath strin
 	cm.deleteDirectoryTree(Key(storage, dirPath))
 }
 func (cm *CacheManager) deleteDirectoryTree(key string) {
-	if dirCache, exists := cm.dirCache.Take(key); exists {
+	if dirCache, exists := cm.dirCache.Pop(key); exists {
 		for _, obj := range dirCache.objs {
 			if obj.IsDir() {
 				cm.deleteDirectoryTree(stdpath.Join(key, obj.GetName()))
+			} else {
+				cm.linkCache.DeleteKey(stdpath.Join(key, obj.GetName()))
 			}
 		}
 	}
@@ -162,15 +133,15 @@ func (cm *CacheManager) SetStorageDetails(storage driver.Driver, details *model.
 		return
 	}
 	expiration := time.Minute * time.Duration(storage.GetStorage().CacheExpiration)
-	cm.detailCache.SetWithTTL(storage.GetStorage().MountPath, details, expiration)
+	cm.detailCache.SetWithTTL(utils.GetActualMountPath(storage.GetStorage().MountPath), details, expiration)
 }
 
 func (cm *CacheManager) GetStorageDetails(storage driver.Driver) (*model.StorageDetails, bool) {
-	return cm.detailCache.Get(storage.GetStorage().MountPath)
+	return cm.detailCache.Get(utils.GetActualMountPath(storage.GetStorage().MountPath))
 }
 
 func (cm *CacheManager) InvalidateStorageDetails(storage driver.Driver) {
-	cm.detailCache.Delete(storage.GetStorage().MountPath)
+	cm.detailCache.Delete(utils.GetActualMountPath(storage.GetStorage().MountPath))
 }
 
 // clears all caches
diff --git a/internal/op/driver.go b/internal/op/driver.go
index f25b3a6b1..6c4e7d265 100644
--- a/internal/op/driver.go
+++ b/internal/op/driver.go
@@ -80,6 +80,13 @@ func getMainItems(config driver.Config) []driver.Item {
 			Required: true,
 			Help:     "The cache expiration time for this storage",
 		})
+		items = append(items, driver.Item{
+			Name:     "custom_cache_policies",
+			Type:     conf.TypeText,
+			Default:  "",
+			Required: false,
+			Help:     "The cache expiration rules for this storage",
+		})
 	}
 	if config.MustProxy() {
 		items = append(items, driver.Item{
diff --git a/internal/op/fs.go b/internal/op/fs.go
index 087857f5d..5116bbef5 100644
--- a/internal/op/fs.go
+++ b/internal/op/fs.go
@@ -4,6 +4,7 @@ import (
 	"context"
 	stdpath "path"
 	"strconv"
+	"strings"
 	"time"
 
 	"github.com/OpenListTeam/OpenList/v4/internal/conf"
@@ -13,6 +14,7 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/stream"
 	"github.com/OpenListTeam/OpenList/v4/pkg/singleflight"
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+	"github.com/bmatcuk/doublestar/v4"
 	"github.com/pkg/errors"
 	log "github.com/sirupsen/logrus"
 	"golang.org/x/time/rate"
@@ -22,6 +24,10 @@ var listG singleflight.Group[[]model.Obj]
 
 // List files in storage, not contains virtual file
 func List(ctx context.Context, storage driver.Driver, path string, args model.ListArgs) ([]model.Obj, error) {
+	return list(ctx, storage, path, args, nil)
+}
+
+func list(ctx context.Context, storage driver.Driver, path string, args model.ListArgs, resultValidator func([]model.Obj) error) ([]model.Obj, error) {
 	if storage.Config().CheckStatus && storage.GetStorage().Status != WORK {
 		return nil, errors.WithMessagef(errs.StorageNotInit, "storage status: %s", storage.GetStorage().Status)
 	}
@@ -31,48 +37,76 @@ func List(ctx context.Context, storage driver.Driver, path string, args model.Li
 	if !args.Refresh {
 		if dirCache, exists := Cache.dirCache.Get(key); exists {
 			log.Debugf("use cache when list %s", path)
-			return dirCache.GetSortedObjects(storage), nil
+			objs := dirCache.GetSortedObjects(storage)
+			if resultValidator != nil {
+				if err := resultValidator(objs); err == nil {
+					return objs, nil
+				}
+			} else {
+				return objs, nil
+			}
 		}
 	}
 
-	dir, err := GetUnwrap(ctx, storage, path)
-	if err != nil {
-		return nil, errors.WithMessage(err, "failed get dir")
-	}
-	log.Debugf("list dir: %+v", dir)
-	if !dir.IsDir() {
-		return nil, errors.WithStack(errs.NotFolder)
-	}
-
 	objs, err, _ := listG.Do(key, func() ([]model.Obj, error) {
+		dir, err := GetUnwrap(ctx, storage, path)
+		if err != nil {
+			return nil, errors.WithMessage(err, "failed get dir")
+		}
+		log.Debugf("list dir: %+v", dir)
+		if !dir.IsDir() {
+			return nil, errors.WithStack(errs.NotFolder)
+		}
 		files, err := storage.List(ctx, dir, args)
 		if err != nil {
 			return nil, errors.Wrapf(err, "failed to list objs")
 		}
-		// set path
-		for _, f := range files {
-			if s, ok := f.(model.SetPath); ok && f.GetPath() == "" && dir.GetPath() != "" {
-				s.SetPath(stdpath.Join(dir.GetPath(), f.GetName()))
-			}
-		}
 		// warp obj name
-		model.WrapObjsName(files)
-		// call hooks
-		go func(reqPath string, files []model.Obj) {
-			HandleObjsUpdateHook(context.WithoutCancel(ctx), reqPath, files)
-		}(utils.GetFullPath(storage.GetStorage().MountPath, path), files)
-
+		wrapObjsName(storage, files)
 		// sort objs
 		if storage.Config().LocalSort {
 			model.SortFiles(files, storage.GetStorage().OrderBy, storage.GetStorage().OrderDirection)
 		}
 		model.ExtractFolder(files, storage.GetStorage().ExtractFolder)
 
+		if !args.SkipHook {
+			// call hooks
+			go func(reqPath string, files []model.Obj) {
+				HandleObjsUpdateHook(context.WithoutCancel(ctx), reqPath, files)
+			}(utils.GetFullPath(storage.GetStorage().MountPath, path), files)
+		}
+
 		if !storage.Config().NoCache {
 			if len(files) > 0 {
 				log.Debugf("set cache: %s => %+v", key, files)
-				ttl := time.Minute * time.Duration(storage.GetStorage().CacheExpiration)
-				Cache.dirCache.SetWithTTL(key, newDirectoryCache(files), ttl)
+
+				ttl := storage.GetStorage().CacheExpiration
+
+				customCachePolicies := storage.GetStorage().CustomCachePolicies
+				if len(customCachePolicies) > 0 {
+					configPolicies := strings.Split(customCachePolicies, "\n")
+					for _, configPolicy := range configPolicies {
+						pattern, ttlstr, ok := strings.Cut(strings.TrimSpace(configPolicy), ":")
+						if !ok {
+							log.Warnf("Malformed custom cache policy entry: %s in storage %s for path %s. Expected format: pattern:ttl", configPolicy, storage.GetStorage().MountPath, path)
+							continue
+						}
+						if match, err1 := doublestar.Match(pattern, path); err1 != nil {
+							log.Warnf("Invalid glob pattern in custom cache policy: %s, error: %v", pattern, err1)
+							continue
+						} else if !match {
+							continue
+						}
+
+						if configTtl, err1 := strconv.ParseInt(ttlstr, 10, 64); err1 == nil {
+							ttl = int(configTtl)
+							break
+						}
+					}
+				}
+
+				duration := time.Minute * time.Duration(ttl)
+				Cache.dirCache.SetWithTTL(key, newDirectoryCache(files), duration)
 			} else {
 				log.Debugf("del cache: %s", key)
 				Cache.deleteDirectoryTree(key)
@@ -80,74 +114,100 @@ func List(ctx context.Context, storage driver.Driver, path string, args model.Li
 		}
 		return files, nil
 	})
-	return objs, err
+	if err != nil {
+		return nil, err
+	}
+	if resultValidator != nil {
+		if err := resultValidator(objs); err != nil {
+			return nil, err
+		}
+	}
+	return objs, nil
 }
 
 // Get object from list of files
-func Get(ctx context.Context, storage driver.Driver, path string) (model.Obj, error) {
+func Get(ctx context.Context, storage driver.Driver, path string, excludeTempObj ...bool) (model.Obj, error) {
+	if storage.Config().CheckStatus && storage.GetStorage().Status != WORK {
+		return nil, errors.WithMessagef(errs.StorageNotInit, "storage status: %s", storage.GetStorage().Status)
+	}
 	path = utils.FixAndCleanPath(path)
 	log.Debugf("op.Get %s", path)
 
+	// is root folder
+	if path == "/" {
+		if getRooter, ok := storage.(driver.GetRooter); ok {
+			rootObj, err := getRooter.GetRoot(ctx)
+			if err != nil {
+				return nil, errors.WithMessage(err, "failed get root obj")
+			}
+			return rootObj, nil
+		}
+		switch r := storage.(type) {
+		case driver.IRootId:
+			return &model.Object{
+				ID:       r.GetRootId(),
+				Name:     RootName,
+				Modified: storage.GetStorage().Modified,
+				IsFolder: true,
+				Mask:     model.Locked,
+			}, nil
+		case driver.IRootPath:
+			return &model.Object{
+				Path:     r.GetRootPath(),
+				Name:     RootName,
+				Modified: storage.GetStorage().Modified,
+				Mask:     model.Locked,
+				IsFolder: true,
+			}, nil
+		}
+		return nil, errors.New("please implement GetRooter or IRootPath or IRootId interface")
+	}
+
+	// try get from cache first
+	dir, name := stdpath.Split(path)
+	dirCache, dirCacheExists := Cache.dirCache.Get(Key(storage, dir))
+	refreshList := false
+	excludeTemp := utils.IsBool(excludeTempObj...)
+	if dirCacheExists {
+		files := dirCache.GetSortedObjects(storage)
+		for _, f := range files {
+			if f.GetName() == name {
+				if excludeTemp && model.ObjHasMask(f, model.Temp) {
+					refreshList = true
+					break
+				}
+				return f, nil
+			}
+		}
+	}
+
 	// get the obj directly without list so that we can reduce the io
 	if g, ok := storage.(driver.Getter); ok {
 		obj, err := g.Get(ctx, path)
 		if err == nil {
-			return model.WrapObjName(obj), nil
+			return obj, nil
 		}
 		if !errs.IsNotImplementError(err) && !errs.IsNotSupportError(err) {
 			return nil, errors.WithMessage(err, "failed to get obj")
 		}
 	}
 
-	// is root folder
-	if utils.PathEqual(path, "/") {
-		var rootObj model.Obj
-		if getRooter, ok := storage.(driver.GetRooter); ok {
-			obj, err := getRooter.GetRoot(ctx)
-			if err != nil {
-				return nil, errors.WithMessage(err, "failed get root obj")
-			}
-			rootObj = obj
-		} else {
-			switch r := storage.GetAddition().(type) {
-			case driver.IRootId:
-				rootObj = &model.Object{
-					ID:       r.GetRootId(),
-					Name:     RootName,
-					Size:     0,
-					Modified: storage.GetStorage().Modified,
-					IsFolder: true,
-				}
-			case driver.IRootPath:
-				rootObj = &model.Object{
-					Path:     r.GetRootPath(),
-					Name:     RootName,
-					Size:     0,
-					Modified: storage.GetStorage().Modified,
-					IsFolder: true,
+	if !dirCacheExists || refreshList {
+		var obj model.Obj
+		list(ctx, storage, dir, model.ListArgs{Refresh: refreshList}, func(objs []model.Obj) error {
+			for _, f := range objs {
+				if f.GetName() == name {
+					if excludeTemp && model.ObjHasMask(f, model.Temp) {
+						return errs.ObjectNotFound
+					}
+					obj = f
+					return nil
 				}
-			default:
-				return nil, errors.Errorf("please implement IRootPath or IRootId or GetRooter method")
 			}
-		}
-		if rootObj == nil {
-			return nil, errors.Errorf("please implement IRootPath or IRootId or GetRooter method")
-		}
-		return &model.ObjWrapName{
-			Name: RootName,
-			Obj:  rootObj,
-		}, nil
-	}
-
-	// not root folder
-	dir, name := stdpath.Split(path)
-	files, err := List(ctx, storage, dir, model.ListArgs{})
-	if err != nil {
-		return nil, errors.WithMessage(err, "failed get parent list")
-	}
-	for _, f := range files {
-		if f.GetName() == name {
-			return f, nil
+			return nil
+		})
+		if obj != nil {
+			return obj, nil
 		}
 	}
 	log.Debugf("cant find obj with name: %s", name)
@@ -155,11 +215,11 @@ func Get(ctx context.Context, storage driver.Driver, path string) (model.Obj, er
 }
 
 func GetUnwrap(ctx context.Context, storage driver.Driver, path string) (model.Obj, error) {
-	obj, err := Get(ctx, storage, path)
+	obj, err := Get(ctx, storage, path, true)
 	if err != nil {
 		return nil, err
 	}
-	return model.UnwrapObj(obj), err
+	return model.UnwrapObjName(obj), err
 }
 
 var linkG = singleflight.Group[*objWithLink]{}
@@ -175,10 +235,10 @@ func Link(ctx context.Context, storage driver.Driver, path string, args model.Li
 		mode = storage.(driver.LinkCacheModeResolver).ResolveLinkCacheMode(path)
 	}
 	typeKey := args.Type
-	if mode&driver.LinkCacheIP == driver.LinkCacheIP {
+	if mode&driver.LinkCacheIP != 0 {
 		typeKey += "/" + args.IP
 	}
-	if mode&driver.LinkCacheUA == driver.LinkCacheUA {
+	if mode&driver.LinkCacheUA != 0 {
 		typeKey += "/" + args.Header.Get("User-Agent")
 	}
 	key := Key(storage, path)
@@ -210,42 +270,40 @@ func Link(ctx context.Context, storage driver.Driver, path string, args model.Li
 		}
 		return ol, nil
 	}
-	retry := 0
 	for {
 		ol, err, _ := linkG.Do(key+"/"+typeKey, fn)
 		if err != nil {
 			return nil, nil, err
 		}
 		if ol.link.SyncClosers.AcquireReference() || !ol.link.RequireReference {
-			if retry > 1 {
-				log.Warnf("Link retry successed after %d times: %s %s", retry, key, typeKey)
-			}
 			return ol.link, ol.obj, nil
 		}
-		retry++
 	}
 }
 
 // Other api
-func Other(ctx context.Context, storage driver.Driver, args model.FsOtherArgs) (interface{}, error) {
+func Other(ctx context.Context, storage driver.Driver, args model.FsOtherArgs) (any, error) {
+	if storage.Config().CheckStatus && storage.GetStorage().Status != WORK {
+		return nil, errors.WithMessagef(errs.StorageNotInit, "storage status: %s", storage.GetStorage().Status)
+	}
+	o, ok := storage.(driver.Other)
+	if !ok {
+		return nil, errs.NotImplement
+	}
 	obj, err := GetUnwrap(ctx, storage, args.Path)
 	if err != nil {
 		return nil, errors.WithMessagef(err, "failed to get obj")
 	}
-	if o, ok := storage.(driver.Other); ok {
-		return o.Other(ctx, model.OtherArgs{
-			Obj:    obj,
-			Method: args.Method,
-			Data:   args.Data,
-		})
-	} else {
-		return nil, errs.NotImplement
-	}
+	return o.Other(ctx, model.OtherArgs{
+		Obj:    obj,
+		Method: args.Method,
+		Data:   args.Data,
+	})
 }
 
 var mkdirG singleflight.Group[any]
 
-func MakeDir(ctx context.Context, storage driver.Driver, path string, lazyCache ...bool) error {
+func MakeDir(ctx context.Context, storage driver.Driver, path string) error {
 	if storage.Config().CheckStatus && storage.GetStorage().Status != WORK {
 		return errors.WithMessagef(errs.StorageNotInit, "storage status: %s", storage.GetStorage().Status)
 	}
@@ -253,162 +311,200 @@ func MakeDir(ctx context.Context, storage driver.Driver, path string, lazyCache
 	key := Key(storage, path)
 	_, err, _ := mkdirG.Do(key, func() (any, error) {
 		// check if dir exists
-		f, err := GetUnwrap(ctx, storage, path)
-		if err != nil {
-			if errs.IsObjectNotFound(err) {
-				parentPath, dirName := stdpath.Split(path)
-				err = MakeDir(ctx, storage, parentPath)
-				if err != nil {
-					return nil, errors.WithMessagef(err, "failed to make parent dir [%s]", parentPath)
-				}
-				parentDir, err := GetUnwrap(ctx, storage, parentPath)
-				// this should not happen
-				if err != nil {
-					return nil, errors.WithMessagef(err, "failed to get parent dir [%s]", parentPath)
-				}
-
-				switch s := storage.(type) {
-				case driver.MkdirResult:
-					var newObj model.Obj
-					newObj, err = s.MakeDir(ctx, parentDir, dirName)
-					if err == nil {
-						if newObj != nil {
-							if !storage.Config().NoCache {
-								if dirCache, exist := Cache.dirCache.Get(Key(storage, parentPath)); exist {
-									dirCache.UpdateObject("", newObj)
-								}
-							}
-						} else if !utils.IsBool(lazyCache...) {
-							Cache.DeleteDirectory(storage, parentPath)
-						}
-					}
-				case driver.Mkdir:
-					err = s.MakeDir(ctx, parentDir, dirName)
-					if err == nil && !utils.IsBool(lazyCache...) {
-						Cache.DeleteDirectory(storage, parentPath)
-					}
-				default:
-					return nil, errs.NotImplement
-				}
-				return nil, errors.WithStack(err)
+		f, err := Get(ctx, storage, path)
+		if err == nil {
+			if f.IsDir() {
+				return nil, nil
 			}
+			return nil, errors.New("file exists")
+		}
+		if !errs.IsObjectNotFound(err) {
 			return nil, errors.WithMessage(err, "failed to check if dir exists")
 		}
-		// dir exists
-		if f.IsDir() {
+		parentPath, dirName := stdpath.Split(path)
+		if err = MakeDir(ctx, storage, parentPath); err != nil {
+			return nil, errors.WithMessagef(err, "failed to make parent dir [%s]", parentPath)
+		}
+		parentDir, err := GetUnwrap(ctx, storage, parentPath)
+		// this should not happen
+		if err != nil {
+			return nil, errors.WithMessagef(err, "failed to get parent dir [%s]", parentPath)
+		}
+		if model.ObjHasMask(parentDir, model.NoWrite) {
+			return nil, errors.WithStack(errs.PermissionDenied)
+		}
+
+		var newObj model.Obj
+		switch s := storage.(type) {
+		case driver.MkdirResult:
+			newObj, err = s.MakeDir(ctx, parentDir, dirName)
+		case driver.Mkdir:
+			err = s.MakeDir(ctx, parentDir, dirName)
+		default:
+			return nil, errs.NotImplement
+		}
+		if err != nil {
+			return nil, errors.WithStack(err)
+		}
+		if storage.Config().NoCache {
 			return nil, nil
 		}
-		// dir to make is a file
-		return nil, errors.New("file exists")
+		if dirCache, exist := Cache.dirCache.Get(Key(storage, parentPath)); exist {
+			if newObj == nil {
+				t := time.Now()
+				newObj = &model.Object{
+					Name:     dirName,
+					IsFolder: true,
+					Modified: t,
+					Ctime:    t,
+					Mask:     model.Temp,
+				}
+			}
+			dirCache.UpdateObject("", wrapObjName(storage, newObj))
+		}
+		return nil, nil
 	})
 	return err
 }
 
-func Move(ctx context.Context, storage driver.Driver, srcPath, dstDirPath string, lazyCache ...bool) error {
+func Move(ctx context.Context, storage driver.Driver, srcPath, dstDirPath string) error {
 	if storage.Config().CheckStatus && storage.GetStorage().Status != WORK {
 		return errors.WithMessagef(errs.StorageNotInit, "storage status: %s", storage.GetStorage().Status)
 	}
 	srcPath = utils.FixAndCleanPath(srcPath)
+	if utils.PathEqual(srcPath, "/") {
+		return errors.New("move root folder is not allowed")
+	}
 	srcDirPath := stdpath.Dir(srcPath)
 	dstDirPath = utils.FixAndCleanPath(dstDirPath)
 	if dstDirPath == srcDirPath {
 		return errors.New("move in place")
 	}
-	srcRawObj, err := Get(ctx, storage, srcPath)
+	srcRawObj, err := Get(ctx, storage, srcPath, true)
 	if err != nil {
 		return errors.WithMessage(err, "failed to get src object")
 	}
-	srcObj := model.UnwrapObj(srcRawObj)
+	if model.ObjHasMask(srcRawObj, model.NoMove) {
+		return errors.WithStack(errs.PermissionDenied)
+	}
+	srcObj := model.UnwrapObjName(srcRawObj)
 	dstDir, err := GetUnwrap(ctx, storage, dstDirPath)
 	if err != nil {
 		return errors.WithMessage(err, "failed to get dst dir")
 	}
+	if model.ObjHasMask(dstDir, model.NoWrite) {
+		return errors.WithStack(errs.PermissionDenied)
+	}
 
+	var newObj model.Obj
 	switch s := storage.(type) {
 	case driver.MoveResult:
-		var newObj model.Obj
 		newObj, err = s.Move(ctx, srcObj, dstDir)
-		if err == nil {
-			Cache.removeDirectoryObject(storage, srcDirPath, srcRawObj)
-			if newObj != nil {
-				Cache.addDirectoryObject(storage, dstDirPath, model.WrapObjName(newObj))
-			} else if !utils.IsBool(lazyCache...) {
-				Cache.DeleteDirectory(storage, dstDirPath)
-			}
-		}
 	case driver.Move:
 		err = s.Move(ctx, srcObj, dstDir)
-		if err == nil {
-			Cache.removeDirectoryObject(storage, srcDirPath, srcRawObj)
-			if !utils.IsBool(lazyCache...) {
-				Cache.DeleteDirectory(storage, dstDirPath)
-			}
-		}
 	default:
 		err = errs.NotImplement
 	}
+	if err != nil {
+		return errors.WithStack(err)
+	}
 
-	if !utils.IsBool(lazyCache...) && err == nil && needHandleObjsUpdateHook() {
-		if !srcObj.IsDir() {
-			go List(context.Background(), storage, dstDirPath, model.ListArgs{Refresh: true})
-		} else {
-			targetPath := stdpath.Join(dstDirPath, srcObj.GetName())
-			var limiter *rate.Limiter
-			if l, _ := GetSettingItemByKey(conf.HandleHookRateLimit); l != nil {
-				if f, e := strconv.ParseFloat(l.Value, 64); e == nil && f > .0 {
-					limiter = rate.NewLimiter(rate.Limit(f), 1)
-				}
+	srcKey := Key(storage, srcDirPath)
+	dstKey := Key(storage, dstDirPath)
+	if !srcRawObj.IsDir() {
+		Cache.linkCache.DeleteKey(stdpath.Join(srcKey, srcRawObj.GetName()))
+		Cache.linkCache.DeleteKey(stdpath.Join(dstKey, srcRawObj.GetName()))
+	}
+	if !storage.Config().NoCache {
+		if cache, exist := Cache.dirCache.Get(srcKey); exist {
+			if srcRawObj.IsDir() {
+				Cache.deleteDirectoryTree(stdpath.Join(srcKey, srcRawObj.GetName()))
+			}
+			cache.RemoveObject(srcRawObj.GetName())
+		}
+		if cache, exist := Cache.dirCache.Get(dstKey); exist {
+			if newObj == nil {
+				newObj = &model.ObjWrapMask{Obj: srcRawObj, Mask: model.Temp}
+			} else {
+				newObj = wrapObjName(storage, newObj)
 			}
-			go RecursivelyListStorage(context.Background(), storage, targetPath, limiter, nil)
+			cache.UpdateObject(srcRawObj.GetName(), newObj)
 		}
 	}
 
-	return errors.WithStack(err)
+	if ctx.Value(conf.SkipHookKey) != nil || !needHandleObjsUpdateHook() {
+		return nil
+	}
+	if !srcObj.IsDir() {
+		go objsUpdateHook(context.WithoutCancel(ctx), storage, dstDirPath, false)
+	} else {
+		go objsUpdateHook(context.WithoutCancel(ctx), storage, stdpath.Join(dstDirPath, srcObj.GetName()), true)
+	}
+	return nil
 }
 
-func Rename(ctx context.Context, storage driver.Driver, srcPath, dstName string, lazyCache ...bool) error {
+func Rename(ctx context.Context, storage driver.Driver, srcPath, dstName string) error {
 	if storage.Config().CheckStatus && storage.GetStorage().Status != WORK {
 		return errors.WithMessagef(errs.StorageNotInit, "storage status: %s", storage.GetStorage().Status)
 	}
 	srcPath = utils.FixAndCleanPath(srcPath)
-	srcRawObj, err := Get(ctx, storage, srcPath)
+	if utils.PathEqual(srcPath, "/") {
+		return errors.New("rename root folder is not allowed")
+	}
+	srcRawObj, err := Get(ctx, storage, srcPath, true)
 	if err != nil {
 		return errors.WithMessage(err, "failed to get src object")
 	}
-	srcObj := model.UnwrapObj(srcRawObj)
+	if model.ObjHasMask(srcRawObj, model.NoRename) {
+		return errors.WithStack(errs.PermissionDenied)
+	}
+	srcObj := model.UnwrapObjName(srcRawObj)
 
+	var newObj model.Obj
 	switch s := storage.(type) {
 	case driver.RenameResult:
-		var newObj model.Obj
 		newObj, err = s.Rename(ctx, srcObj, dstName)
-		if err == nil {
-			srcDirPath := stdpath.Dir(srcPath)
-			if newObj != nil {
-				Cache.updateDirectoryObject(storage, srcDirPath, srcRawObj, model.WrapObjName(newObj))
-			} else {
-				Cache.removeDirectoryObject(storage, srcDirPath, srcRawObj)
-				if !utils.IsBool(lazyCache...) {
-					Cache.DeleteDirectory(storage, srcDirPath)
-				}
-			}
-		}
 	case driver.Rename:
 		err = s.Rename(ctx, srcObj, dstName)
-		if err == nil {
-			srcDirPath := stdpath.Dir(srcPath)
-			Cache.removeDirectoryObject(storage, srcDirPath, srcRawObj)
-			if !utils.IsBool(lazyCache...) {
-				Cache.DeleteDirectory(storage, srcDirPath)
-			}
-		}
 	default:
 		return errs.NotImplement
 	}
-	return errors.WithStack(err)
+	if err != nil {
+		return errors.WithStack(err)
+	}
+
+	dirKey := Key(storage, stdpath.Dir(srcPath))
+	if !srcRawObj.IsDir() {
+		Cache.linkCache.DeleteKey(stdpath.Join(dirKey, srcRawObj.GetName()))
+		Cache.linkCache.DeleteKey(stdpath.Join(dirKey, dstName))
+	}
+	if !storage.Config().NoCache {
+		if cache, exist := Cache.dirCache.Get(dirKey); exist {
+			if srcRawObj.IsDir() {
+				Cache.deleteDirectoryTree(stdpath.Join(dirKey, srcRawObj.GetName()))
+			}
+			if newObj == nil {
+				newObj = &model.ObjWrapMask{Obj: &model.ObjWrapName{Name: dstName, Obj: srcObj}, Mask: model.Temp}
+			}
+			newObj = wrapObjName(storage, newObj)
+			cache.UpdateObject(srcRawObj.GetName(), newObj)
+		}
+	}
+
+	if ctx.Value(conf.SkipHookKey) != nil || !needHandleObjsUpdateHook() {
+		return nil
+	}
+	dstDirPath := stdpath.Dir(srcPath)
+	if !srcObj.IsDir() {
+		go objsUpdateHook(context.WithoutCancel(ctx), storage, dstDirPath, false)
+	} else {
+		go objsUpdateHook(context.WithoutCancel(ctx), storage, stdpath.Join(dstDirPath, srcObj.GetName()), true)
+	}
+	return nil
 }
 
 // Copy Just copy file[s] in a storage
-func Copy(ctx context.Context, storage driver.Driver, srcPath, dstDirPath string, lazyCache ...bool) error {
+func Copy(ctx context.Context, storage driver.Driver, srcPath, dstDirPath string) error {
 	if storage.Config().CheckStatus && storage.GetStorage().Status != WORK {
 		return errors.WithMessagef(errs.StorageNotInit, "storage status: %s", storage.GetStorage().Status)
 	}
@@ -417,65 +513,70 @@ func Copy(ctx context.Context, storage driver.Driver, srcPath, dstDirPath string
 	if dstDirPath == stdpath.Dir(srcPath) {
 		return errors.New("copy in place")
 	}
-	srcRawObj, err := Get(ctx, storage, srcPath)
+	srcRawObj, err := Get(ctx, storage, srcPath, true)
 	if err != nil {
 		return errors.WithMessage(err, "failed to get src object")
 	}
-	srcObj := model.UnwrapObj(srcRawObj)
+	// if model.ObjHasMask(srcRawObj, model.NoCopy) {
+	// 	return errors.WithStack(errs.PermissionDenied)
+	// }
+	srcObj := model.UnwrapObjName(srcRawObj)
 	dstDir, err := GetUnwrap(ctx, storage, dstDirPath)
 	if err != nil {
 		return errors.WithMessage(err, "failed to get dst dir")
 	}
+	if model.ObjHasMask(dstDir, model.NoWrite) {
+		return errors.WithStack(errs.PermissionDenied)
+	}
 
+	var newObj model.Obj
 	switch s := storage.(type) {
 	case driver.CopyResult:
-		var newObj model.Obj
 		newObj, err = s.Copy(ctx, srcObj, dstDir)
-		if err == nil {
-			if newObj != nil {
-				Cache.addDirectoryObject(storage, dstDirPath, model.WrapObjName(newObj))
-			} else if !utils.IsBool(lazyCache...) {
-				Cache.DeleteDirectory(storage, dstDirPath)
-			}
-		}
 	case driver.Copy:
 		err = s.Copy(ctx, srcObj, dstDir)
-		if err == nil {
-			if !utils.IsBool(lazyCache...) {
-				Cache.DeleteDirectory(storage, dstDirPath)
-			}
-		}
 	default:
 		err = errs.NotImplement
 	}
+	if err != nil {
+		return errors.WithStack(err)
+	}
 
-	if !utils.IsBool(lazyCache...) && err == nil && needHandleObjsUpdateHook() {
-		if !srcObj.IsDir() {
-			go List(context.Background(), storage, dstDirPath, model.ListArgs{Refresh: true})
-		} else {
-			targetPath := stdpath.Join(dstDirPath, srcObj.GetName())
-			var limiter *rate.Limiter
-			if l, _ := GetSettingItemByKey(conf.HandleHookRateLimit); l != nil {
-				if f, e := strconv.ParseFloat(l.Value, 64); e == nil && f > .0 {
-					limiter = rate.NewLimiter(rate.Limit(f), 1)
-				}
+	dstKey := Key(storage, dstDirPath)
+	if !srcRawObj.IsDir() {
+		Cache.linkCache.DeleteKey(stdpath.Join(dstKey, srcRawObj.GetName()))
+	}
+	if !storage.Config().NoCache {
+		if cache, exist := Cache.dirCache.Get(dstKey); exist {
+			if newObj == nil {
+				newObj = &model.ObjWrapMask{Obj: srcRawObj, Mask: model.Temp}
+			} else {
+				newObj = wrapObjName(storage, newObj)
 			}
-			go RecursivelyListStorage(context.Background(), storage, targetPath, limiter, nil)
+			cache.UpdateObject(srcRawObj.GetName(), newObj)
 		}
 	}
 
-	return errors.WithStack(err)
+	if ctx.Value(conf.SkipHookKey) != nil || !needHandleObjsUpdateHook() {
+		return nil
+	}
+	if !srcObj.IsDir() {
+		go objsUpdateHook(context.WithoutCancel(ctx), storage, dstDirPath, false)
+	} else {
+		go objsUpdateHook(context.WithoutCancel(ctx), storage, stdpath.Join(dstDirPath, srcObj.GetName()), true)
+	}
+	return nil
 }
 
 func Remove(ctx context.Context, storage driver.Driver, path string) error {
 	if storage.Config().CheckStatus && storage.GetStorage().Status != WORK {
 		return errors.WithMessagef(errs.StorageNotInit, "storage status: %s", storage.GetStorage().Status)
 	}
+	path = utils.FixAndCleanPath(path)
 	if utils.PathEqual(path, "/") {
-		return errors.New("delete root folder is not allowed, please goto the manage page to delete the storage instead")
+		return errors.New("delete root folder is not allowed")
 	}
-	path = utils.FixAndCleanPath(path)
-	rawObj, err := Get(ctx, storage, path)
+	rawObj, err := Get(ctx, storage, path, true)
 	if err != nil {
 		// if object not found, it's ok
 		if errs.IsObjectNotFound(err) {
@@ -484,11 +585,14 @@ func Remove(ctx context.Context, storage driver.Driver, path string) error {
 		}
 		return errors.WithMessage(err, "failed to get object")
 	}
+	if model.ObjHasMask(rawObj, model.NoRemove) {
+		return errors.WithStack(errs.PermissionDenied)
+	}
 	dirPath := stdpath.Dir(path)
 
 	switch s := storage.(type) {
 	case driver.Remove:
-		err = s.Remove(ctx, model.UnwrapObj(rawObj))
+		err = s.Remove(ctx, model.UnwrapObjName(rawObj))
 		if err == nil {
 			Cache.removeDirectoryObject(storage, dirPath, rawObj)
 		}
@@ -498,10 +602,9 @@ func Remove(ctx context.Context, storage driver.Driver, path string) error {
 	return errors.WithStack(err)
 }
 
-func Put(ctx context.Context, storage driver.Driver, dstDirPath string, file model.FileStreamer, up driver.UpdateProgress, lazyCache ...bool) error {
-	close := file.Close
+func Put(ctx context.Context, storage driver.Driver, dstDirPath string, file model.FileStreamer, up driver.UpdateProgress) error {
 	defer func() {
-		if err := close(); err != nil {
+		if err := file.Close(); err != nil {
 			log.Errorf("failed to close file streamer, %v", err)
 		}
 	}()
@@ -512,7 +615,7 @@ func Put(ctx context.Context, storage driver.Driver, dstDirPath string, file mod
 	if storage.Config().OnlyIndices {
 		var link string
 		dstDirPath, link = urlTreeSplitLineFormPath(stdpath.Join(dstDirPath, file.GetName()))
-		file = &stream.FileStream{Obj: &model.Object{Name: link}}
+		file = &stream.FileStream{Obj: &model.Object{Name: link}, Closers: utils.Closers{file}}
 	}
 	// if file exist and size = 0, delete it
 	dstDirPath = utils.FixAndCleanPath(dstDirPath)
@@ -545,6 +648,9 @@ func Put(ctx context.Context, storage driver.Driver, dstDirPath string, file mod
 	if err != nil {
 		return errors.WithMessagef(err, "failed to get dir [%s]", dstDirPath)
 	}
+	if model.ObjHasMask(parentDir, model.NoWrite) {
+		return errors.WithStack(errs.PermissionDenied)
+	}
 	// if up is nil, set a default to prevent panic
 	if up == nil {
 		up = func(p float64) {}
@@ -555,29 +661,38 @@ func Put(ctx context.Context, storage driver.Driver, dstDirPath string, file mod
 		log.Warnf("file size < 0, try to get full size from cache")
 		file.CacheFullAndWriter(nil, nil)
 	}
+
+	var newObj model.Obj
 	switch s := storage.(type) {
 	case driver.PutResult:
-		var newObj model.Obj
 		newObj, err = s.Put(ctx, parentDir, file, up)
-		if err == nil {
-			Cache.linkCache.DeleteKey(Key(storage, dstPath))
-			if newObj != nil {
-				Cache.addDirectoryObject(storage, dstDirPath, model.WrapObjName(newObj))
-			} else if !utils.IsBool(lazyCache...) {
-				Cache.DeleteDirectory(storage, dstDirPath)
-			}
-		}
 	case driver.Put:
 		err = s.Put(ctx, parentDir, file, up)
-		if err == nil {
-			Cache.linkCache.DeleteKey(Key(storage, dstPath))
-			if !utils.IsBool(lazyCache...) {
-				Cache.DeleteDirectory(storage, dstDirPath)
-			}
-		}
 	default:
 		return errs.NotImplement
 	}
+	if err == nil {
+		Cache.linkCache.DeleteKey(Key(storage, dstPath))
+		if !storage.Config().NoCache {
+			if cache, exist := Cache.dirCache.Get(Key(storage, dstDirPath)); exist {
+				if newObj == nil {
+					newObj = &model.Object{
+						Name:     file.GetName(),
+						Size:     file.GetSize(),
+						Modified: file.ModTime(),
+						Ctime:    file.CreateTime(),
+						Mask:     model.Temp,
+					}
+				}
+				newObj = wrapObjName(storage, newObj)
+				cache.UpdateObject(newObj.GetName(), newObj)
+			}
+		}
+
+		if ctx.Value(conf.SkipHookKey) == nil && needHandleObjsUpdateHook() {
+			go objsUpdateHook(context.WithoutCancel(ctx), storage, dstDirPath, false)
+		}
+	}
 	log.Debugf("put file [%s] done", file.GetName())
 	if storage.Config().NoOverwriteUpload && fi != nil && fi.GetSize() > 0 {
 		if err != nil {
@@ -591,23 +706,20 @@ func Put(ctx context.Context, storage driver.Driver, dstDirPath string, file mod
 			err = Remove(ctx, storage, tempPath)
 		}
 	}
-	if !utils.IsBool(lazyCache...) && err == nil && needHandleObjsUpdateHook() {
-		go List(context.Background(), storage, dstDirPath, model.ListArgs{Refresh: true})
-	}
 	return errors.WithStack(err)
 }
 
-func PutURL(ctx context.Context, storage driver.Driver, dstDirPath, dstName, url string, lazyCache ...bool) error {
+func PutURL(ctx context.Context, storage driver.Driver, dstDirPath, dstName, url string) error {
 	if storage.Config().CheckStatus && storage.GetStorage().Status != WORK {
 		return errors.WithMessagef(errs.StorageNotInit, "storage status: %s", storage.GetStorage().Status)
 	}
 	dstDirPath = utils.FixAndCleanPath(dstDirPath)
 	dstPath := stdpath.Join(dstDirPath, dstName)
-	_, err := GetUnwrap(ctx, storage, dstPath)
-	if err == nil {
+
+	if _, err := Get(ctx, storage, dstPath); err == nil {
 		return errors.WithStack(errs.ObjectAlreadyExists)
 	}
-	err = MakeDir(ctx, storage, dstDirPath)
+	err := MakeDir(ctx, storage, dstDirPath)
 	if err != nil {
 		return errors.WithMessagef(err, "failed to make dir [%s]", dstDirPath)
 	}
@@ -615,31 +727,39 @@ func PutURL(ctx context.Context, storage driver.Driver, dstDirPath, dstName, url
 	if err != nil {
 		return errors.WithMessagef(err, "failed to get dir [%s]", dstDirPath)
 	}
+	if model.ObjHasMask(dstDir, model.NoWrite) {
+		return errors.WithStack(errs.PermissionDenied)
+	}
+	var newObj model.Obj
 	switch s := storage.(type) {
 	case driver.PutURLResult:
-		var newObj model.Obj
 		newObj, err = s.PutURL(ctx, dstDir, dstName, url)
-		if err == nil {
-			Cache.linkCache.DeleteKey(Key(storage, dstPath))
-			if newObj != nil {
-				Cache.addDirectoryObject(storage, dstDirPath, model.WrapObjName(newObj))
-			} else if !utils.IsBool(lazyCache...) {
-				Cache.DeleteDirectory(storage, dstDirPath)
-			}
-		}
 	case driver.PutURL:
 		err = s.PutURL(ctx, dstDir, dstName, url)
-		if err == nil {
-			Cache.linkCache.DeleteKey(Key(storage, dstPath))
-			if !utils.IsBool(lazyCache...) {
-				Cache.DeleteDirectory(storage, dstDirPath)
-			}
-		}
 	default:
 		return errors.WithStack(errs.NotImplement)
 	}
-	if !utils.IsBool(lazyCache...) && err == nil && needHandleObjsUpdateHook() {
-		go List(context.Background(), storage, dstDirPath, model.ListArgs{Refresh: true})
+	if err == nil {
+		Cache.linkCache.DeleteKey(Key(storage, dstPath))
+		if !storage.Config().NoCache {
+			if cache, exist := Cache.dirCache.Get(Key(storage, dstDirPath)); exist {
+				if newObj == nil {
+					t := time.Now()
+					newObj = &model.Object{
+						Name:     dstName,
+						Modified: t,
+						Ctime:    t,
+						Mask:     model.Temp,
+					}
+				}
+				newObj = wrapObjName(storage, newObj)
+				cache.UpdateObject(newObj.GetName(), newObj)
+			}
+
+			if ctx.Value(conf.SkipHookKey) == nil && needHandleObjsUpdateHook() {
+				go objsUpdateHook(context.WithoutCancel(ctx), storage, dstDirPath, false)
+			}
+		}
 	}
 	log.Debugf("put url [%s](%s) done", dstName, url)
 	return errors.WithStack(err)
@@ -666,7 +786,7 @@ func GetDirectUploadInfo(ctx context.Context, tool string, storage driver.Driver
 	}
 	dstDirPath = utils.FixAndCleanPath(dstDirPath)
 	dstPath := stdpath.Join(dstDirPath, dstName)
-	_, err := GetUnwrap(ctx, storage, dstPath)
+	_, err := Get(ctx, storage, dstPath)
 	if err == nil {
 		return nil, errors.WithStack(errs.ObjectAlreadyExists)
 	}
@@ -685,7 +805,61 @@ func GetDirectUploadInfo(ctx context.Context, tool string, storage driver.Driver
 	return info, nil
 }
 
+func objsUpdateHook(ctx context.Context, storage driver.Driver, dirPath string, recursive bool) {
+	files, err := List(ctx, storage, dirPath, model.ListArgs{SkipHook: true})
+	if err != nil {
+		return
+	}
+	if !recursive {
+		HandleObjsUpdateHook(ctx, utils.GetFullPath(storage.GetStorage().MountPath, dirPath), files)
+		return
+	}
+	var limiter *rate.Limiter
+	if l, _ := GetSettingItemByKey(conf.HandleHookRateLimit); l != nil {
+		if f, e := strconv.ParseFloat(l.Value, 64); e == nil && f > .0 {
+			limiter = rate.NewLimiter(rate.Limit(f), 1)
+		}
+	}
+	recursivelyObjsUpdateHook(ctx, storage, dirPath, files, limiter)
+}
+func recursivelyObjsUpdateHook(ctx context.Context, storage driver.Driver, dirPath string, files []model.Obj, limiter *rate.Limiter) {
+	HandleObjsUpdateHook(ctx, utils.GetFullPath(storage.GetStorage().MountPath, dirPath), files)
+	for _, f := range files {
+		if utils.IsCanceled(ctx) {
+			return
+		}
+		if !f.IsDir() {
+			continue
+		}
+		dstPath := stdpath.Join(dirPath, f.GetName())
+		if limiter != nil {
+			if err := limiter.Wait(ctx); err != nil {
+				return
+			}
+		}
+		files, err := List(ctx, storage, dstPath, model.ListArgs{SkipHook: true})
+		if err == nil {
+			recursivelyObjsUpdateHook(ctx, storage, dstPath, files, limiter)
+		}
+	}
+}
+
 func needHandleObjsUpdateHook() bool {
+	if len(objsUpdateHooks) < 1 {
+		return false
+	}
 	needHandle, _ := GetSettingItemByKey(conf.HandleHookAfterWriting)
 	return needHandle != nil && (needHandle.Value == "true" || needHandle.Value == "1")
 }
+
+func wrapObjsName(storage driver.Driver, objs []model.Obj) {
+	if _, ok := storage.(driver.Getter); !ok {
+		model.WrapObjsName(objs)
+	}
+}
+func wrapObjName(storage driver.Driver, obj model.Obj) model.Obj {
+	if _, ok := storage.(driver.Getter); !ok {
+		return model.WrapObjName(obj)
+	}
+	return obj
+}
diff --git a/internal/op/storage.go b/internal/op/storage.go
index 5ccdf781a..20abfa49d 100644
--- a/internal/op/storage.go
+++ b/internal/op/storage.go
@@ -341,16 +341,17 @@ func getStoragesByPath(path string) []driver.Driver {
 // for example, there are: /a/b,/a/c,/a/d/e,/a/b.balance1,/av
 // GetStorageVirtualFilesByPath(/a) => b,c,d
 func GetStorageVirtualFilesByPath(prefix string) []model.Obj {
-	return getStorageVirtualFilesByPath(prefix, func(_ driver.Driver, obj model.Obj) model.Obj {
-		return obj
-	})
+	return getStorageVirtualFilesByPath(prefix, nil, "")
 }
 
-func GetStorageVirtualFilesWithDetailsByPath(ctx context.Context, prefix string, hideDetails, refresh bool) []model.Obj {
+func GetStorageVirtualFilesWithDetailsByPath(ctx context.Context, prefix string, hideDetails, refresh bool, filterByName string) []model.Obj {
 	if hideDetails {
-		return GetStorageVirtualFilesByPath(prefix)
+		return getStorageVirtualFilesByPath(prefix, nil, filterByName)
 	}
 	return getStorageVirtualFilesByPath(prefix, func(d driver.Driver, obj model.Obj) model.Obj {
+		if _, ok := obj.(*model.ObjStorageDetails); ok {
+			return obj
+		}
 		ret := &model.ObjStorageDetails{
 			Obj: obj,
 			StorageDetailsWithName: model.StorageDetailsWithName{
@@ -374,10 +375,10 @@ func GetStorageVirtualFilesWithDetailsByPath(ctx context.Context, prefix string,
 		case <-time.After(time.Second):
 		}
 		return ret
-	})
+	}, filterByName)
 }
 
-func getStorageVirtualFilesByPath(prefix string, rootCallback func(driver.Driver, model.Obj) model.Obj) []model.Obj {
+func getStorageVirtualFilesByPath(prefix string, rootCallback func(driver.Driver, model.Obj) model.Obj, filterByName string) []model.Obj {
 	files := make([]model.Obj, 0)
 	storages := storagesMap.Values()
 	sort.Slice(storages, func(i, j int) bool {
@@ -387,45 +388,60 @@ func getStorageVirtualFilesByPath(prefix string, rootCallback func(driver.Driver
 		return storages[i].GetStorage().Order < storages[j].GetStorage().Order
 	})
 
-	prefix = utils.FixAndCleanPath(prefix)
+	if !strings.HasSuffix(prefix, "/") {
+		prefix += "/"
+	}
 	set := make(map[string]int)
 	var wg sync.WaitGroup
 	for _, v := range storages {
-		mountPath := utils.GetActualMountPath(v.GetStorage().MountPath)
 		// Exclude prefix itself and non prefix
-		if len(prefix) >= len(mountPath) || !utils.IsSubPath(prefix, mountPath) {
+		p, found := strings.CutPrefix(utils.GetActualMountPath(v.GetStorage().MountPath), prefix)
+		if !found || p == "" {
 			continue
 		}
-		names := strings.SplitN(strings.TrimPrefix(mountPath[len(prefix):], "/"), "/", 2)
-		idx, ok := set[names[0]]
-		if !ok {
-			set[names[0]] = len(files)
-			obj := &model.Object{
-				Name:     names[0],
-				Size:     0,
-				Modified: v.GetStorage().Modified,
-				IsFolder: true,
+		name, _, found := strings.Cut(p, "/")
+		if filterByName != "" && name != filterByName {
+			continue
+		}
+
+		if idx, ok := set[name]; ok {
+			if !found {
+				files[idx].(*model.Object).Mask = model.Locked | model.Virtual
+				if rootCallback != nil {
+					wg.Add(1)
+					go func() {
+						defer wg.Done()
+						files[idx] = rootCallback(v, files[idx])
+					}()
+				}
 			}
-			if len(names) == 1 {
-				idx = len(files)
-				files = append(files, obj)
+			continue
+		}
+		set[name] = len(files)
+		obj := &model.Object{
+			Name:     name,
+			Modified: v.GetStorage().Modified,
+			IsFolder: true,
+		}
+		if !found {
+			idx := len(files)
+			obj.Mask = model.Locked | model.Virtual
+			files = append(files, obj)
+			if rootCallback != nil {
 				wg.Add(1)
 				go func() {
 					defer wg.Done()
 					files[idx] = rootCallback(v, files[idx])
 				}()
-			} else {
-				files = append(files, obj)
 			}
-		} else if len(names) == 1 {
-			wg.Add(1)
-			go func() {
-				defer wg.Done()
-				files[idx] = rootCallback(v, files[idx])
-			}()
+		} else {
+			obj.Mask = model.ReadOnly | model.Virtual
+			files = append(files, obj)
 		}
 	}
-	wg.Wait()
+	if rootCallback != nil {
+		wg.Wait()
+	}
 	return files
 }
 
diff --git a/internal/stream/util.go b/internal/stream/util.go
index 1bedf17db..6aa3dda5d 100644
--- a/internal/stream/util.go
+++ b/internal/stream/util.go
@@ -194,7 +194,7 @@ func NewStreamSectionReader(file model.FileStreamer, maxBufferSize int, up *mode
 			return nil, err
 		}
 
-		if f.Truncate((file.GetSize()+int64(maxBufferSize-1))/int64(maxBufferSize)*int64(maxBufferSize)) != nil {
+		if f.Truncate(file.GetSize()) != nil {
 			// fallback to full cache
 			_, _ = f.Close(), os.Remove(f.Name())
 			cache, err := file.CacheFullAndWriter(up, nil)
@@ -204,11 +204,11 @@ func NewStreamSectionReader(file model.FileStreamer, maxBufferSize int, up *mode
 			return &cachedSectionReader{cache}, nil
 		}
 
-		ss := &fileSectionReader{Reader: file, temp: f}
+		ss := &fileSectionReader{file: file, temp: f}
 		ss.bufPool = &pool.Pool[*offsetWriterWithBase]{
 			New: func() *offsetWriterWithBase {
-				base := ss.fileOff
-				ss.fileOff += int64(maxBufferSize)
+				base := ss.tempOffset
+				ss.tempOffset += int64(maxBufferSize)
 				return &offsetWriterWithBase{io.NewOffsetWriter(ss.temp, base), base}
 			},
 		}
@@ -225,7 +225,7 @@ func NewStreamSectionReader(file model.FileStreamer, maxBufferSize int, up *mode
 			New: func() []byte {
 				buf, err := mmap.Alloc(maxBufferSize)
 				if err == nil {
-					ss.file.Add(utils.CloseFunc(func() error {
+					file.Add(utils.CloseFunc(func() error {
 						return mmap.Free(buf)
 					}))
 				} else {
@@ -262,11 +262,11 @@ func (s *cachedSectionReader) GetSectionReader(off, length int64) (io.ReadSeeker
 func (*cachedSectionReader) FreeSectionReader(sr io.ReadSeeker) {}
 
 type fileSectionReader struct {
-	io.Reader
-	off     int64
-	temp    *os.File
-	fileOff int64
-	bufPool *pool.Pool[*offsetWriterWithBase]
+	file       model.FileStreamer
+	fileOffset int64
+	temp       *os.File
+	tempOffset int64
+	bufPool    *pool.Pool[*offsetWriterWithBase]
 }
 
 type offsetWriterWithBase struct {
@@ -276,14 +276,14 @@ type offsetWriterWithBase struct {
 
 // çº¿ç¨‹ä¸å®‰å…¨
 func (ss *fileSectionReader) DiscardSection(off int64, length int64) error {
-	if off != ss.off {
-		return fmt.Errorf("stream not cached: request offset %d != current offset %d", off, ss.off)
+	if off != ss.fileOffset {
+		return fmt.Errorf("stream not cached: request offset %d != current offset %d", off, ss.fileOffset)
 	}
-	_, err := utils.CopyWithBufferN(io.Discard, ss.Reader, length)
+	n, err := utils.CopyWithBufferN(io.Discard, ss.file, length)
+	ss.fileOffset += n
 	if err != nil {
-		return fmt.Errorf("failed to skip data: (expect =%d) %w", length, err)
+		return fmt.Errorf("failed to skip data: (expect =%d, actual =%d) %w", length, n, err)
 	}
-	ss.off += length
 	return nil
 }
 
@@ -292,17 +292,18 @@ type fileBufferSectionReader struct {
 	fileBuf *offsetWriterWithBase
 }
 
+// çº¿ç¨‹ä¸å®‰å…¨
 func (ss *fileSectionReader) GetSectionReader(off, length int64) (io.ReadSeeker, error) {
-	if off != ss.off {
-		return nil, fmt.Errorf("stream not cached: request offset %d != current offset %d", off, ss.off)
+	if off != ss.fileOffset {
+		return nil, fmt.Errorf("stream not cached: request offset %d != current offset %d", off, ss.fileOffset)
 	}
 	fileBuf := ss.bufPool.Get()
 	_, _ = fileBuf.Seek(0, io.SeekStart)
-	n, err := utils.CopyWithBufferN(fileBuf, ss.Reader, length)
+	n, err := utils.CopyWithBufferN(fileBuf, ss.file, length)
+	ss.fileOffset += n
 	if err != nil {
 		return nil, fmt.Errorf("failed to read all data: (expect =%d, actual =%d) %w", length, n, err)
 	}
-	ss.off += length
 	return &fileBufferSectionReader{io.NewSectionReader(ss.temp, fileBuf.base, length), fileBuf}, nil
 }
 
@@ -315,21 +316,21 @@ func (ss *fileSectionReader) FreeSectionReader(rs io.ReadSeeker) {
 }
 
 type directSectionReader struct {
-	file    model.FileStreamer
-	off     int64
-	bufPool *pool.Pool[[]byte]
+	file       model.FileStreamer
+	fileOffset int64
+	bufPool    *pool.Pool[[]byte]
 }
 
 // çº¿ç¨‹ä¸å®‰å…¨
 func (ss *directSectionReader) DiscardSection(off int64, length int64) error {
-	if off != ss.off {
-		return fmt.Errorf("stream not cached: request offset %d != current offset %d", off, ss.off)
+	if off != ss.fileOffset {
+		return fmt.Errorf("stream not cached: request offset %d != current offset %d", off, ss.fileOffset)
 	}
-	_, err := utils.CopyWithBufferN(io.Discard, ss.file, length)
+	n, err := utils.CopyWithBufferN(io.Discard, ss.file, length)
+	ss.fileOffset += n
 	if err != nil {
-		return fmt.Errorf("failed to skip data: (expect =%d) %w", length, err)
+		return fmt.Errorf("failed to skip data: (expect =%d, actual =%d) %w", length, n, err)
 	}
-	ss.off += length
 	return nil
 }
 
@@ -340,16 +341,16 @@ type bufferSectionReader struct {
 
 // çº¿ç¨‹ä¸å®‰å…¨
 func (ss *directSectionReader) GetSectionReader(off, length int64) (io.ReadSeeker, error) {
-	if off != ss.off {
-		return nil, fmt.Errorf("stream not cached: request offset %d != current offset %d", off, ss.off)
+	if off != ss.fileOffset {
+		return nil, fmt.Errorf("stream not cached: request offset %d != current offset %d", off, ss.fileOffset)
 	}
 	tempBuf := ss.bufPool.Get()
 	buf := tempBuf[:length]
 	n, err := io.ReadFull(ss.file, buf)
+	ss.fileOffset += int64(n)
 	if int64(n) != length {
 		return nil, fmt.Errorf("failed to read all data: (expect =%d, actual =%d) %w", length, n, err)
 	}
-	ss.off += int64(n)
 	return &bufferSectionReader{bytes.NewReader(buf), buf}, nil
 }
 func (ss *directSectionReader) FreeSectionReader(rs io.ReadSeeker) {
diff --git a/internal/task/base.go b/internal/task/base.go
index 5bfa03a86..f969e6c27 100644
--- a/internal/task/base.go
+++ b/internal/task/base.go
@@ -65,18 +65,18 @@ func (t *TaskExtension) GetTotalBytes() int64 {
 	return t.TotalBytes
 }
 
-func (t *TaskExtension) ReinitCtx() error {
+func (t *TaskExtension) SetRetry(retry int, maxRetry int) {
+	t.Base.SetRetry(retry, maxRetry)
+	if retry > 0 || !conf.Conf.Tasks.AllowRetryCanceled || t.Ctx() == nil {
+		return
+	}
 	select {
 	case <-t.Ctx().Done():
-		if !conf.Conf.Tasks.AllowRetryCanceled {
-			return t.Ctx().Err()
-		}
 		ctx, cancel := context.WithCancel(context.Background())
 		t.SetCtx(ctx)
 		t.SetCancelFunc(cancel)
 	default:
 	}
-	return nil
 }
 
 type TaskExtensionInfo interface {
diff --git a/internal/task_group/group.go b/internal/task_group/group.go
index 3cf78c8a2..edd51fe74 100644
--- a/internal/task_group/group.go
+++ b/internal/task_group/group.go
@@ -1,12 +1,13 @@
 package task_group
 
 import (
+	"context"
 	"sync"
 
 	"github.com/sirupsen/logrus"
 )
 
-type OnCompletionFunc func(groupID string, payloads ...any)
+type OnCompletionFunc func(ctx context.Context, groupID string, payloads ...any)
 type TaskGroupCoordinator struct {
 	name string
 	mu   sync.Mutex
@@ -53,7 +54,7 @@ func (tgc *TaskGroupCoordinator) AppendPayload(groupID string, payload any) {
 	tgc.groupPayloads[groupID] = append(tgc.groupPayloads[groupID], payload)
 }
 
-func (tgc *TaskGroupCoordinator) Done(groupID string, success bool) {
+func (tgc *TaskGroupCoordinator) Done(ctx context.Context, groupID string, success bool) {
 	tgc.mu.Lock()
 	defer tgc.mu.Unlock()
 	state, ok := tgc.groupStates[groupID]
@@ -71,7 +72,7 @@ func (tgc *TaskGroupCoordinator) Done(groupID string, success bool) {
 		if tgc.onCompletion != nil && state.hasSuccess {
 			logrus.Debugf("OnCompletion:%s", groupID)
 			tgc.mu.Unlock()
-			tgc.onCompletion(groupID, payloads...)
+			tgc.onCompletion(ctx, groupID, payloads...)
 			tgc.mu.Lock()
 		}
 		return
diff --git a/internal/task_group/transfer.go b/internal/task_group/transfer.go
index b046f0b28..0e9661b45 100644
--- a/internal/task_group/transfer.go
+++ b/internal/task_group/transfer.go
@@ -10,6 +10,7 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
 	"github.com/OpenListTeam/OpenList/v4/internal/op"
 	"github.com/OpenListTeam/OpenList/v4/internal/setting"
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
 	"github.com/pkg/errors"
 	log "github.com/sirupsen/logrus"
 	"golang.org/x/time/rate"
@@ -18,54 +19,52 @@ import (
 type SrcPathToRemove string
 
 // ActualPath
-type DstPathToRefresh string
+type DstPathToHook string
 
-func RefreshAndRemove(dstPath string, payloads ...any) {
+func HookAndRemove(ctx context.Context, dstPath string, payloads ...any) {
 	dstStorage, dstActualPath, err := op.GetStorageAndActualPath(dstPath)
 	if err != nil {
 		log.Error(errors.WithMessage(err, "failed get dst storage"))
 		return
 	}
-	_, dstNeedRefresh := dstStorage.(driver.Put)
-	if dstNeedRefresh {
-		op.Cache.DeleteDirectory(dstStorage, dstActualPath)
-	}
 	dstNeedHandleHook := setting.GetBool(conf.HandleHookAfterWriting)
 	dstHandleHookLimit := setting.GetFloat(conf.HandleHookRateLimit, .0)
 	var listLimiter *rate.Limiter
-	if dstNeedRefresh && dstNeedHandleHook && dstHandleHookLimit > .0 {
+	if dstNeedHandleHook && dstHandleHookLimit > .0 {
 		listLimiter = rate.NewLimiter(rate.Limit(dstHandleHookLimit), 1)
 	}
-	var ctx context.Context
+	hookedPaths := make(map[string]struct{})
+	handleHook := func(actualPath string) {
+		if _, ok := hookedPaths[actualPath]; ok {
+			return
+		}
+		if listLimiter != nil {
+			_ = listLimiter.Wait(ctx)
+		}
+		files, e := op.List(ctx, dstStorage, actualPath, model.ListArgs{SkipHook: true})
+		if e != nil {
+			log.Errorf("failed handle objs update hook: %v", e)
+		} else {
+			op.HandleObjsUpdateHook(ctx, utils.GetFullPath(dstStorage.GetStorage().MountPath, actualPath), files)
+			hookedPaths[actualPath] = struct{}{}
+		}
+	}
+	if dstNeedHandleHook {
+		handleHook(dstActualPath)
+	}
 	for _, payload := range payloads {
 		switch p := payload.(type) {
-		case DstPathToRefresh:
-			if dstNeedRefresh {
-				if dstNeedHandleHook {
-					if ctx == nil {
-						ctx = context.Background()
-					}
-					if listLimiter != nil {
-						_ = listLimiter.Wait(ctx)
-					}
-					_, e := op.List(ctx, dstStorage, string(p), model.ListArgs{Refresh: true})
-					if e != nil {
-						log.Errorf("failed handle objs update hook: %v", e)
-					}
-				} else {
-					op.Cache.DeleteDirectory(dstStorage, string(p))
-				}
+		case DstPathToHook:
+			if dstNeedHandleHook {
+				handleHook(string(p))
 			}
 		case SrcPathToRemove:
-			if ctx == nil {
-				ctx = context.Background()
-			}
 			srcStorage, srcActualPath, err := op.GetStorageAndActualPath(string(p))
 			if err != nil {
 				log.Error(errors.WithMessage(err, "failed get src storage"))
 				continue
 			}
-			err = verifyAndRemove(ctx, srcStorage, dstStorage, srcActualPath, dstActualPath, dstNeedRefresh)
+			err = verifyAndRemove(ctx, srcStorage, dstStorage, srcActualPath, dstActualPath)
 			if err != nil {
 				log.Error(err)
 			}
@@ -73,14 +72,14 @@ func RefreshAndRemove(dstPath string, payloads ...any) {
 	}
 }
 
-func verifyAndRemove(ctx context.Context, srcStorage, dstStorage driver.Driver, srcPath, dstPath string, refresh bool) error {
-	srcObj, err := op.Get(ctx, srcStorage, srcPath)
+func verifyAndRemove(ctx context.Context, srcStorage, dstStorage driver.Driver, srcPath, dstPath string) error {
+	srcObj, err := op.GetUnwrap(ctx, srcStorage, srcPath)
 	if err != nil {
 		return errors.WithMessagef(err, "failed get src [%s] file", path.Join(srcStorage.GetStorage().MountPath, srcPath))
 	}
 
 	dstObjPath := path.Join(dstPath, srcObj.GetName())
-	dstObj, err := op.Get(ctx, dstStorage, dstObjPath)
+	dstObj, err := op.GetUnwrap(ctx, dstStorage, dstObjPath)
 	if err != nil {
 		return errors.WithMessagef(err, "failed get dst [%s] file", path.Join(dstStorage.GetStorage().MountPath, dstObjPath))
 	}
@@ -99,13 +98,10 @@ func verifyAndRemove(ctx context.Context, srcStorage, dstStorage driver.Driver,
 		return errors.WithMessagef(err, "failed list src [%s] objs", path.Join(srcStorage.GetStorage().MountPath, srcPath))
 	}
 
-	if refresh {
-		op.Cache.DeleteDirectory(dstStorage, dstObjPath)
-	}
 	hasErr := false
 	for _, obj := range srcObjs {
 		srcSubPath := path.Join(srcPath, obj.GetName())
-		err := verifyAndRemove(ctx, srcStorage, dstStorage, srcSubPath, dstObjPath, refresh)
+		err := verifyAndRemove(ctx, srcStorage, dstStorage, srcSubPath, dstObjPath)
 		if err != nil {
 			log.Error(err)
 			hasErr = true
@@ -121,4 +117,4 @@ func verifyAndRemove(ctx context.Context, srcStorage, dstStorage driver.Driver,
 	return nil
 }
 
-var TransferCoordinator *TaskGroupCoordinator = NewTaskGroupCoordinator("RefreshAndRemove", RefreshAndRemove)
+var TransferCoordinator *TaskGroupCoordinator = NewTaskGroupCoordinator("HookAndRemove", HookAndRemove)
diff --git a/pkg/errgroup/errgroup.go b/pkg/errgroup/errgroup.go
index d3c4feaff..7d72a1d8e 100644
--- a/pkg/errgroup/errgroup.go
+++ b/pkg/errgroup/errgroup.go
@@ -29,6 +29,7 @@ func NewGroupWithContext(ctx context.Context, limit int, retryOpts ...retry.Opti
 }
 
 // OrderedGroup
+// ä½¿å¾—Lifecycle.Beforeæ˜¯æœ‰åºä¸”çº¿ç¨‹å®‰å…¨
 func NewOrderedGroupWithContext(ctx context.Context, limit int, retryOpts ...retry.Option) (*Group, context.Context) {
 	group, ctx := NewGroupWithContext(ctx, limit, retryOpts...)
 	group.startChan = make(chan token, 1)
@@ -53,11 +54,11 @@ func (g *Group) Go(do func(ctx context.Context) error) {
 }
 
 type Lifecycle struct {
-	// Beforeåœ¨OrderedGroupæ˜¯çº¿ç¨‹å®‰å…¨çš„ã€‚
+	// Beforeåœ¨OrderedGroupæ˜¯æœ‰åºä¸”çº¿ç¨‹å®‰å…¨çš„
 	// åªä¼šè¢«è°ƒç”¨ä¸€æ¬¡
-	Before func(ctx context.Context) error
+	Before func(ctx context.Context) (err error)
 	// å¦‚æœBeforeè¿”å›errå°±ä¸è°ƒç”¨Do
-	Do func(ctx context.Context) error
+	Do func(ctx context.Context) (err error)
 	// æœ€åè°ƒç”¨ä¸€æ¬¡After
 	After func(err error)
 }
diff --git a/pkg/utils/file.go b/pkg/utils/file.go
index dcfd51a27..4fa58d397 100644
--- a/pkg/utils/file.go
+++ b/pkg/utils/file.go
@@ -191,14 +191,14 @@ const (
 func IsSystemFile(filename string) bool {
 	// Common system files
 	switch filename {
-	case ".DS_Store", "desktop.ini", "Thumbs.db":
+	case ".DS_Store", "desktop.ini", "Thumbs.db", "@eaDir":
 		return true
 	}
-	
+
 	// Apple Double files (._*)
 	if strings.HasPrefix(filename, "._") {
 		return true
 	}
-	
+
 	return false
 }
diff --git a/pkg/utils/file_test.go b/pkg/utils/file_test.go
index d7a7262f4..bcfff7934 100644
--- a/pkg/utils/file_test.go
+++ b/pkg/utils/file_test.go
@@ -17,7 +17,8 @@ func TestIsSystemFile(t *testing.T) {
 		{"._", true},
 		{"._somefile", true},
 		{"._folder_name", true},
-		
+		{"@eaDir", true},
+
 		// Regular files that should not be filtered
 		{"test.txt", false},
 		{"file.pdf", false},
diff --git a/server/common/ldap.go b/server/common/ldap.go
new file mode 100644
index 000000000..9dc3b93fd
--- /dev/null
+++ b/server/common/ldap.go
@@ -0,0 +1,107 @@
+package common
+
+import (
+	"crypto/tls"
+	"fmt"
+	"strings"
+
+	"github.com/OpenListTeam/OpenList/v4/internal/conf"
+	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	"github.com/OpenListTeam/OpenList/v4/internal/op"
+	"github.com/OpenListTeam/OpenList/v4/internal/setting"
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+	"github.com/OpenListTeam/OpenList/v4/pkg/utils/random"
+	"github.com/pkg/errors"
+	log "github.com/sirupsen/logrus"
+	"gopkg.in/ldap.v3"
+)
+
+var ErrFailedLdapAuth = errors.New("failed to auth")
+
+func HandleLdapLogin(username, password string) error {
+	// Auth start
+	ldapServer := setting.GetStr(conf.LdapServer)
+	skipTlsVerify := setting.GetBool(conf.LdapSkipTlsVerify)
+	ldapManagerDN := setting.GetStr(conf.LdapManagerDN)
+	ldapManagerPassword := setting.GetStr(conf.LdapManagerPassword)
+	ldapUserSearchBase := setting.GetStr(conf.LdapUserSearchBase)
+	ldapUserSearchFilter := setting.GetStr(conf.LdapUserSearchFilter) // (uid=%s)
+
+	// Connect to LdapServer
+	l, err := dial(ldapServer, skipTlsVerify)
+	if err != nil {
+		return errors.WithMessagef(err, "failed to connect to LDAP")
+	}
+	defer l.Close()
+
+	// First bind with a read only user
+	if ldapManagerDN != "" && ldapManagerPassword != "" {
+		err = l.Bind(ldapManagerDN, ldapManagerPassword)
+		if err != nil {
+			return errors.WithMessagef(err, "failed to bind to LDAP")
+		}
+	}
+
+	// Search for the given username
+	searchRequest := ldap.NewSearchRequest(
+		ldapUserSearchBase,
+		ldap.ScopeWholeSubtree, ldap.NeverDerefAliases, 0, 0, false,
+		fmt.Sprintf(ldapUserSearchFilter, ldap.EscapeFilter(username)),
+		[]string{"dn"},
+		nil,
+	)
+	sr, err := l.Search(searchRequest)
+	if err != nil {
+		return errors.WithMessagef(err, "failed login ldap: LDAP search failed")
+	}
+	if len(sr.Entries) != 1 {
+		return errors.New("failed login ldap: user does not exist or too many entries returned")
+	}
+	userDN := sr.Entries[0].DN
+
+	// Bind as the user to verify their password
+	err = l.Bind(userDN, password)
+	if err != nil {
+		return errors.WithMessagef(ErrFailedLdapAuth, "%v", err)
+	}
+	log.Infof("LDAP auth successful for %s", username)
+	// Auth finished
+	return nil
+}
+
+func LdapRegister(username string) (*model.User, error) {
+	if username == "" {
+		return nil, errors.New("cannot get username from ldap provider")
+	}
+	user := &model.User{
+		Username:   username,
+		Password:   "",
+		Authn:      "[]",
+		Permission: int32(setting.GetInt(conf.LdapDefaultPermission, 0)),
+		BasePath:   setting.GetStr(conf.LdapDefaultDir),
+		Role:       0,
+		Disabled:   false,
+		AllowLdap:  true,
+	}
+	user.SetPassword(random.String(16))
+	if err := op.CreateUser(user); err != nil {
+		return nil, err
+	}
+	return user, nil
+}
+
+func dial(ldapServer string, skipTlsVerify ...bool) (*ldap.Conn, error) {
+	tlsEnabled := false
+	if strings.HasPrefix(ldapServer, "ldaps://") {
+		tlsEnabled = true
+		ldapServer = strings.TrimPrefix(ldapServer, "ldaps://")
+	} else if strings.HasPrefix(ldapServer, "ldap://") {
+		ldapServer = strings.TrimPrefix(ldapServer, "ldap://")
+	}
+
+	if tlsEnabled {
+		return ldap.DialTLS("tcp", ldapServer, &tls.Config{InsecureSkipVerify: utils.IsBool(skipTlsVerify...)})
+	} else {
+		return ldap.Dial("tcp", ldapServer)
+	}
+}
diff --git a/server/ftp.go b/server/ftp.go
index fb7d86c8e..d07a62dd9 100644
--- a/server/ftp.go
+++ b/server/ftp.go
@@ -19,6 +19,7 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/op"
 	"github.com/OpenListTeam/OpenList/v4/internal/setting"
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+	"github.com/OpenListTeam/OpenList/v4/server/common"
 	"github.com/OpenListTeam/OpenList/v4/server/ftp"
 	ftpserver "github.com/fclairamb/ftpserverlib"
 )
@@ -112,6 +113,12 @@ func (d *FtpMainDriver) ClientDisconnected(cc ftpserver.ClientContext) {
 }
 
 func (d *FtpMainDriver) AuthUser(cc ftpserver.ClientContext, user, pass string) (ftpserver.ClientDriver, error) {
+	ip := cc.RemoteAddr().String()
+	count, ok := model.LoginCache.Get(ip)
+	if ok && count >= model.DefaultMaxAuthRetries {
+		model.LoginCache.Expire(ip, model.DefaultLockDuration)
+		return nil, errors.New("Too many unsuccessful sign-in attempts have been made using an incorrect username or password, Try again later.")
+	}
 	var userObj *model.User
 	var err error
 	if user == "anonymous" || user == "guest" {
@@ -121,17 +128,24 @@ func (d *FtpMainDriver) AuthUser(cc ftpserver.ClientContext, user, pass string)
 		}
 	} else {
 		userObj, err = op.GetUserByName(user)
-		if err != nil {
-			return nil, err
+		if err == nil {
+			err = userObj.ValidateRawPassword(pass)
+			if err != nil && setting.GetBool(conf.LdapLoginEnabled) && userObj.AllowLdap {
+				err = common.HandleLdapLogin(user, pass)
+			}
+		} else if setting.GetBool(conf.LdapLoginEnabled) && model.CanFTPAccess(int32(setting.GetInt(conf.LdapDefaultPermission, 0))) {
+			userObj, err = tryLdapLoginAndRegister(user, pass)
 		}
-		passHash := model.StaticHash(pass)
-		if err = userObj.ValidatePwdStaticHash(passHash); err != nil {
+		if err != nil {
+			model.LoginCache.Set(ip, count+1)
 			return nil, err
 		}
 	}
 	if userObj.Disabled || !userObj.CanFTPAccess() {
+		model.LoginCache.Set(ip, count+1)
 		return nil, errors.New("user is not allowed to access via FTP")
 	}
+	model.LoginCache.Del(ip)
 
 	ctx := context.Background()
 	ctx = context.WithValue(ctx, conf.UserKey, userObj)
@@ -140,7 +154,7 @@ func (d *FtpMainDriver) AuthUser(cc ftpserver.ClientContext, user, pass string)
 	} else {
 		ctx = context.WithValue(ctx, conf.MetaPassKey, "")
 	}
-	ctx = context.WithValue(ctx, conf.ClientIPKey, cc.RemoteAddr().String())
+	ctx = context.WithValue(ctx, conf.ClientIPKey, ip)
 	ctx = context.WithValue(ctx, conf.ProxyHeaderKey, d.proxyHeader)
 	return ftp.NewAferoAdapter(ctx), nil
 }
@@ -167,7 +181,7 @@ func lookupIP(host string) string {
 	}
 	ips, err := net.LookupIP(host)
 	if err != nil || len(ips) == 0 {
-		utils.Log.Fatalf("given FTP public host is invalid, and the default value will be used: %v", err)
+		utils.Log.Errorf("given FTP public host is invalid, and the default value will be used: %v", err)
 		return ""
 	}
 	for _, ip := range ips {
@@ -272,7 +286,7 @@ func newPortMapper(str string) ftpserver.PasvPortGetter {
 			break
 		}
 		if err != nil {
-			utils.Log.Fatalf("failed to convert FTP PASV port mapper %s: %v, the port mapper will be ignored.", mapper, err)
+			utils.Log.Errorf("failed to convert FTP PASV port mapper %s: %v, the port mapper will be ignored.", mapper, err)
 			return nil
 		}
 	}
diff --git a/server/handles/fsread.go b/server/handles/fsread.go
index d5aab75e4..65bc25248 100644
--- a/server/handles/fsread.go
+++ b/server/handles/fsread.go
@@ -33,8 +33,6 @@ type DirReq struct {
 }
 
 type ObjResp struct {
-	Id           string                        `json:"id"`
-	Path         string                        `json:"path"`
 	Name         string                        `json:"name"`
 	Size         int64                         `json:"size"`
 	IsDir        bool                          `json:"is_dir"`
@@ -234,8 +232,6 @@ func toObjsResp(objs []model.Obj, parent string, encrypt bool) []ObjResp {
 		thumb, _ := model.GetThumb(obj)
 		mountDetails, _ := model.GetStorageDetails(obj)
 		resp = append(resp, ObjResp{
-			Id:           obj.GetID(),
-			Path:         obj.GetPath(),
 			Name:         obj.GetName(),
 			Size:         obj.GetSize(),
 			IsDir:        obj.IsDir(),
@@ -365,8 +361,6 @@ func FsGet(c *gin.Context, req *FsGetReq, user *model.User) {
 	mountDetails, _ := model.GetStorageDetails(obj)
 	common.SuccessResp(c, FsGetResp{
 		ObjResp: ObjResp{
-			Id:           obj.GetID(),
-			Path:         obj.GetPath(),
 			Name:         obj.GetName(),
 			Size:         obj.GetSize(),
 			IsDir:        obj.IsDir(),
diff --git a/server/handles/fsup.go b/server/handles/fsup.go
index 2da65a166..0f46398cd 100644
--- a/server/handles/fsup.go
+++ b/server/handles/fsup.go
@@ -112,7 +112,7 @@ func FsStream(c *gin.Context) {
 	if asTask {
 		t, err = fs.PutAsTask(c.Request.Context(), dir, s)
 	} else {
-		err = fs.PutDirectly(c.Request.Context(), dir, s, true)
+		err = fs.PutDirectly(c.Request.Context(), dir, s)
 	}
 	if err != nil {
 		common.ErrorResp(c, err, 500)
@@ -212,7 +212,7 @@ func FsForm(c *gin.Context) {
 		}{f}
 		t, err = fs.PutAsTask(c.Request.Context(), dir, s)
 	} else {
-		err = fs.PutDirectly(c.Request.Context(), dir, s, true)
+		err = fs.PutDirectly(c.Request.Context(), dir, s)
 	}
 	if err != nil {
 		common.ErrorResp(c, err, 500)
diff --git a/server/handles/ldap_login.go b/server/handles/ldap_login.go
index dff3aebe3..ba44615f7 100644
--- a/server/handles/ldap_login.go
+++ b/server/handles/ldap_login.go
@@ -1,21 +1,13 @@
 package handles
 
 import (
-	"crypto/tls"
-	"errors"
-	"fmt"
-	"strings"
-
 	"github.com/OpenListTeam/OpenList/v4/internal/conf"
-	"github.com/OpenListTeam/OpenList/v4/internal/db"
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
 	"github.com/OpenListTeam/OpenList/v4/internal/op"
 	"github.com/OpenListTeam/OpenList/v4/internal/setting"
-	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
-	"github.com/OpenListTeam/OpenList/v4/pkg/utils/random"
 	"github.com/OpenListTeam/OpenList/v4/server/common"
 	"github.com/gin-gonic/gin"
-	"gopkg.in/ldap.v3"
+	"github.com/pkg/errors"
 )
 
 func LoginLdap(c *gin.Context) {
@@ -24,15 +16,16 @@ func LoginLdap(c *gin.Context) {
 		common.ErrorResp(c, err, 400)
 		return
 	}
-	loginLdap(c, &req)
-}
-
-func loginLdap(c *gin.Context, req *LoginReq) {
 	enabled := setting.GetBool(conf.LdapLoginEnabled)
 	if !enabled {
 		common.ErrorStrResp(c, "ldap is not enabled", 403)
 		return
 	}
+	user, err := op.GetUserByName(req.Username)
+	if err == nil && !user.AllowLdap {
+		common.ErrorStrResp(c, "login via ldap is not allowed", 403)
+		return
+	}
 
 	// check count of login
 	ip := c.ClientIP()
@@ -43,67 +36,19 @@ func loginLdap(c *gin.Context, req *LoginReq) {
 		return
 	}
 
-	// Auth start
-	ldapServer := setting.GetStr(conf.LdapServer)
-	ldapManagerDN := setting.GetStr(conf.LdapManagerDN)
-	ldapManagerPassword := setting.GetStr(conf.LdapManagerPassword)
-	ldapUserSearchBase := setting.GetStr(conf.LdapUserSearchBase)
-	ldapUserSearchFilter := setting.GetStr(conf.LdapUserSearchFilter) // (uid=%s)
-
-	// Connect to LdapServer
-	l, err := dial(ldapServer)
+	err = common.HandleLdapLogin(req.Username, req.Password)
 	if err != nil {
-		utils.Log.Errorf("failed to connect to LDAP: %v", err)
-		common.ErrorResp(c, err, 500)
-		return
-	}
-
-	// First bind with a read only user
-	if ldapManagerDN != "" && ldapManagerPassword != "" {
-		err = l.Bind(ldapManagerDN, ldapManagerPassword)
-		if err != nil {
-			utils.Log.Errorf("Failed to bind to LDAP: %v", err)
+		if errors.Is(err, common.ErrFailedLdapAuth) {
+			model.LoginCache.Set(ip, count+1)
+			common.ErrorResp(c, err, 400)
+		} else {
 			common.ErrorResp(c, err, 500)
-			return
 		}
-	}
-
-	// Search for the given username
-	searchRequest := ldap.NewSearchRequest(
-		ldapUserSearchBase,
-		ldap.ScopeWholeSubtree, ldap.NeverDerefAliases, 0, 0, false,
-		fmt.Sprintf(ldapUserSearchFilter, req.Username),
-		[]string{"dn"},
-		nil,
-	)
-	sr, err := l.Search(searchRequest)
-	if err != nil {
-		utils.Log.Errorf("LDAP search failed: %v", err)
-		common.ErrorResp(c, err, 500)
-		return
-	}
-	if len(sr.Entries) != 1 {
-		utils.Log.Errorf("User does not exist or too many entries returned")
-		common.ErrorResp(c, err, 500)
 		return
 	}
-	userDN := sr.Entries[0].DN
 
-	// Bind as the user to verify their password
-	err = l.Bind(userDN, req.Password)
-	if err != nil {
-		utils.Log.Errorf("Failed to auth. %v", err)
-		common.ErrorResp(c, err, 400)
-		model.LoginCache.Set(ip, count+1)
-		return
-	} else {
-		utils.Log.Infof("Auth successful username:%s", req.Username)
-	}
-	// Auth finished
-
-	user, err := op.GetUserByName(req.Username)
-	if err != nil {
-		user, err = ladpRegister(req.Username)
+	if user == nil {
+		user, err = common.LdapRegister(req.Username)
 		if err != nil {
 			common.ErrorResp(c, err, 400)
 			model.LoginCache.Set(ip, count+1)
@@ -120,38 +65,3 @@ func loginLdap(c *gin.Context, req *LoginReq) {
 	common.SuccessResp(c, gin.H{"token": token})
 	model.LoginCache.Del(ip)
 }
-
-func ladpRegister(username string) (*model.User, error) {
-	if username == "" {
-		return nil, errors.New("cannot get username from ldap provider")
-	}
-	user := &model.User{
-		ID:         0,
-		Username:   username,
-		Password:   random.String(16),
-		Permission: int32(setting.GetInt(conf.LdapDefaultPermission, 0)),
-		BasePath:   setting.GetStr(conf.LdapDefaultDir),
-		Role:       0,
-		Disabled:   false,
-	}
-	if err := db.CreateUser(user); err != nil {
-		return nil, err
-	}
-	return user, nil
-}
-
-func dial(ldapServer string) (*ldap.Conn, error) {
-	var tlsEnabled bool = false
-	if strings.HasPrefix(ldapServer, "ldaps://") {
-		tlsEnabled = true
-		ldapServer = strings.TrimPrefix(ldapServer, "ldaps://")
-	} else if strings.HasPrefix(ldapServer, "ldap://") {
-		ldapServer = strings.TrimPrefix(ldapServer, "ldap://")
-	}
-
-	if tlsEnabled {
-		return ldap.DialTLS("tcp", ldapServer, &tls.Config{InsecureSkipVerify: true})
-	} else {
-		return ldap.Dial("tcp", ldapServer)
-	}
-}
diff --git a/server/handles/sharing.go b/server/handles/sharing.go
index 535ecb48a..43f855afb 100644
--- a/server/handles/sharing.go
+++ b/server/handles/sharing.go
@@ -34,9 +34,9 @@ func SharingGet(c *gin.Context, req *FsGetReq) {
 		return
 	}
 	_ = countAccess(c.ClientIP(), s)
-	fakePath := fmt.Sprintf("/%s/%s", sid, path)
 	url := ""
 	if !obj.IsDir() {
+		fakePath := fmt.Sprintf("/%s/%s", sid, path)
 		url = fmt.Sprintf("%s/sd%s", common.GetApiUrl(c), utils.EncodePath(fakePath, true))
 		if s.Pwd != "" {
 			url += "?pwd=" + s.Pwd
@@ -45,8 +45,6 @@ func SharingGet(c *gin.Context, req *FsGetReq) {
 	thumb, _ := model.GetThumb(obj)
 	common.SuccessResp(c, FsGetResp{
 		ObjResp: ObjResp{
-			Id:          "",
-			Path:        fakePath,
 			Name:        obj.GetName(),
 			Size:        obj.GetSize(),
 			IsDir:       obj.IsDir(),
@@ -80,14 +78,11 @@ func SharingList(c *gin.Context, req *ListReq) {
 		return
 	}
 	_ = countAccess(c.ClientIP(), s)
-	fakePath := fmt.Sprintf("/%s/%s", sid, path)
 	total, objs := pagination(objs, &req.PageReq)
 	common.SuccessResp(c, FsListResp{
 		Content: utils.MustSliceConvert(objs, func(obj model.Obj) ObjResp {
 			thumb, _ := model.GetThumb(obj)
 			return ObjResp{
-				Id:          "",
-				Path:        stdpath.Join(fakePath, obj.GetName()),
 				Name:        obj.GetName(),
 				Size:        obj.GetSize(),
 				IsDir:       obj.IsDir(),
diff --git a/server/s3/backend.go b/server/s3/backend.go
index c0f7aedd4..f00d2149c 100644
--- a/server/s3/backend.go
+++ b/server/s3/backend.go
@@ -258,7 +258,7 @@ func (b *s3Backend) PutObject(
 	if err != nil {
 		if errs.IsObjectNotFound(err) && strings.Contains(objectName, "/") {
 			log.Debugf("reqPath: %s not found and objectName contains /, need to makeDir", reqPath)
-			err = fs.MakeDir(ctx, reqPath, true)
+			err = fs.MakeDir(ctx, reqPath)
 			if err != nil {
 				return result, errors.WithMessagef(err, "failed to makeDir, reqPath: %s", reqPath)
 			}
@@ -281,6 +281,11 @@ func (b *s3Backend) PutObject(
 		ti, _ = swift.FloatStringToTime(val)
 	}
 
+	// If Modified is not set, use current time
+	if ti.IsZero() {
+		ti = time.Now()
+	}
+
 	obj := model.Object{
 		Name:     path.Base(fp),
 		Size:     size,
diff --git a/server/sftp.go b/server/sftp.go
index 055f79730..37dc9870d 100644
--- a/server/sftp.go
+++ b/server/sftp.go
@@ -11,6 +11,7 @@ import (
 	"github.com/OpenListTeam/OpenList/v4/internal/op"
 	"github.com/OpenListTeam/OpenList/v4/internal/setting"
 	"github.com/OpenListTeam/OpenList/v4/pkg/utils"
+	"github.com/OpenListTeam/OpenList/v4/server/common"
 	"github.com/OpenListTeam/OpenList/v4/server/ftp"
 	"github.com/OpenListTeam/OpenList/v4/server/sftp"
 	"github.com/OpenListTeam/sftpd-openlist"
@@ -92,17 +93,31 @@ func (d *SftpDriver) NoClientAuth(conn ssh.ConnMetadata) (*ssh.Permissions, erro
 }
 
 func (d *SftpDriver) PasswordAuth(conn ssh.ConnMetadata, password []byte) (*ssh.Permissions, error) {
+	ip := conn.RemoteAddr().String()
+	count, ok := model.LoginCache.Get(ip)
+	if ok && count >= model.DefaultMaxAuthRetries {
+		model.LoginCache.Expire(ip, model.DefaultLockDuration)
+		return nil, errors.New("Too many unsuccessful sign-in attempts have been made using an incorrect username or password, Try again later.")
+	}
+	pass := string(password)
 	userObj, err := op.GetUserByName(conn.User())
+	if err == nil {
+		err = userObj.ValidateRawPassword(pass)
+		if err != nil && setting.GetBool(conf.LdapLoginEnabled) && userObj.AllowLdap {
+			err = common.HandleLdapLogin(conn.User(), pass)
+		}
+	} else if setting.GetBool(conf.LdapLoginEnabled) && model.CanFTPAccess(int32(setting.GetInt(conf.LdapDefaultPermission, 0))) {
+		userObj, err = tryLdapLoginAndRegister(conn.User(), pass)
+	}
 	if err != nil {
+		model.LoginCache.Set(ip, count+1)
 		return nil, err
 	}
 	if userObj.Disabled || !userObj.CanFTPAccess() {
+		model.LoginCache.Set(ip, count+1)
 		return nil, errors.New("user is not allowed to access via SFTP")
 	}
-	passHash := model.StaticHash(string(password))
-	if err = userObj.ValidatePwdStaticHash(passHash); err != nil {
-		return nil, err
-	}
+	model.LoginCache.Del(ip)
 	return nil, nil
 }
 
diff --git a/server/sftp/hostkey.go b/server/sftp/hostkey.go
index ffa25c665..6d857666a 100644
--- a/server/sftp/hostkey.go
+++ b/server/sftp/hostkey.go
@@ -24,7 +24,7 @@ func InitHostKey() {
 	if !utils.Exists(sshPath) {
 		err := utils.CreateNestedDirectory(sshPath)
 		if err != nil {
-			utils.Log.Fatalf("failed to create ssh directory: %+v", err)
+			utils.Log.Errorf("failed to create ssh directory: %+v", err)
 			return
 		}
 	}
@@ -54,30 +54,30 @@ func LoadOrGenerateRSAHostKey(parentDir string) (ssh.Signer, bool) {
 	_ = os.Remove(publicKeyPath)
 	privateKey, err := rsa.GenerateKey(rand.Reader, 4096)
 	if err != nil {
-		utils.Log.Fatalf("failed to generate RSA private key: %+v", err)
+		utils.Log.Errorf("failed to generate RSA private key: %+v", err)
 		return nil, false
 	}
 	publicKey, err := ssh.NewPublicKey(&privateKey.PublicKey)
 	if err != nil {
-		utils.Log.Fatalf("failed to generate RSA public key: %+v", err)
+		utils.Log.Errorf("failed to generate RSA public key: %+v", err)
 		return nil, false
 	}
 	ret, err := ssh.NewSignerFromKey(privateKey)
 	if err != nil {
-		utils.Log.Fatalf("failed to generate RSA signer: %+v", err)
+		utils.Log.Errorf("failed to generate RSA signer: %+v", err)
 		return nil, false
 	}
 	privateBytes := rsaEncodePrivateKey(privateKey)
 	publicBytes := ssh.MarshalAuthorizedKey(publicKey)
 	err = os.WriteFile(privateKeyPath, privateBytes, 0600)
 	if err != nil {
-		utils.Log.Fatalf("failed to write RSA private key to file: %+v", err)
+		utils.Log.Errorf("failed to write RSA private key to file: %+v", err)
 		return nil, false
 	}
 	err = os.WriteFile(publicKeyPath, publicBytes, 0644)
 	if err != nil {
 		_ = os.Remove(privateKeyPath)
-		utils.Log.Fatalf("failed to write RSA public key to file: %+v", err)
+		utils.Log.Errorf("failed to write RSA public key to file: %+v", err)
 		return nil, false
 	}
 	return ret, true
diff --git a/server/utils.go b/server/utils.go
new file mode 100644
index 000000000..0e9d68809
--- /dev/null
+++ b/server/utils.go
@@ -0,0 +1,14 @@
+package server
+
+import (
+	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	"github.com/OpenListTeam/OpenList/v4/server/common"
+)
+
+func tryLdapLoginAndRegister(user, pass string) (*model.User, error) {
+	err := common.HandleLdapLogin(user, pass)
+	if err != nil {
+		return nil, err
+	}
+	return common.LdapRegister(user)
+}
diff --git a/server/webdav.go b/server/webdav.go
index b2afe581d..789236b8b 100644
--- a/server/webdav.go
+++ b/server/webdav.go
@@ -6,14 +6,13 @@ import (
 	"path"
 	"strings"
 
+	"github.com/OpenListTeam/OpenList/v4/internal/conf"
 	"github.com/OpenListTeam/OpenList/v4/internal/model"
+	"github.com/OpenListTeam/OpenList/v4/internal/op"
+	"github.com/OpenListTeam/OpenList/v4/internal/setting"
 	"github.com/OpenListTeam/OpenList/v4/internal/stream"
 	"github.com/OpenListTeam/OpenList/v4/server/common"
 	"github.com/OpenListTeam/OpenList/v4/server/middlewares"
-
-	"github.com/OpenListTeam/OpenList/v4/internal/conf"
-	"github.com/OpenListTeam/OpenList/v4/internal/op"
-	"github.com/OpenListTeam/OpenList/v4/internal/setting"
 	"github.com/OpenListTeam/OpenList/v4/server/webdav"
 	"github.com/gin-gonic/gin"
 	log "github.com/sirupsen/logrus"
@@ -94,8 +93,8 @@ func WebDAVAuth(c *gin.Context) {
 		c.Abort()
 		return
 	}
-	user, err := op.GetUserByName(username)
-	if err != nil || user.ValidateRawPassword(password) != nil {
+	user, ok := tryLogin(username, password)
+	if !ok {
 		if c.Request.Method == "OPTIONS" {
 			common.GinWithValue(c, conf.UserKey, guest)
 			c.Next()
@@ -146,3 +145,16 @@ func WebDAVAuth(c *gin.Context) {
 	common.GinWithValue(c, conf.UserKey, user)
 	c.Next()
 }
+
+func tryLogin(username, password string) (*model.User, bool) {
+	user, err := op.GetUserByName(username)
+	if err == nil {
+		err = user.ValidateRawPassword(password)
+		if err != nil && setting.GetBool(conf.LdapLoginEnabled) && user.AllowLdap {
+			err = common.HandleLdapLogin(username, password)
+		}
+	} else if setting.GetBool(conf.LdapLoginEnabled) && model.CanWebdavRead(int32(setting.GetInt(conf.LdapDefaultPermission, 0))) {
+		user, err = tryLdapLoginAndRegister(username, password)
+	}
+	return user, err == nil
+}
